{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Petai-training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyzVbLEtFgUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le-lmaQTGcVb",
        "colab_type": "code",
        "outputId": "061ec0e0-ab7a-45af-9e7d-ec8e1a00593a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaxImr4pPRSQ",
        "colab_type": "code",
        "outputId": "52030a36-b97f-43c4-ddff-598f00563b64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!pip install -q tf-nightly-2.0-preview"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 95.2MB 32kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8MB 34.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 450kB 39.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 10.4MB/s \n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.10.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tb-nightly 2.1.0a20191206 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MxxntOTPhDB",
        "colab_type": "code",
        "outputId": "45575f79-ac89-4953-d7f6-2412ba7f8bc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "from tensorflow import summary"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6yDN6k4Pprs",
        "colab_type": "code",
        "outputId": "e612a581-98d7-44cb-f14e-d3e740cdec25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!pip install tensorboardcolab\n",
        "from tensorboardcolab import TensorBoardColab\n",
        "tb = TensorBoardColab()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://adb0bafe.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbsK2UWab4on",
        "colab_type": "code",
        "outputId": "37c806ef-c192-4ebd-ae39-08333dfdb90a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/gdrive/My\\ Drive"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0MiB9IBJjxI",
        "colab_type": "code",
        "outputId": "ed082787-0797-4375-9314-2fe97e2ee465",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "%ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'2019 AGES Student Declaration Form.pdf'   patch_images.ipynb\n",
            " abcdxyz.ipynb                             \u001b[0m\u001b[01;34mPETAI-master\u001b[0m/\n",
            "\u001b[01;34m'Anyfile Notepad Files'\u001b[0m/                  'Research Statement.pdf'\n",
            "'CV of Enaiyat Ghani Ovy.pdf'             \u001b[01;34m'Tannistha Maiti'\u001b[0m/\n",
            "'Getting started.pdf'                     'Unofficial Transcript.pdf'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5-h-z5hK7IA",
        "colab_type": "code",
        "outputId": "76ad4325-0540-4ce6-ef1c-7070fda86b78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd PETAI-master/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/PETAI-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP6IYje1LB2m",
        "colab_type": "code",
        "outputId": "9ce6b018-78c6-49cd-ca8c-3ea8db2bb7a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mcore\u001b[0m/  \u001b[01;34mdata\u001b[0m/  LICENSE  README.md  \u001b[01;34mruns\u001b[0m/  \u001b[01;34mtest\u001b[0m/  test.py  \u001b[01;34mtrainData\u001b[0m/  train.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDGQlof1OJQq",
        "colab_type": "code",
        "outputId": "1eba6f1d-3e19-4160-b3fb-baf8a0a812b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "pip install tensorboardX"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.17.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (45.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzJyNOebOTIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zZPiOMhNtYl",
        "colab_type": "code",
        "outputId": "b964a79a-10c8-420d-a059-4fa62fe20eda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python train.py --batch_size 32 --aug True --n_epoch 30"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "401 701 255\n",
            "99\n",
            "tcmalloc: large alloc 1951531008 bytes == 0x2b582000 @  0x7f5c0cc741e7 0x7f5c0a491f71 0x7f5c0a4f555d 0x7f5c0a4f5be7 0x7f5c0a58d898 0x50ac25 0x50d390 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x58958c 0x5a067e 0x7f5c0a4e106d 0x50a8af 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50d390 0x509d48 0x50aa7d 0x50c5b9 0x508245 0x509642 0x595311 0x54a6ff 0x551b81 0x5aa6ec 0x50abb3\n",
            "tcmalloc: large alloc 1951531008 bytes == 0xc1e5c000 @  0x7f5c0cc741e7 0x7f5c0a491f71 0x7f5c0a4f555d 0x7f5c0a4f5be7 0x7f5c0a58d898 0x50ac25 0x50d390 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x58958c 0x5a067e 0x7f5c0a4e106d 0x50a8af 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50d390 0x509d48 0x50aa7d 0x50c5b9 0x508245 0x509642 0x595311 0x54a6ff 0x551b81 0x5aa6ec 0x50abb3\n",
            "train.py:195: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
            "  torch.nn.utils.clip_grad_norm(model.parameters(), args.clip)\n",
            "Epoch [1/30] training Loss: 10.0690\n",
            "Epoch [1/30] training Loss: -116.4150\n",
            "Epoch [1/30] training Loss: -2774.1921\n",
            "Epoch [1/30] training Loss: -3262.8560\n",
            "Epoch [1/30] training Loss: -931.9158\n",
            "Epoch [1/30] training Loss: -3219.0383\n",
            "Epoch [1/30] training Loss: -572.5715\n",
            "Epoch [1/30] training Loss: -3654.4045\n",
            "Epoch [1/30] training Loss: -2510.3718\n",
            "Epoch [1/30] training Loss: 2362.9131\n",
            "Epoch [1/30] training Loss: -2198.4163\n",
            "Epoch [1/30] training Loss: -3845.4307\n",
            "Epoch [1/30] training Loss: 653.2673\n",
            "Epoch [1/30] training Loss: -783.2607\n",
            "Epoch [1/30] training Loss: -1272.6704\n",
            "Epoch [1/30] training Loss: -2887.8550\n",
            "Epoch [1/30] training Loss: -5142.1572\n",
            "Epoch [1/30] training Loss: -4048.0518\n",
            "Epoch [1/30] training Loss: -46162.9453\n",
            "Epoch [1/30] training Loss: -84085.8828\n",
            "Epoch [1/30] training Loss: -6371.5591\n",
            "Epoch [1/30] training Loss: 2059.1155\n",
            "Epoch [1/30] training Loss: -747.0987\n",
            "Epoch [1/30] training Loss: -1552.2789\n",
            "Epoch [1/30] training Loss: -4093.9106\n",
            "Epoch [1/30] training Loss: -14540.1445\n",
            "Epoch [1/30] training Loss: -8825.2988\n",
            "Epoch [1/30] training Loss: 436.0688\n",
            "Epoch [1/30] training Loss: -1927.4121\n",
            "Epoch [1/30] training Loss: -5075.3896\n",
            "Epoch [1/30] training Loss: 173423.1562\n",
            "Epoch [1/30] training Loss: 43029.8594\n",
            "Epoch [1/30] training Loss: -4271.5967\n",
            "Epoch [1/30] training Loss: -19878.1484\n",
            "Epoch [1/30] training Loss: 893.9635\n",
            "Epoch [1/30] training Loss: -5177.0605\n",
            "Epoch [1/30] training Loss: -394.3076\n",
            "Epoch [1/30] training Loss: 4842.1460\n",
            "Epoch [1/30] training Loss: -5181.9521\n",
            "Epoch [1/30] training Loss: -4794.0044\n",
            "Epoch [1/30] training Loss: -34448.9336\n",
            "Epoch [1/30] training Loss: 1616.4312\n",
            "Epoch [1/30] training Loss: -4420.9111\n",
            "Epoch [1/30] training Loss: -7707.2637\n",
            "Epoch [1/30] training Loss: -11154.0625\n",
            "Epoch [1/30] training Loss: -23999.7344\n",
            "Epoch [1/30] training Loss: 347.0319\n",
            "Epoch [1/30] training Loss: -7597.7817\n",
            "Epoch [1/30] training Loss: -2537.5945\n",
            "Epoch [1/30] training Loss: -3006.3911\n",
            "Epoch [1/30] training Loss: -17323.6094\n",
            "Epoch [1/30] training Loss: -6203.4277\n",
            "Epoch [1/30] training Loss: -36147.0234\n",
            "Epoch [1/30] training Loss: 2017.7936\n",
            "Epoch [1/30] training Loss: -3910.0620\n",
            "Epoch [1/30] training Loss: -7624.9448\n",
            "Epoch [1/30] training Loss: 18782.8555\n",
            "Epoch [1/30] training Loss: 1267.8914\n",
            "Epoch [1/30] training Loss: -3796.4268\n",
            "Epoch [1/30] training Loss: -6628.1855\n",
            "Epoch [1/30] training Loss: -24911.2070\n",
            "Epoch [1/30] training Loss: 1275.5375\n",
            "Epoch [1/30] training Loss: -6175.8716\n",
            "Epoch [1/30] training Loss: -33004.7305\n",
            "Epoch [1/30] training Loss: 231.1093\n",
            "Epoch [1/30] training Loss: -12274.4688\n",
            "Epoch [1/30] training Loss: 11111.0576\n",
            "Epoch [1/30] training Loss: 504.4060\n",
            "Epoch [1/30] training Loss: -6030.7871\n",
            "Epoch [1/30] training Loss: -3558.8604\n",
            "Epoch [1/30] training Loss: -5135.8545\n",
            "0it [00:00, ?it/s]Epoch [0/30] validation Loss: -3915.1968\n",
            "19it [00:01, 11.24it/s]Epoch [0/30] validation Loss: -4028.3757\n",
            "39it [00:03, 16.72it/s]Epoch [0/30] validation Loss: -3773.7786\n",
            "59it [00:04, 16.73it/s]Epoch [0/30] validation Loss: -3691.1650\n",
            "79it [00:05, 16.85it/s]Epoch [0/30] validation Loss: -3527.8059\n",
            "99it [00:06, 16.87it/s]Epoch [0/30] validation Loss: -3718.8555\n",
            "119it [00:07, 16.80it/s]Epoch [0/30] validation Loss: -3444.7725\n",
            "139it [00:09, 16.86it/s]Epoch [0/30] validation Loss: -3780.3845\n",
            "159it [00:10, 16.74it/s]Epoch [0/30] validation Loss: -4058.3770\n",
            "179it [00:11, 16.59it/s]Epoch [0/30] validation Loss: -3363.3801\n",
            "199it [00:12, 16.85it/s]Epoch [0/30] validation Loss: -3713.6511\n",
            "219it [00:13, 16.86it/s]Epoch [0/30] validation Loss: -3997.1467\n",
            "239it [00:14, 16.78it/s]Epoch [0/30] validation Loss: -3994.8547\n",
            "259it [00:16, 16.93it/s]Epoch [0/30] validation Loss: -4550.4517\n",
            "279it [00:17, 16.92it/s]Epoch [0/30] validation Loss: -4313.8896\n",
            "299it [00:18, 16.77it/s]Epoch [0/30] validation Loss: -4357.7178\n",
            "319it [00:19, 16.93it/s]Epoch [0/30] validation Loss: -4875.1934\n",
            "339it [00:20, 16.91it/s]Epoch [0/30] validation Loss: -4170.0234\n",
            "351it [00:21, 17.66it/s]\n",
            "Pixel Acc:  0.19509891200778928\n",
            "Class Accuracy:  [8.01221103e-01 1.71949637e-01 0.00000000e+00 3.62406378e-06\n",
            " 2.32103864e-02 4.14602570e-04]\n",
            "Mean Class Acc:  0.1661332254031194\n",
            "Freq Weighted IoU:  0.05471677014261323\n",
            "Mean IoU:  0.04952794027804422\n",
            "confusion_matrix [[1.6391697e+07 3.4652030e+06 0.0000000e+00 1.7400000e+02 6.0026400e+05\n",
            "  1.0560000e+03]\n",
            " [1.0153725e+07 2.1838780e+06 0.0000000e+00 1.7400000e+02 3.5885000e+05\n",
            "  4.0570000e+03]\n",
            " [4.1175727e+07 8.8587040e+06 0.0000000e+00 5.4800000e+02 1.4123090e+06\n",
            "  1.4496000e+04]\n",
            " [5.3146660e+06 1.1367540e+06 0.0000000e+00 2.4000000e+01 1.6859300e+05\n",
            "  2.3630000e+03]\n",
            " [2.2676180e+06 4.7554800e+05 0.0000000e+00 2.0000000e+00 6.5221000e+04\n",
            "  1.6030000e+03]\n",
            " [1.2026620e+06 2.5513900e+05 0.0000000e+00 6.0000000e+00 3.6981000e+04\n",
            "  6.2000000e+02]]\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DataParallel. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type SeismicNet. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type PReLU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ResidualBlock. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type TransposeResidualBlock. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ConvTranspose2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "Epoch [2/30] training Loss: -5255.2241\n",
            "Epoch [2/30] training Loss: -4986.4502\n",
            "Epoch [2/30] training Loss: 107176.0391\n",
            "Epoch [2/30] training Loss: -18673.2109\n",
            "Epoch [2/30] training Loss: 11382.2266\n",
            "Epoch [2/30] training Loss: 126.7565\n",
            "Epoch [2/30] training Loss: 1063.6853\n",
            "Epoch [2/30] training Loss: -4997.1816\n",
            "Epoch [2/30] training Loss: -3457.2446\n",
            "Epoch [2/30] training Loss: -8432.1709\n",
            "Epoch [2/30] training Loss: 13345.7227\n",
            "Epoch [2/30] training Loss: 508.9453\n",
            "Epoch [2/30] training Loss: -5431.9956\n",
            "Epoch [2/30] training Loss: -11022.0195\n",
            "Epoch [2/30] training Loss: 7273.3311\n",
            "Epoch [2/30] training Loss: -483.4850\n",
            "Epoch [2/30] training Loss: 617.1155\n",
            "Epoch [2/30] training Loss: -767.4235\n",
            "Epoch [2/30] training Loss: -2920.5745\n",
            "Epoch [2/30] training Loss: -3702.7690\n",
            "Epoch [2/30] training Loss: -5243.5034\n",
            "Epoch [2/30] training Loss: 2659.6624\n",
            "Epoch [2/30] training Loss: -1197.1853\n",
            "Epoch [2/30] training Loss: 2499.6465\n",
            "Epoch [2/30] training Loss: -3568.8872\n",
            "Epoch [2/30] training Loss: -15751.0557\n",
            "Epoch [2/30] training Loss: -967.7661\n",
            "Epoch [2/30] training Loss: 290.8938\n",
            "Epoch [2/30] training Loss: 11623.4150\n",
            "Epoch [2/30] training Loss: 3825.8787\n",
            "Epoch [2/30] training Loss: -1085.9308\n",
            "Epoch [2/30] training Loss: -11910.5498\n",
            "Epoch [2/30] training Loss: -5234.6704\n",
            "Epoch [2/30] training Loss: -1634.4880\n",
            "Epoch [2/30] training Loss: 15326.4717\n",
            "Epoch [2/30] training Loss: 2204.1306\n",
            "Epoch [2/30] training Loss: -24619.6895\n",
            "Epoch [2/30] training Loss: -724364.0625\n",
            "Epoch [2/30] training Loss: 909.4681\n",
            "Epoch [2/30] training Loss: -84639.0391\n",
            "Epoch [2/30] training Loss: 8923.9980\n",
            "Epoch [2/30] training Loss: -24459.5703\n",
            "Epoch [2/30] training Loss: -2979.8828\n",
            "Epoch [2/30] training Loss: 434629.8438\n",
            "Epoch [2/30] training Loss: 1992.8755\n",
            "Epoch [2/30] training Loss: -2967.4453\n",
            "Epoch [2/30] training Loss: -3403.7693\n",
            "Epoch [2/30] training Loss: -3961.2856\n",
            "Epoch [2/30] training Loss: -5221.4077\n",
            "Epoch [2/30] training Loss: -5192.1924\n",
            "Epoch [2/30] training Loss: 7403.4897\n",
            "Epoch [2/30] training Loss: 180.2071\n",
            "Epoch [2/30] training Loss: -943.1102\n",
            "Epoch [2/30] training Loss: -2525.9429\n",
            "Epoch [2/30] training Loss: -3008.6074\n",
            "Epoch [2/30] training Loss: -3056.9507\n",
            "Epoch [2/30] training Loss: -3096.2539\n",
            "Epoch [2/30] training Loss: -3284.3086\n",
            "Epoch [2/30] training Loss: -9653.5225\n",
            "Epoch [2/30] training Loss: -794.7148\n",
            "Epoch [2/30] training Loss: -2781.9983\n",
            "Epoch [2/30] training Loss: -3221.0974\n",
            "Epoch [2/30] training Loss: -3810.5535\n",
            "Epoch [2/30] training Loss: 10206.2305\n",
            "Epoch [2/30] training Loss: 6500.7002\n",
            "Epoch [2/30] training Loss: -2609.6904\n",
            "Epoch [2/30] training Loss: 12201.2559\n",
            "Epoch [2/30] training Loss: 70225.7031\n",
            "Epoch [2/30] training Loss: -13464.7598\n",
            "Epoch [2/30] training Loss: 11034.3574\n",
            "Epoch [2/30] training Loss: -11391.4189\n",
            "0it [00:00, ?it/s]Epoch [1/30] validation Loss: 3858.0754\n",
            "19it [00:01, 11.24it/s]Epoch [1/30] validation Loss: 3408.2573\n",
            "39it [00:03, 16.78it/s]Epoch [1/30] validation Loss: 6123.4189\n",
            "59it [00:04, 17.04it/s]Epoch [1/30] validation Loss: 38030.7305\n",
            "79it [00:05, 16.97it/s]Epoch [1/30] validation Loss: 5642.5518\n",
            "99it [00:06, 16.86it/s]Epoch [1/30] validation Loss: 14000.3984\n",
            "119it [00:07, 16.57it/s]Epoch [1/30] validation Loss: 32945.7930\n",
            "139it [00:08, 16.84it/s]Epoch [1/30] validation Loss: 6697.5513\n",
            "159it [00:10, 16.85it/s]Epoch [1/30] validation Loss: 3176.7759\n",
            "179it [00:11, 16.95it/s]Epoch [1/30] validation Loss: -27316.0215\n",
            "199it [00:12, 16.93it/s]Epoch [1/30] validation Loss: 11265.3203\n",
            "219it [00:13, 16.98it/s]Epoch [1/30] validation Loss: 3447.9832\n",
            "239it [00:14, 16.90it/s]Epoch [1/30] validation Loss: 3447.5859\n",
            "259it [00:16, 16.81it/s]Epoch [1/30] validation Loss: 1717.3430\n",
            "279it [00:17, 16.88it/s]Epoch [1/30] validation Loss: 2357.9490\n",
            "299it [00:18, 16.86it/s]Epoch [1/30] validation Loss: 2219.4368\n",
            "319it [00:19, 16.82it/s]Epoch [1/30] validation Loss: 1588.4159\n",
            "339it [00:20, 16.69it/s]Epoch [1/30] validation Loss: 2426.0745\n",
            "351it [00:21, 17.56it/s]\n",
            "Pixel Acc:  0.07362666156434508\n",
            "Class Accuracy:  [0.07228065 0.00671877 0.00160661 0.74175178 0.16939336 0.        ]\n",
            "Mean Class Acc:  0.16529186292121645\n",
            "Freq Weighted IoU:  0.019396505856755453\n",
            "Mean IoU:  0.026297048248176552\n",
            "confusion_matrix [[1.4787460e+06 1.1674000e+05 3.3076000e+04 1.5284869e+07 3.5449630e+06\n",
            "  0.0000000e+00]\n",
            " [8.5540600e+05 8.5333000e+04 2.1004000e+04 9.5361310e+06 2.2028100e+06\n",
            "  0.0000000e+00]\n",
            " [3.5755140e+06 3.4381300e+05 8.2679000e+04 3.8542876e+07 8.9169020e+06\n",
            "  0.0000000e+00]\n",
            " [5.1632400e+05 4.4601000e+04 1.0346000e+04 4.9121770e+06 1.1389520e+06\n",
            "  0.0000000e+00]\n",
            " [2.5863200e+05 1.8839000e+04 4.3070000e+03 2.0522200e+06 4.7599400e+05\n",
            "  0.0000000e+00]\n",
            " [1.2165600e+05 9.9130000e+03 2.2870000e+03 1.1059250e+06 2.5562700e+05\n",
            "  0.0000000e+00]]\n",
            "Epoch [3/30] training Loss: -11569.7080\n",
            "Epoch [3/30] training Loss: 3664.6816\n",
            "Epoch [3/30] training Loss: 8777.5742\n",
            "Epoch [3/30] training Loss: -28458.8535\n",
            "Epoch [3/30] training Loss: 6196.6587\n",
            "Epoch [3/30] training Loss: 1427.2383\n",
            "Epoch [3/30] training Loss: -5424.7021\n",
            "Epoch [3/30] training Loss: -8738.3867\n",
            "Epoch [3/30] training Loss: 4139.0317\n",
            "Epoch [3/30] training Loss: 394.3759\n",
            "Epoch [3/30] training Loss: -2134.5625\n",
            "Epoch [3/30] training Loss: -9676.0625\n",
            "Epoch [3/30] training Loss: -21348.4375\n",
            "Epoch [3/30] training Loss: 3750.0862\n",
            "Epoch [3/30] training Loss: 484.9437\n",
            "Epoch [3/30] training Loss: -1547.8247\n",
            "Epoch [3/30] training Loss: -7073.6631\n",
            "Epoch [3/30] training Loss: 13376.5029\n",
            "Epoch [3/30] training Loss: -2600.1472\n",
            "Epoch [3/30] training Loss: -39782.3867\n",
            "Epoch [3/30] training Loss: 6170.2822\n",
            "Epoch [3/30] training Loss: 1596.5369\n",
            "Epoch [3/30] training Loss: -2195.9492\n",
            "Epoch [3/30] training Loss: -12520.2725\n",
            "Epoch [3/30] training Loss: 58203.8516\n",
            "Epoch [3/30] training Loss: 81679.1875\n",
            "Epoch [3/30] training Loss: 3968.0056\n",
            "Epoch [3/30] training Loss: 1944.7454\n",
            "Epoch [3/30] training Loss: 4462.0996\n",
            "Epoch [3/30] training Loss: 4529.0391\n",
            "Epoch [3/30] training Loss: 1723.2664\n",
            "Epoch [3/30] training Loss: -5487.6963\n",
            "Epoch [3/30] training Loss: 1863.2649\n",
            "Epoch [3/30] training Loss: -290.8477\n",
            "Epoch [3/30] training Loss: 34123.1094\n",
            "Epoch [3/30] training Loss: -2620.4680\n",
            "Epoch [3/30] training Loss: -102286.1875\n",
            "Epoch [3/30] training Loss: 2568.1597\n",
            "Epoch [3/30] training Loss: -19107.0117\n",
            "Epoch [3/30] training Loss: 25334.7266\n",
            "Epoch [3/30] training Loss: -34240.5312\n",
            "Epoch [3/30] training Loss: -962.0172\n",
            "Epoch [3/30] training Loss: 8483.8271\n",
            "Epoch [3/30] training Loss: 1616.3157\n",
            "Epoch [3/30] training Loss: 8470.4707\n",
            "Epoch [3/30] training Loss: -4144.6255\n",
            "Epoch [3/30] training Loss: 7451.3135\n",
            "Epoch [3/30] training Loss: 2552.9058\n",
            "Epoch [3/30] training Loss: 16963.4883\n",
            "Epoch [3/30] training Loss: 1175.9508\n",
            "Epoch [3/30] training Loss: -1067.2206\n",
            "Epoch [3/30] training Loss: 255.7686\n",
            "Epoch [3/30] training Loss: -4155.5459\n",
            "Epoch [3/30] training Loss: 11983.3320\n",
            "Epoch [3/30] training Loss: -397.0615\n",
            "Epoch [3/30] training Loss: 2029.8972\n",
            "Epoch [3/30] training Loss: -5755.6187\n",
            "Epoch [3/30] training Loss: -2800.3362\n",
            "Epoch [3/30] training Loss: -8551.1787\n",
            "Epoch [3/30] training Loss: -5414.0869\n",
            "Epoch [3/30] training Loss: 11157.7148\n",
            "Epoch [3/30] training Loss: -862.2175\n",
            "Epoch [3/30] training Loss: -9347.3906\n",
            "Epoch [3/30] training Loss: 2729.9587\n",
            "Epoch [3/30] training Loss: -24346.6914\n",
            "Epoch [3/30] training Loss: -1338.6615\n",
            "Epoch [3/30] training Loss: -2183.6711\n",
            "Epoch [3/30] training Loss: 3065.4609\n",
            "Epoch [3/30] training Loss: 6694.7388\n",
            "Epoch [3/30] training Loss: -5368.1157\n",
            "Epoch [3/30] training Loss: -1371.7843\n",
            "0it [00:00, ?it/s]Epoch [2/30] validation Loss: -1006.6823\n",
            "19it [00:01, 11.12it/s]Epoch [2/30] validation Loss: -735.5970\n",
            "39it [00:03, 16.72it/s]Epoch [2/30] validation Loss: -1113.6003\n",
            "59it [00:04, 16.95it/s]Epoch [2/30] validation Loss: -1068.4657\n",
            "79it [00:05, 16.98it/s]Epoch [2/30] validation Loss: -1271.7407\n",
            "99it [00:06, 16.98it/s]Epoch [2/30] validation Loss: -937.7036\n",
            "119it [00:07, 16.91it/s]Epoch [2/30] validation Loss: -1179.5269\n",
            "139it [00:08, 16.76it/s]Epoch [2/30] validation Loss: -1123.6055\n",
            "159it [00:10, 16.85it/s]Epoch [2/30] validation Loss: -789.3175\n",
            "179it [00:11, 16.64it/s]Epoch [2/30] validation Loss: -1408.2394\n",
            "199it [00:12, 16.83it/s]Epoch [2/30] validation Loss: -1150.9548\n",
            "219it [00:13, 16.73it/s]Epoch [2/30] validation Loss: -934.7034\n",
            "239it [00:14, 16.84it/s]Epoch [2/30] validation Loss: -933.3850\n",
            "259it [00:16, 16.80it/s]Epoch [2/30] validation Loss: -917.8972\n",
            "279it [00:17, 16.82it/s]Epoch [2/30] validation Loss: -656.2007\n",
            "299it [00:18, 16.89it/s]Epoch [2/30] validation Loss: -710.8242\n",
            "319it [00:19, 16.94it/s]Epoch [2/30] validation Loss: -634.1761\n",
            "339it [00:20, 16.90it/s]Epoch [2/30] validation Loss: -984.4181\n",
            "351it [00:21, 17.57it/s]\n",
            "Pixel Acc:  0.17456375265621196\n",
            "Class Accuracy:  [0.76951685 0.00597802 0.00160008 0.04346929 0.1736763  0.00139494]\n",
            "Mean Class Acc:  0.1659392463089139\n",
            "Freq Weighted IoU:  0.04742255705130395\n",
            "Mean IoU:  0.0437657303249073\n",
            "confusion_matrix [[1.5743079e+07 1.0618800e+05 3.3540000e+04 8.7264100e+05 3.6844050e+06\n",
            "  1.8541000e+04]\n",
            " [9.7328490e+06 7.5925000e+04 2.1148000e+04 5.7437600e+05 2.2808880e+06\n",
            "  1.5498000e+04]\n",
            " [3.9507533e+07 3.0306700e+05 8.2343000e+04 2.2761270e+06 9.2278550e+06\n",
            "  6.4859000e+04]\n",
            " [5.1028040e+06 3.9544000e+04 1.0213000e+04 2.8787100e+05 1.1727780e+06\n",
            "  9.1900000e+03]\n",
            " [2.1756780e+06 1.7283000e+04 4.3300000e+03 1.2036200e+05 4.8802900e+05\n",
            "  4.3100000e+03]\n",
            " [1.1550890e+06 8.8850000e+03 2.2860000e+03 6.3996000e+04 2.6306600e+05\n",
            "  2.0860000e+03]]\n",
            "Epoch [4/30] training Loss: -2246.1028\n",
            "Epoch [4/30] training Loss: -20232.9961\n",
            "Epoch [4/30] training Loss: -3492.8765\n",
            "Epoch [4/30] training Loss: -2743.7874\n",
            "Epoch [4/30] training Loss: -4703.2622\n",
            "Epoch [4/30] training Loss: -6670.9360\n",
            "Epoch [4/30] training Loss: -3232.1436\n",
            "Epoch [4/30] training Loss: 15089.4453\n",
            "Epoch [4/30] training Loss: 5242.1357\n",
            "Epoch [4/30] training Loss: -500.6539\n",
            "Epoch [4/30] training Loss: -1432.0566\n",
            "Epoch [4/30] training Loss: -3454.3940\n",
            "Epoch [4/30] training Loss: -9986.2637\n",
            "Epoch [4/30] training Loss: 690.1285\n",
            "Epoch [4/30] training Loss: -24789.6758\n",
            "Epoch [4/30] training Loss: -95.5990\n",
            "Epoch [4/30] training Loss: 12565.2080\n",
            "Epoch [4/30] training Loss: -8061.0508\n",
            "Epoch [4/30] training Loss: -4866.2656\n",
            "Epoch [4/30] training Loss: 499.1331\n",
            "Epoch [4/30] training Loss: 1929.0907\n",
            "Epoch [4/30] training Loss: -9397.7734\n",
            "Epoch [4/30] training Loss: 1336.0364\n",
            "Epoch [4/30] training Loss: -989.6201\n",
            "Epoch [4/30] training Loss: -1265.9271\n",
            "Epoch [4/30] training Loss: -262.0095\n",
            "Epoch [4/30] training Loss: -3012.9231\n",
            "Epoch [4/30] training Loss: 10362.0684\n",
            "Epoch [4/30] training Loss: -2506.7124\n",
            "Epoch [4/30] training Loss: -2399.5422\n",
            "Epoch [4/30] training Loss: -584.4396\n",
            "Epoch [4/30] training Loss: -611.8120\n",
            "Epoch [4/30] training Loss: -6040.0293\n",
            "Epoch [4/30] training Loss: -1722.7219\n",
            "Epoch [4/30] training Loss: 2681.4426\n",
            "Epoch [4/30] training Loss: -2914.0312\n",
            "Epoch [4/30] training Loss: -449.4459\n",
            "Epoch [4/30] training Loss: -2603.3794\n",
            "Epoch [4/30] training Loss: 3575.7749\n",
            "Epoch [4/30] training Loss: -1424.9086\n",
            "Epoch [4/30] training Loss: 38631.1562\n",
            "Epoch [4/30] training Loss: -1813.7980\n",
            "Epoch [4/30] training Loss: -100283.1484\n",
            "Epoch [4/30] training Loss: -1949.0382\n",
            "Epoch [4/30] training Loss: -8082.4189\n",
            "Epoch [4/30] training Loss: -1500.7771\n",
            "Epoch [4/30] training Loss: -175.2061\n",
            "Epoch [4/30] training Loss: -2405.6812\n",
            "Epoch [4/30] training Loss: -5485.6392\n",
            "Epoch [4/30] training Loss: -1708.1837\n",
            "Epoch [4/30] training Loss: -617.9935\n",
            "Epoch [4/30] training Loss: -2295.5479\n",
            "Epoch [4/30] training Loss: -3772.0059\n",
            "Epoch [4/30] training Loss: -1429.7900\n",
            "Epoch [4/30] training Loss: 500.1714\n",
            "Epoch [4/30] training Loss: 3027.6692\n",
            "Epoch [4/30] training Loss: 3235.6907\n",
            "Epoch [4/30] training Loss: -375.0950\n",
            "Epoch [4/30] training Loss: -1916.9365\n",
            "Epoch [4/30] training Loss: 2681086.5000\n",
            "Epoch [4/30] training Loss: 1000.5515\n",
            "Epoch [4/30] training Loss: -2429.1746\n",
            "Epoch [4/30] training Loss: 924.4791\n",
            "Epoch [4/30] training Loss: -20269.4316\n",
            "Epoch [4/30] training Loss: -1889.3639\n",
            "Epoch [4/30] training Loss: 23181.3398\n",
            "Epoch [4/30] training Loss: 3610.0894\n",
            "Epoch [4/30] training Loss: 17664.3125\n",
            "Epoch [4/30] training Loss: 1642.1433\n",
            "Epoch [4/30] training Loss: -2315.2598\n",
            "Epoch [4/30] training Loss: -12618.7031\n",
            "0it [00:00, ?it/s]Epoch [3/30] validation Loss: -180.0689\n",
            "19it [00:01, 11.07it/s]Epoch [3/30] validation Loss: -142.8805\n",
            "39it [00:03, 16.59it/s]Epoch [3/30] validation Loss: -211.3984\n",
            "59it [00:04, 16.82it/s]Epoch [3/30] validation Loss: -207.6787\n",
            "79it [00:05, 16.79it/s]Epoch [3/30] validation Loss: -276.7375\n",
            "99it [00:06, 16.74it/s]Epoch [3/30] validation Loss: -189.3607\n",
            "119it [00:07, 16.77it/s]Epoch [3/30] validation Loss: -273.5452\n",
            "139it [00:09, 16.85it/s]Epoch [3/30] validation Loss: -205.9498\n",
            "159it [00:10, 16.76it/s]Epoch [3/30] validation Loss: -146.2783\n",
            "179it [00:11, 16.84it/s]Epoch [3/30] validation Loss: -357.0103\n",
            "199it [00:12, 16.72it/s]Epoch [3/30] validation Loss: -220.1371\n",
            "219it [00:13, 16.80it/s]Epoch [3/30] validation Loss: -165.0240\n",
            "239it [00:15, 16.81it/s]Epoch [3/30] validation Loss: -165.4934\n",
            "259it [00:16, 16.77it/s]Epoch [3/30] validation Loss: -147.3049\n",
            "279it [00:17, 16.60it/s]Epoch [3/30] validation Loss: -124.7056\n",
            "299it [00:18, 16.83it/s]Epoch [3/30] validation Loss: -126.2800\n",
            "319it [00:19, 16.74it/s]Epoch [3/30] validation Loss: -109.6543\n",
            "339it [00:20, 16.80it/s]Epoch [3/30] validation Loss: -165.7616\n",
            "351it [00:21, 17.42it/s]\n",
            "Pixel Acc:  0.17626147397019543\n",
            "Class Accuracy:  [0.79482632 0.00160377 0.00131047 0.02828823 0.02948727 0.14890585]\n",
            "Mean Class Acc:  0.1674036525949774\n",
            "Freq Weighted IoU:  0.046701024206735435\n",
            "Mean IoU:  0.042830840137117736\n",
            "confusion_matrix [[1.6260870e+07 2.0668000e+04 2.9580000e+04 3.7308600e+05 6.6780000e+05\n",
            "  3.1063900e+06]\n",
            " [1.0028362e+07 2.0369000e+04 1.7637000e+04 2.9139900e+05 4.2924800e+05\n",
            "  1.9136690e+06]\n",
            " [4.0681855e+07 8.0483000e+04 6.7439000e+04 1.0475200e+06 1.7189130e+06\n",
            "  7.8655740e+06]\n",
            " [5.2461540e+06 1.0976000e+04 7.3800000e+03 1.8733600e+05 2.0986600e+05\n",
            "  9.6068800e+05]\n",
            " [2.2323980e+06 4.6760000e+03 2.8760000e+03 7.5617000e+04 8.2859000e+04\n",
            "  4.1156600e+05]\n",
            " [1.1861120e+06 2.4500000e+03 1.8020000e+03 3.6373000e+04 4.5996000e+04\n",
            "  2.2267500e+05]]\n",
            "Epoch [5/30] training Loss: -15951.0156\n",
            "Epoch [5/30] training Loss: -1238.6853\n",
            "Epoch [5/30] training Loss: 662.6556\n",
            "Epoch [5/30] training Loss: -8162.7393\n",
            "Epoch [5/30] training Loss: -1430.3025\n",
            "Epoch [5/30] training Loss: 359.1667\n",
            "Epoch [5/30] training Loss: -4871.5850\n",
            "Epoch [5/30] training Loss: -4454.7461\n",
            "Epoch [5/30] training Loss: -4035.5317\n",
            "Epoch [5/30] training Loss: -2346.4629\n",
            "Epoch [5/30] training Loss: -1229.1566\n",
            "Epoch [5/30] training Loss: 26354.6074\n",
            "Epoch [5/30] training Loss: -1546.0834\n",
            "Epoch [5/30] training Loss: -1198.0867\n",
            "Epoch [5/30] training Loss: -3515.7910\n",
            "Epoch [5/30] training Loss: -500.0627\n",
            "Epoch [5/30] training Loss: 969.3940\n",
            "Epoch [5/30] training Loss: -909.3221\n",
            "Epoch [5/30] training Loss: -2788.6890\n",
            "Epoch [5/30] training Loss: 4608.6113\n",
            "Epoch [5/30] training Loss: -1688.0208\n",
            "Epoch [5/30] training Loss: -6797.5942\n",
            "Epoch [5/30] training Loss: 258.1090\n",
            "Epoch [5/30] training Loss: -1140.9751\n",
            "Epoch [5/30] training Loss: -2918.6707\n",
            "Epoch [5/30] training Loss: -3589.0718\n",
            "Epoch [5/30] training Loss: 789.9866\n",
            "Epoch [5/30] training Loss: -24697.1328\n",
            "Epoch [5/30] training Loss: -1545.0392\n",
            "Epoch [5/30] training Loss: -3305.2539\n",
            "Epoch [5/30] training Loss: -467.0299\n",
            "Epoch [5/30] training Loss: -963.2620\n",
            "Epoch [5/30] training Loss: -2877.8926\n",
            "Epoch [5/30] training Loss: -3257.8435\n",
            "Epoch [5/30] training Loss: -330.6750\n",
            "Epoch [5/30] training Loss: -1764.6316\n",
            "Epoch [5/30] training Loss: 134.4396\n",
            "Epoch [5/30] training Loss: -620.5469\n",
            "Epoch [5/30] training Loss: -2013.1893\n",
            "Epoch [5/30] training Loss: -3016.4958\n",
            "Epoch [5/30] training Loss: -4075.1245\n",
            "Epoch [5/30] training Loss: -1732.5354\n",
            "Epoch [5/30] training Loss: 3213.9287\n",
            "Epoch [5/30] training Loss: -4555.5581\n",
            "Epoch [5/30] training Loss: -726.2110\n",
            "Epoch [5/30] training Loss: -1710.3621\n",
            "Epoch [5/30] training Loss: -3147.3674\n",
            "Epoch [5/30] training Loss: -2157.1116\n",
            "Epoch [5/30] training Loss: -995.6962\n",
            "Epoch [5/30] training Loss: -399.1376\n",
            "Epoch [5/30] training Loss: 1149.4199\n",
            "Epoch [5/30] training Loss: -1411.4568\n",
            "Epoch [5/30] training Loss: -4589.5952\n",
            "Epoch [5/30] training Loss: -26269.9609\n",
            "Epoch [5/30] training Loss: -8441.0791\n",
            "Epoch [5/30] training Loss: -587.4237\n",
            "Epoch [5/30] training Loss: -4438.8643\n",
            "Epoch [5/30] training Loss: -14345.5146\n",
            "Epoch [5/30] training Loss: 493.9316\n",
            "Epoch [5/30] training Loss: -33213.7578\n",
            "Epoch [5/30] training Loss: 2275.7100\n",
            "Epoch [5/30] training Loss: 328.9662\n",
            "Epoch [5/30] training Loss: -723.6528\n",
            "Epoch [5/30] training Loss: -3443.5161\n",
            "Epoch [5/30] training Loss: -4854.9751\n",
            "Epoch [5/30] training Loss: -4449.3877\n",
            "Epoch [5/30] training Loss: 248.6568\n",
            "Epoch [5/30] training Loss: 1540.5564\n",
            "Epoch [5/30] training Loss: -870.3101\n",
            "Epoch [5/30] training Loss: -4060.5698\n",
            "Epoch [5/30] training Loss: 97.7147\n",
            "0it [00:00, ?it/s]Epoch [4/30] validation Loss: 6369.2671\n",
            "19it [00:01, 11.15it/s]Epoch [4/30] validation Loss: 8536.2930\n",
            "39it [00:03, 16.50it/s]Epoch [4/30] validation Loss: -10347.0791\n",
            "59it [00:04, 16.83it/s]Epoch [4/30] validation Loss: -36671.2383\n",
            "79it [00:05, 16.91it/s]Epoch [4/30] validation Loss: 8664.8740\n",
            "99it [00:06, 16.84it/s]Epoch [4/30] validation Loss: -193560.6562\n",
            "119it [00:07, 16.92it/s]Epoch [4/30] validation Loss: -8221.1533\n",
            "139it [00:09, 16.95it/s]Epoch [4/30] validation Loss: -17815.1582\n",
            "159it [00:10, 16.90it/s]Epoch [4/30] validation Loss: 12015.0645\n",
            "179it [00:11, 16.67it/s]Epoch [4/30] validation Loss: -8970.1025\n",
            "199it [00:12, 16.84it/s]Epoch [4/30] validation Loss: -9175.8584\n",
            "219it [00:13, 16.67it/s]Epoch [4/30] validation Loss: -509383.2188\n",
            "239it [00:14, 16.81it/s]Epoch [4/30] validation Loss: 259266.4531\n",
            "259it [00:16, 16.83it/s]Epoch [4/30] validation Loss: -34973.0703\n",
            "279it [00:17, 16.74it/s]Epoch [4/30] validation Loss: 5212.7285\n",
            "299it [00:18, 16.76it/s]Epoch [4/30] validation Loss: 6730.3799\n",
            "319it [00:19, 16.66it/s]Epoch [4/30] validation Loss: 4279.2095\n",
            "339it [00:20, 16.82it/s]Epoch [4/30] validation Loss: -21056.7891\n",
            "351it [00:21, 17.47it/s]\n",
            "Pixel Acc:  0.1821198919562055\n",
            "Class Accuracy:  [7.84091263e-01 4.34700997e-04 3.31941466e-03 1.62886114e-01\n",
            " 1.98441846e-02 3.29415116e-02]\n",
            "Mean Class Acc:  0.1672528648568058\n",
            "Freq Weighted IoU:  0.04961110279469211\n",
            "Mean IoU:  0.04683813206751499\n",
            "confusion_matrix [[1.6041248e+07 1.0060000e+04 4.2839000e+04 2.8837230e+06 6.4591800e+05\n",
            "  8.3460600e+05]\n",
            " [9.8715160e+06 5.5210000e+03 3.1921000e+04 1.9613460e+06 3.5084000e+05\n",
            "  4.7954000e+05]\n",
            " [3.9969964e+07 2.3399000e+04 1.7082300e+05 8.0558600e+06 1.3384260e+06\n",
            "  1.9033120e+06]\n",
            " [5.1255420e+06 2.1780000e+03 4.3622000e+04 1.0786970e+06 1.4995100e+05\n",
            "  2.2241000e+05]\n",
            " [2.1663280e+06 6.2000000e+02 3.3781000e+04 4.6742600e+05 5.5762000e+04\n",
            "  8.6075000e+04]\n",
            " [1.1577780e+06 4.3900000e+02 1.1740000e+04 2.4365300e+05 3.2537000e+04\n",
            "  4.9261000e+04]]\n",
            "Epoch [6/30] training Loss: -110.1656\n",
            "Epoch [6/30] training Loss: 2156.9834\n",
            "Epoch [6/30] training Loss: -1329.3892\n",
            "Epoch [6/30] training Loss: 289.7664\n",
            "Epoch [6/30] training Loss: -934.1742\n",
            "Epoch [6/30] training Loss: -3254.7800\n",
            "Epoch [6/30] training Loss: -3762.1057\n",
            "Epoch [6/30] training Loss: -7289.9565\n",
            "Epoch [6/30] training Loss: -19759.7402\n",
            "Epoch [6/30] training Loss: 1656.7766\n",
            "Epoch [6/30] training Loss: -888.3078\n",
            "Epoch [6/30] training Loss: -2824.0068\n",
            "Epoch [6/30] training Loss: -1084.8523\n",
            "Epoch [6/30] training Loss: -3952.0601\n",
            "Epoch [6/30] training Loss: 125.6604\n",
            "Epoch [6/30] training Loss: -253.6012\n",
            "Epoch [6/30] training Loss: -1245.6787\n",
            "Epoch [6/30] training Loss: -952.2642\n",
            "Epoch [6/30] training Loss: -2121.7786\n",
            "Epoch [6/30] training Loss: -1008.0961\n",
            "Epoch [6/30] training Loss: -857.9202\n",
            "Epoch [6/30] training Loss: -1492.1548\n",
            "Epoch [6/30] training Loss: -2196.6326\n",
            "Epoch [6/30] training Loss: -3080.7615\n",
            "Epoch [6/30] training Loss: -4716.3765\n",
            "Epoch [6/30] training Loss: -2177.1633\n",
            "Epoch [6/30] training Loss: -5643.4375\n",
            "Epoch [6/30] training Loss: -1919.1565\n",
            "Epoch [6/30] training Loss: -831.4098\n",
            "Epoch [6/30] training Loss: -3333.8320\n",
            "Epoch [6/30] training Loss: -1955.8479\n",
            "Epoch [6/30] training Loss: -4634.1108\n",
            "Epoch [6/30] training Loss: 3149.5659\n",
            "Epoch [6/30] training Loss: -550.5778\n",
            "Epoch [6/30] training Loss: -734.0831\n",
            "Epoch [6/30] training Loss: -3005.5503\n",
            "Epoch [6/30] training Loss: -3399.7798\n",
            "Epoch [6/30] training Loss: -1074.9573\n",
            "Epoch [6/30] training Loss: -1574.9460\n",
            "Epoch [6/30] training Loss: -1530.0417\n",
            "Epoch [6/30] training Loss: 3888.1885\n",
            "Epoch [6/30] training Loss: -2594.3228\n",
            "Epoch [6/30] training Loss: -4326.3350\n",
            "Epoch [6/30] training Loss: -2017.0963\n",
            "Epoch [6/30] training Loss: -3873.4207\n",
            "Epoch [6/30] training Loss: 566.3170\n",
            "Epoch [6/30] training Loss: -1377.3857\n",
            "Epoch [6/30] training Loss: -867.8605\n",
            "Epoch [6/30] training Loss: -1993.9182\n",
            "Epoch [6/30] training Loss: -263.9794\n",
            "Epoch [6/30] training Loss: -1848.6462\n",
            "Epoch [6/30] training Loss: -3166.6799\n",
            "Epoch [6/30] training Loss: -3918.5264\n",
            "Epoch [6/30] training Loss: -5027.3086\n",
            "Epoch [6/30] training Loss: -8073.5322\n",
            "Epoch [6/30] training Loss: -61177.1250\n",
            "Epoch [6/30] training Loss: -1407.7986\n",
            "Epoch [6/30] training Loss: -2724.3237\n",
            "Epoch [6/30] training Loss: -2432.9482\n",
            "Epoch [6/30] training Loss: 595.4445\n",
            "Epoch [6/30] training Loss: -13471.9580\n",
            "Epoch [6/30] training Loss: -1279.2273\n",
            "Epoch [6/30] training Loss: 1820.8083\n",
            "Epoch [6/30] training Loss: -613.2355\n",
            "Epoch [6/30] training Loss: -1858.4452\n",
            "Epoch [6/30] training Loss: -1350.4518\n",
            "Epoch [6/30] training Loss: -5486.7261\n",
            "Epoch [6/30] training Loss: -2829.4087\n",
            "Epoch [6/30] training Loss: -2577.9651\n",
            "Epoch [6/30] training Loss: 5645.3711\n",
            "Epoch [6/30] training Loss: -1333.0426\n",
            "0it [00:00, ?it/s]Epoch [5/30] validation Loss: -307.8686\n",
            "19it [00:01, 11.11it/s]Epoch [5/30] validation Loss: -260.8095\n",
            "39it [00:03, 16.69it/s]Epoch [5/30] validation Loss: -343.9635\n",
            "59it [00:04, 16.89it/s]Epoch [5/30] validation Loss: -370.8458\n",
            "79it [00:05, 16.89it/s]Epoch [5/30] validation Loss: -446.6556\n",
            "99it [00:06, 16.95it/s]Epoch [5/30] validation Loss: -331.1664\n",
            "119it [00:07, 16.92it/s]Epoch [5/30] validation Loss: -467.3174\n",
            "139it [00:08, 16.87it/s]Epoch [5/30] validation Loss: -375.4883\n",
            "159it [00:10, 16.79it/s]Epoch [5/30] validation Loss: -263.4952\n",
            "179it [00:11, 16.72it/s]Epoch [5/30] validation Loss: -548.3703\n",
            "199it [00:12, 16.83it/s]Epoch [5/30] validation Loss: -378.1857\n",
            "219it [00:13, 16.80it/s]Epoch [5/30] validation Loss: -306.5040\n",
            "239it [00:14, 16.79it/s]Epoch [5/30] validation Loss: -304.8116\n",
            "259it [00:16, 16.90it/s]Epoch [5/30] validation Loss: -248.2987\n",
            "279it [00:17, 16.90it/s]Epoch [5/30] validation Loss: -229.0579\n",
            "299it [00:18, 16.85it/s]Epoch [5/30] validation Loss: -229.4624\n",
            "319it [00:19, 16.67it/s]Epoch [5/30] validation Loss: -201.0953\n",
            "339it [00:20, 16.77it/s]Epoch [5/30] validation Loss: -278.9871\n",
            "351it [00:21, 17.30it/s]\n",
            "Pixel Acc:  0.17674125044262787\n",
            "Class Accuracy:  [0.76548203 0.00558269 0.00613673 0.05215209 0.17526989 0.00151597]\n",
            "Mean Class Acc:  0.16768990160361022\n",
            "Freq Weighted IoU:  0.05005090938697612\n",
            "Mean IoU:  0.04517503446975379\n",
            "confusion_matrix [[1.5660533e+07 8.7318000e+04 1.1949500e+05 1.0935180e+06 3.4780240e+06\n",
            "  1.9506000e+04]\n",
            " [9.6687170e+06 7.0904000e+04 8.0433000e+04 7.2251800e+05 2.1418770e+06\n",
            "  1.6235000e+04]\n",
            " [3.9223457e+07 2.7260800e+05 3.1580700e+05 2.8531770e+06 8.7279580e+06\n",
            "  6.8777000e+04]\n",
            " [5.0530960e+06 3.2828000e+04 3.9762000e+04 3.4537200e+05 1.1415520e+06\n",
            "  9.7900000e+03]\n",
            " [2.1430290e+06 1.4123000e+04 1.7051000e+04 1.3846800e+05 4.9250700e+05\n",
            "  4.8140000e+03]\n",
            " [1.1422600e+06 7.4380000e+03 8.8970000e+03 7.6617000e+04 2.5792900e+05\n",
            "  2.2670000e+03]]\n",
            "Epoch [7/30] training Loss: -1671.3671\n",
            "Epoch [7/30] training Loss: -2888.6953\n",
            "Epoch [7/30] training Loss: -3150.3962\n",
            "Epoch [7/30] training Loss: -3842.9131\n",
            "Epoch [7/30] training Loss: -1602.7561\n",
            "Epoch [7/30] training Loss: 532.0756\n",
            "Epoch [7/30] training Loss: -2670.8262\n",
            "Epoch [7/30] training Loss: -5917.6069\n",
            "Epoch [7/30] training Loss: 347.5846\n",
            "Epoch [7/30] training Loss: -1041.9993\n",
            "Epoch [7/30] training Loss: -2047.2356\n",
            "Epoch [7/30] training Loss: -2800.8723\n",
            "Epoch [7/30] training Loss: -2948.9419\n",
            "Epoch [7/30] training Loss: -3059.3633\n",
            "Epoch [7/30] training Loss: -3071.9368\n",
            "Epoch [7/30] training Loss: -3225.0269\n",
            "Epoch [7/30] training Loss: -303.7511\n",
            "Epoch [7/30] training Loss: 14884.9121\n",
            "Epoch [7/30] training Loss: -9103.6279\n",
            "Epoch [7/30] training Loss: -3305.7114\n",
            "Epoch [7/30] training Loss: -3014.4180\n",
            "Epoch [7/30] training Loss: -3935.0898\n",
            "Epoch [7/30] training Loss: -2496.8367\n",
            "Epoch [7/30] training Loss: -2296.7920\n",
            "Epoch [7/30] training Loss: 1984.4954\n",
            "Epoch [7/30] training Loss: -1838.9878\n",
            "Epoch [7/30] training Loss: -6749.6460\n",
            "Epoch [7/30] training Loss: -4083.2605\n",
            "Epoch [7/30] training Loss: -456.1711\n",
            "Epoch [7/30] training Loss: -3352.4116\n",
            "Epoch [7/30] training Loss: -3320.3916\n",
            "Epoch [7/30] training Loss: -3056.4487\n",
            "Epoch [7/30] training Loss: 351.5663\n",
            "Epoch [7/30] training Loss: -1798.0449\n",
            "Epoch [7/30] training Loss: -3058.5752\n",
            "Epoch [7/30] training Loss: 2071.9878\n",
            "Epoch [7/30] training Loss: -505.5976\n",
            "Epoch [7/30] training Loss: -3080.9248\n",
            "Epoch [7/30] training Loss: -2504.8223\n",
            "Epoch [7/30] training Loss: 3375.4307\n",
            "Epoch [7/30] training Loss: -758.0947\n",
            "Epoch [7/30] training Loss: -1303.9006\n",
            "Epoch [7/30] training Loss: -3671.9602\n",
            "Epoch [7/30] training Loss: -6011.3423\n",
            "Epoch [7/30] training Loss: -302.9417\n",
            "Epoch [7/30] training Loss: -2156.3274\n",
            "Epoch [7/30] training Loss: 1724.3502\n",
            "Epoch [7/30] training Loss: -917.1364\n",
            "Epoch [7/30] training Loss: -1775.8219\n",
            "Epoch [7/30] training Loss: -281735.3750\n",
            "Epoch [7/30] training Loss: -289.3554\n",
            "Epoch [7/30] training Loss: -3055.2065\n",
            "Epoch [7/30] training Loss: -4728.3560\n",
            "Epoch [7/30] training Loss: -3654.9470\n",
            "Epoch [7/30] training Loss: -1083.4711\n",
            "Epoch [7/30] training Loss: -1467.9741\n",
            "Epoch [7/30] training Loss: -1741.6733\n",
            "Epoch [7/30] training Loss: -3396.8801\n",
            "Epoch [7/30] training Loss: -2225.5667\n",
            "Epoch [7/30] training Loss: 3047.8430\n",
            "Epoch [7/30] training Loss: -8524.5781\n",
            "Epoch [7/30] training Loss: -1716.7966\n",
            "Epoch [7/30] training Loss: -299060.1250\n",
            "Epoch [7/30] training Loss: -951.9742\n",
            "Epoch [7/30] training Loss: -2834.4648\n",
            "Epoch [7/30] training Loss: -2697.0283\n",
            "Epoch [7/30] training Loss: -630.1187\n",
            "Epoch [7/30] training Loss: -3455.7019\n",
            "Epoch [7/30] training Loss: -569.0936\n",
            "Epoch [7/30] training Loss: -1658.6707\n",
            "Epoch [7/30] training Loss: -15923.3574\n",
            "0it [00:00, ?it/s]Epoch [6/30] validation Loss: -24881.5781\n",
            "19it [00:01, 11.16it/s]Epoch [6/30] validation Loss: 17540.2344\n",
            "39it [00:03, 16.43it/s]Epoch [6/30] validation Loss: -11922.0840\n",
            "59it [00:04, 16.73it/s]Epoch [6/30] validation Loss: -12565.9170\n",
            "79it [00:05, 16.90it/s]Epoch [6/30] validation Loss: -6946.5991\n",
            "99it [00:06, 16.91it/s]Epoch [6/30] validation Loss: -20383.1191\n",
            "119it [00:07, 16.89it/s]Epoch [6/30] validation Loss: -6966.5840\n",
            "139it [00:09, 16.86it/s]Epoch [6/30] validation Loss: -13170.4980\n",
            "159it [00:10, 16.96it/s]Epoch [6/30] validation Loss: 24292.4473\n",
            "179it [00:11, 16.91it/s]Epoch [6/30] validation Loss: -5217.5752\n",
            "199it [00:12, 16.88it/s]Epoch [6/30] validation Loss: -10526.0137\n",
            "219it [00:13, 16.82it/s]Epoch [6/30] validation Loss: -59569.0195\n",
            "239it [00:14, 16.95it/s]Epoch [6/30] validation Loss: -56016.0508\n",
            "259it [00:16, 16.95it/s]Epoch [6/30] validation Loss: 25658.5859\n",
            "279it [00:17, 16.83it/s]Epoch [6/30] validation Loss: 7842.4072\n",
            "299it [00:18, 16.91it/s]Epoch [6/30] validation Loss: 9338.6689\n",
            "319it [00:19, 16.88it/s]Epoch [6/30] validation Loss: 5157.9346\n",
            "339it [00:20, 16.90it/s]Epoch [6/30] validation Loss: -158371.1250\n",
            "351it [00:21, 17.49it/s]\n",
            "Pixel Acc:  0.1762530698755363\n",
            "Class Accuracy:  [7.93637125e-01 5.61465823e-04 5.47202172e-05 2.39475115e-03\n",
            " 2.05834038e-01 4.01228294e-06]\n",
            "Mean Class Acc:  0.16708101876914186\n",
            "Freq Weighted IoU:  0.044500448639091555\n",
            "Mean IoU:  0.03876592192611335\n",
            "confusion_matrix [[1.6236541e+07 7.5840000e+03 2.4500000e+02 8.9812000e+04 4.1238190e+06\n",
            "  3.9300000e+02]\n",
            " [1.0073504e+07 7.1310000e+03 3.0500000e+02 4.1995000e+04 2.5775970e+06\n",
            "  1.5200000e+02]\n",
            " [4.0819339e+07 2.9185000e+04 2.8160000e+03 1.5937500e+05 1.0450324e+07\n",
            "  7.4500000e+02]\n",
            " [5.2490460e+06 4.1660000e+03 6.8900000e+02 1.5859000e+04 1.3526220e+06\n",
            "  1.8000000e+01]\n",
            " [2.2233930e+06 1.8990000e+03 3.6700000e+02 5.9410000e+03 5.7839200e+05\n",
            "  0.0000000e+00]\n",
            " [1.1857050e+06 9.6300000e+02 1.9200000e+02 3.6720000e+03 3.0487000e+05\n",
            "  6.0000000e+00]]\n",
            "Epoch [8/30] training Loss: 4761.3467\n",
            "Epoch [8/30] training Loss: 616.8778\n",
            "Epoch [8/30] training Loss: -1581.5251\n",
            "Epoch [8/30] training Loss: -7678.5327\n",
            "Epoch [8/30] training Loss: -2391.8293\n",
            "Epoch [8/30] training Loss: 3810.6150\n",
            "Epoch [8/30] training Loss: 30763.4570\n",
            "Epoch [8/30] training Loss: 315.8682\n",
            "Epoch [8/30] training Loss: -2027.4667\n",
            "Epoch [8/30] training Loss: 111.8571\n",
            "Epoch [8/30] training Loss: -63.5754\n",
            "Epoch [8/30] training Loss: -963.2687\n",
            "Epoch [8/30] training Loss: -311.8536\n",
            "Epoch [8/30] training Loss: -2716.3464\n",
            "Epoch [8/30] training Loss: 345.7007\n",
            "Epoch [8/30] training Loss: -1085.4794\n",
            "Epoch [8/30] training Loss: -2359.6526\n",
            "Epoch [8/30] training Loss: -2822.4934\n",
            "Epoch [8/30] training Loss: -3276.4534\n",
            "Epoch [8/30] training Loss: -3534.6028\n",
            "Epoch [8/30] training Loss: 8332.8057\n",
            "Epoch [8/30] training Loss: -1639.0476\n",
            "Epoch [8/30] training Loss: 175.5033\n",
            "Epoch [8/30] training Loss: -3650.0781\n",
            "Epoch [8/30] training Loss: 3397.3813\n",
            "Epoch [8/30] training Loss: -1492.5327\n",
            "Epoch [8/30] training Loss: -2316.4712\n",
            "Epoch [8/30] training Loss: -710.6049\n",
            "Epoch [8/30] training Loss: 4771.2124\n",
            "Epoch [8/30] training Loss: -1335.5671\n",
            "Epoch [8/30] training Loss: -9150.6641\n",
            "Epoch [8/30] training Loss: -2804.1196\n",
            "Epoch [8/30] training Loss: -2277.7998\n",
            "Epoch [8/30] training Loss: -3828.1033\n",
            "Epoch [8/30] training Loss: 132.4671\n",
            "Epoch [8/30] training Loss: -18.7115\n",
            "Epoch [8/30] training Loss: -1448.2997\n",
            "Epoch [8/30] training Loss: -2598.4448\n",
            "Epoch [8/30] training Loss: 3170.0312\n",
            "Epoch [8/30] training Loss: -431.6862\n",
            "Epoch [8/30] training Loss: -3857.2065\n",
            "Epoch [8/30] training Loss: -4843.7158\n",
            "Epoch [8/30] training Loss: -1380.5298\n",
            "Epoch [8/30] training Loss: -314.4349\n",
            "Epoch [8/30] training Loss: -1597.1816\n",
            "Epoch [8/30] training Loss: 4295.7129\n",
            "Epoch [8/30] training Loss: -2850.8442\n",
            "Epoch [8/30] training Loss: -1451.4352\n",
            "Epoch [8/30] training Loss: -1972.4232\n",
            "Epoch [8/30] training Loss: -3278.1660\n",
            "Epoch [8/30] training Loss: -4434.0269\n",
            "Epoch [8/30] training Loss: -6628.7974\n",
            "Epoch [8/30] training Loss: -1747.5651\n",
            "Epoch [8/30] training Loss: -3403.2456\n",
            "Epoch [8/30] training Loss: -5964.6001\n",
            "Epoch [8/30] training Loss: -1694.4111\n",
            "Epoch [8/30] training Loss: -3319.3252\n",
            "Epoch [8/30] training Loss: -309.1594\n",
            "Epoch [8/30] training Loss: -2050.0242\n",
            "Epoch [8/30] training Loss: -4545.0889\n",
            "Epoch [8/30] training Loss: -1952.9006\n",
            "Epoch [8/30] training Loss: -1765.1031\n",
            "Epoch [8/30] training Loss: -2766.4370\n",
            "Epoch [8/30] training Loss: -186.5502\n",
            "Epoch [8/30] training Loss: -2190.2236\n",
            "Epoch [8/30] training Loss: -3471.3545\n",
            "Epoch [8/30] training Loss: -548.4250\n",
            "Epoch [8/30] training Loss: -3376.5269\n",
            "Epoch [8/30] training Loss: 1671.0680\n",
            "Epoch [8/30] training Loss: -3423.6675\n",
            "Epoch [8/30] training Loss: -4394.9316\n",
            "0it [00:00, ?it/s]Epoch [7/30] validation Loss: -1650.0172\n",
            "19it [00:01, 11.13it/s]Epoch [7/30] validation Loss: -1134.0684\n",
            "39it [00:03, 16.44it/s]Epoch [7/30] validation Loss: -1809.4294\n",
            "59it [00:04, 16.78it/s]Epoch [7/30] validation Loss: -1606.2933\n",
            "79it [00:05, 16.84it/s]Epoch [7/30] validation Loss: -1911.7539\n",
            "99it [00:06, 16.85it/s]Epoch [7/30] validation Loss: -1430.7539\n",
            "119it [00:07, 16.68it/s]Epoch [7/30] validation Loss: -1635.7877\n",
            "139it [00:09, 16.68it/s]Epoch [7/30] validation Loss: -1696.3650\n",
            "159it [00:10, 16.55it/s]Epoch [7/30] validation Loss: -1252.3643\n",
            "179it [00:11, 16.58it/s]Epoch [7/30] validation Loss: -2001.5385\n",
            "199it [00:12, 16.84it/s]Epoch [7/30] validation Loss: -1787.2994\n",
            "219it [00:13, 16.75it/s]Epoch [7/30] validation Loss: -1450.1696\n",
            "239it [00:15, 16.71it/s]Epoch [7/30] validation Loss: -1449.1683\n",
            "259it [00:16, 16.64it/s]Epoch [7/30] validation Loss: -1597.5356\n",
            "279it [00:17, 16.60it/s]Epoch [7/30] validation Loss: -1029.0972\n",
            "299it [00:18, 16.60it/s]Epoch [7/30] validation Loss: -1153.4841\n",
            "319it [00:19, 16.69it/s]Epoch [7/30] validation Loss: -1050.5626\n",
            "339it [00:21, 16.82it/s]Epoch [7/30] validation Loss: -1671.8882\n",
            "351it [00:21, 17.42it/s]\n",
            "Pixel Acc:  0.18056851492070083\n",
            "Class Accuracy:  [0.77005458 0.02200637 0.00217981 0.13941985 0.06265392 0.00533366]\n",
            "Mean Class Acc:  0.16694136497682854\n",
            "Freq Weighted IoU:  0.05079758644018419\n",
            "Mean IoU:  0.0493448699875615\n",
            "confusion_matrix [[1.5754080e+07 4.4880700e+05 5.8608000e+04 3.0653110e+06 1.1315880e+06\n",
            "  0.0000000e+00]\n",
            " [9.7671440e+06 2.7949600e+05 2.9313000e+04 1.8595620e+06 7.6516900e+05\n",
            "  0.0000000e+00]\n",
            " [3.9605971e+07 1.1480510e+06 1.1217700e+05 7.4630110e+06 3.0932420e+06\n",
            "  3.9332000e+04]\n",
            " [5.1072160e+06 1.4711300e+05 1.0804000e+04 9.2329400e+05 4.0639400e+05\n",
            "  2.7579000e+04]\n",
            " [2.1683460e+06 6.2902000e+04 3.8320000e+03 3.7239000e+05 1.7605700e+05\n",
            "  2.6465000e+04]\n",
            " [1.1540130e+06 3.3214000e+04 2.4120000e+03 2.0676400e+05 9.1029000e+04\n",
            "  7.9760000e+03]]\n",
            "Epoch [9/30] training Loss: 513.1047\n",
            "Epoch [9/30] training Loss: -3029.1116\n",
            "Epoch [9/30] training Loss: -32478.5410\n",
            "Epoch [9/30] training Loss: -1500.7935\n",
            "Epoch [9/30] training Loss: -2669.8772\n",
            "Epoch [9/30] training Loss: -1886.3086\n",
            "Epoch [9/30] training Loss: 1044.2914\n",
            "Epoch [9/30] training Loss: -2603.9395\n",
            "Epoch [9/30] training Loss: -1898.7343\n",
            "Epoch [9/30] training Loss: -2308.8547\n",
            "Epoch [9/30] training Loss: -2022.3628\n",
            "Epoch [9/30] training Loss: 971.2257\n",
            "Epoch [9/30] training Loss: -2751.1714\n",
            "Epoch [9/30] training Loss: -3908.6289\n",
            "Epoch [9/30] training Loss: -2491.9072\n",
            "Epoch [9/30] training Loss: -19811.0234\n",
            "Epoch [9/30] training Loss: -1649.7883\n",
            "Epoch [9/30] training Loss: -3419.3188\n",
            "Epoch [9/30] training Loss: -3095.7161\n",
            "Epoch [9/30] training Loss: -1285.6074\n",
            "Epoch [9/30] training Loss: -2748.4363\n",
            "Epoch [9/30] training Loss: -3430.8284\n",
            "Epoch [9/30] training Loss: -2599.9656\n",
            "Epoch [9/30] training Loss: -2652.3740\n",
            "Epoch [9/30] training Loss: 22.9264\n",
            "Epoch [9/30] training Loss: 4236.8682\n",
            "Epoch [9/30] training Loss: -1179.3386\n",
            "Epoch [9/30] training Loss: -2559.9304\n",
            "Epoch [9/30] training Loss: -9366.1904\n",
            "Epoch [9/30] training Loss: -1601.3527\n",
            "Epoch [9/30] training Loss: 192795.6406\n",
            "Epoch [9/30] training Loss: -5.5804\n",
            "Epoch [9/30] training Loss: -2628.1335\n",
            "Epoch [9/30] training Loss: -3269.4097\n",
            "Epoch [9/30] training Loss: -4656.0571\n",
            "Epoch [9/30] training Loss: 359.5717\n",
            "Epoch [9/30] training Loss: -3032.6440\n",
            "Epoch [9/30] training Loss: -3466.3411\n",
            "Epoch [9/30] training Loss: -2216.4827\n",
            "Epoch [9/30] training Loss: -3381.4729\n",
            "Epoch [9/30] training Loss: 1664.2948\n",
            "Epoch [9/30] training Loss: -4333.9058\n",
            "Epoch [9/30] training Loss: 191.9939\n",
            "Epoch [9/30] training Loss: -2891.6875\n",
            "Epoch [9/30] training Loss: -2742.2095\n",
            "Epoch [9/30] training Loss: 68934.4609\n",
            "Epoch [9/30] training Loss: -3570.1870\n",
            "Epoch [9/30] training Loss: -3344.2346\n",
            "Epoch [9/30] training Loss: -919.6273\n",
            "Epoch [9/30] training Loss: -2611.2073\n",
            "Epoch [9/30] training Loss: -3081.2083\n",
            "Epoch [9/30] training Loss: -3592.9292\n",
            "Epoch [9/30] training Loss: -2310.8508\n",
            "Epoch [9/30] training Loss: -2530.9507\n",
            "Epoch [9/30] training Loss: -3049.2949\n",
            "Epoch [9/30] training Loss: -2453.6448\n",
            "Epoch [9/30] training Loss: -2100.5842\n",
            "Epoch [9/30] training Loss: -1429.1486\n",
            "Epoch [9/30] training Loss: -2052.3008\n",
            "Epoch [9/30] training Loss: -2546.9248\n",
            "Epoch [9/30] training Loss: -2105.6963\n",
            "Epoch [9/30] training Loss: -3171.2278\n",
            "Epoch [9/30] training Loss: -1907.1946\n",
            "Epoch [9/30] training Loss: -4307.1299\n",
            "Epoch [9/30] training Loss: -1965.7400\n",
            "Epoch [9/30] training Loss: -2927.6636\n",
            "Epoch [9/30] training Loss: -1550.7750\n",
            "Epoch [9/30] training Loss: -1782.8949\n",
            "Epoch [9/30] training Loss: 1671.5699\n",
            "Epoch [9/30] training Loss: -2726.6426\n",
            "Epoch [9/30] training Loss: -3798.6851\n",
            "0it [00:00, ?it/s]Epoch [8/30] validation Loss: -6336.0913\n",
            "19it [00:01, 10.97it/s]Epoch [8/30] validation Loss: -5377.0522\n",
            "39it [00:03, 16.50it/s]Epoch [8/30] validation Loss: -6135.5532\n",
            "59it [00:04, 16.68it/s]Epoch [8/30] validation Loss: -5168.0376\n",
            "79it [00:05, 16.53it/s]Epoch [8/30] validation Loss: -5122.4321\n",
            "99it [00:06, 16.63it/s]Epoch [8/30] validation Loss: -4990.5981\n",
            "119it [00:07, 16.66it/s]Epoch [8/30] validation Loss: -4258.7402\n",
            "139it [00:09, 16.74it/s]Epoch [8/30] validation Loss: -5645.5884\n",
            "159it [00:10, 16.80it/s]Epoch [8/30] validation Loss: -5770.3506\n",
            "179it [00:11, 16.73it/s]Epoch [8/30] validation Loss: -4497.6885\n",
            "199it [00:12, 16.73it/s]Epoch [8/30] validation Loss: -5684.9619\n",
            "219it [00:13, 16.86it/s]Epoch [8/30] validation Loss: -5943.1670\n",
            "239it [00:15, 16.86it/s]Epoch [8/30] validation Loss: -5945.4678\n",
            "259it [00:16, 16.88it/s]Epoch [8/30] validation Loss: -9063.7334\n",
            "279it [00:17, 17.00it/s]Epoch [8/30] validation Loss: -5969.2354\n",
            "299it [00:18, 16.71it/s]Epoch [8/30] validation Loss: -6499.3848\n",
            "319it [00:19, 16.87it/s]Epoch [8/30] validation Loss: -7807.4082\n",
            "339it [00:21, 16.66it/s]Epoch [8/30] validation Loss: -7591.9946\n",
            "351it [00:21, 17.40it/s]\n",
            "Pixel Acc:  0.18790811534336294\n",
            "Class Accuracy:  [0.74844223 0.0439133  0.01596892 0.18985972 0.00146655 0.00098769]\n",
            "Mean Class Acc:  0.16677306862369576\n",
            "Freq Weighted IoU:  0.059523236185973945\n",
            "Mean IoU:  0.05089211583980724\n",
            "confusion_matrix [[1.5311926e+07 8.1756500e+05 3.4868100e+05 3.9655230e+06 1.3435000e+04\n",
            "  1.2640000e+03]\n",
            " [9.5170510e+06 5.5772900e+05 2.0359400e+05 2.4120060e+06 9.6490000e+03\n",
            "  6.5500000e+02]\n",
            " [3.8566735e+07 2.2217190e+06 8.2178900e+05 9.7976520e+06 4.1857000e+04\n",
            "  1.2032000e+04]\n",
            " [4.9702280e+06 2.7613400e+05 1.0580000e+05 1.2573270e+06 7.2920000e+03\n",
            "  5.6190000e+03]\n",
            " [2.1160510e+06 1.1627700e+05 4.5592000e+04 5.2388500e+05 4.1210000e+03\n",
            "  4.0660000e+03]\n",
            " [1.1242710e+06 6.1642000e+04 2.3846000e+04 2.8237400e+05 1.7980000e+03\n",
            "  1.4770000e+03]]\n",
            "Epoch [10/30] training Loss: -4929.6733\n",
            "Epoch [10/30] training Loss: -1727.0679\n",
            "Epoch [10/30] training Loss: -2999.5886\n",
            "Epoch [10/30] training Loss: -3515.2344\n",
            "Epoch [10/30] training Loss: -3273.7212\n",
            "Epoch [10/30] training Loss: -3198.9622\n",
            "Epoch [10/30] training Loss: -2334.0376\n",
            "Epoch [10/30] training Loss: -2886.7856\n",
            "Epoch [10/30] training Loss: -2998.2859\n",
            "Epoch [10/30] training Loss: -1561.7842\n",
            "Epoch [10/30] training Loss: -2916.0833\n",
            "Epoch [10/30] training Loss: -5513.8066\n",
            "Epoch [10/30] training Loss: -2777.5527\n",
            "Epoch [10/30] training Loss: -2969.1516\n",
            "Epoch [10/30] training Loss: -7863.6724\n",
            "Epoch [10/30] training Loss: -3982.8047\n",
            "Epoch [10/30] training Loss: -5957.4648\n",
            "Epoch [10/30] training Loss: -2128.8931\n",
            "Epoch [10/30] training Loss: -3719.4089\n",
            "Epoch [10/30] training Loss: -4396.9902\n",
            "Epoch [10/30] training Loss: -1171.4064\n",
            "Epoch [10/30] training Loss: -2588.8081\n",
            "Epoch [10/30] training Loss: -1616.1071\n",
            "Epoch [10/30] training Loss: -1602.6973\n",
            "Epoch [10/30] training Loss: -3070.7310\n",
            "Epoch [10/30] training Loss: -69.9863\n",
            "Epoch [10/30] training Loss: -1502.0244\n",
            "Epoch [10/30] training Loss: -992.3662\n",
            "Epoch [10/30] training Loss: -2245.4419\n",
            "Epoch [10/30] training Loss: -5227.2715\n",
            "Epoch [10/30] training Loss: 12153.6885\n",
            "Epoch [10/30] training Loss: -1802.0621\n",
            "Epoch [10/30] training Loss: -3452.3237\n",
            "Epoch [10/30] training Loss: -5529.4258\n",
            "Epoch [10/30] training Loss: -1889.2898\n",
            "Epoch [10/30] training Loss: -1676.6509\n",
            "Epoch [10/30] training Loss: -1244.2081\n",
            "Epoch [10/30] training Loss: -2786.5681\n",
            "Epoch [10/30] training Loss: -2620.1812\n",
            "Epoch [10/30] training Loss: -2824.1323\n",
            "Epoch [10/30] training Loss: -4093.8333\n",
            "Epoch [10/30] training Loss: -3162.2349\n",
            "Epoch [10/30] training Loss: 773.5196\n",
            "Epoch [10/30] training Loss: 514.5272\n",
            "Epoch [10/30] training Loss: -2726.0134\n",
            "Epoch [10/30] training Loss: -2731.8887\n",
            "Epoch [10/30] training Loss: -2809.0449\n",
            "Epoch [10/30] training Loss: -2393.1416\n",
            "Epoch [10/30] training Loss: -1393.9282\n",
            "Epoch [10/30] training Loss: -3363.0149\n",
            "Epoch [10/30] training Loss: -4194.5088\n",
            "Epoch [10/30] training Loss: -1149.3525\n",
            "Epoch [10/30] training Loss: -1394.4543\n",
            "Epoch [10/30] training Loss: -2220.5190\n",
            "Epoch [10/30] training Loss: 749.6102\n",
            "Epoch [10/30] training Loss: -1597.7838\n",
            "Epoch [10/30] training Loss: -2833.4885\n",
            "Epoch [10/30] training Loss: -2051.1538\n",
            "Epoch [10/30] training Loss: -3620.0396\n",
            "Epoch [10/30] training Loss: -1609.0946\n",
            "Epoch [10/30] training Loss: -2507.3213\n",
            "Epoch [10/30] training Loss: -2923.0544\n",
            "Epoch [10/30] training Loss: -3313.8176\n",
            "Epoch [10/30] training Loss: -2976.6533\n",
            "Epoch [10/30] training Loss: -3098.5718\n",
            "Epoch [10/30] training Loss: 139.8016\n",
            "Epoch [10/30] training Loss: -1652.4854\n",
            "Epoch [10/30] training Loss: -1305.3529\n",
            "Epoch [10/30] training Loss: -2735.7800\n",
            "Epoch [10/30] training Loss: -2544.4312\n",
            "Epoch [10/30] training Loss: -3086.7739\n",
            "0it [00:00, ?it/s]Epoch [9/30] validation Loss: -3162.1514\n",
            "19it [00:01, 11.28it/s]Epoch [9/30] validation Loss: -3135.5627\n",
            "39it [00:03, 16.59it/s]Epoch [9/30] validation Loss: -3156.3867\n",
            "59it [00:04, 16.84it/s]Epoch [9/30] validation Loss: -3128.0188\n",
            "79it [00:05, 16.92it/s]Epoch [9/30] validation Loss: -3121.4736\n",
            "99it [00:06, 16.98it/s]Epoch [9/30] validation Loss: -3123.0664\n",
            "119it [00:07, 16.81it/s]Epoch [9/30] validation Loss: -3102.7715\n",
            "139it [00:08, 16.92it/s]Epoch [9/30] validation Loss: -3147.7175\n",
            "159it [00:10, 16.75it/s]Epoch [9/30] validation Loss: -3143.5820\n",
            "179it [00:11, 16.74it/s]Epoch [9/30] validation Loss: -3100.9365\n",
            "199it [00:12, 16.70it/s]Epoch [9/30] validation Loss: -3143.7200\n",
            "219it [00:13, 16.98it/s]Epoch [9/30] validation Loss: -3153.2654\n",
            "239it [00:14, 16.94it/s]Epoch [9/30] validation Loss: -3153.2681\n",
            "259it [00:16, 16.87it/s]Epoch [9/30] validation Loss: -3296.9888\n",
            "279it [00:17, 16.82it/s]Epoch [9/30] validation Loss: -3147.8384\n",
            "299it [00:18, 16.91it/s]Epoch [9/30] validation Loss: -3159.0979\n",
            "319it [00:19, 16.80it/s]Epoch [9/30] validation Loss: -3181.0562\n",
            "339it [00:20, 16.75it/s]Epoch [9/30] validation Loss: -3220.4431\n",
            "351it [00:21, 17.46it/s]\n",
            "Pixel Acc:  0.2757704655246768\n",
            "Class Accuracy:  [7.52644220e-01 4.64915118e-02 2.01325259e-01 8.69775308e-05\n",
            " 0.00000000e+00 0.00000000e+00]\n",
            "Mean Class Acc:  0.1667579947898311\n",
            "Freq Weighted IoU:  0.14009975624858895\n",
            "Mean IoU:  0.06793760952085429\n",
            "confusion_matrix [[1.5397892e+07 9.6862300e+05 4.0914370e+06 4.4200000e+02 0.0000000e+00\n",
            "  0.0000000e+00]\n",
            " [9.5558740e+06 5.9047400e+05 2.5541650e+06 1.7100000e+02 0.0000000e+00\n",
            "  0.0000000e+00]\n",
            " [3.8723695e+07 2.3761760e+06 1.0360557e+07 1.3560000e+03 0.0000000e+00\n",
            "  0.0000000e+00]\n",
            " [4.9858000e+06 2.9741700e+05 1.3386070e+06 5.7600000e+02 0.0000000e+00\n",
            "  0.0000000e+00]\n",
            " [2.1183400e+06 1.2065500e+05 5.7056800e+05 4.2900000e+02 0.0000000e+00\n",
            "  0.0000000e+00]\n",
            " [1.1273940e+06 6.6260000e+04 3.0161700e+05 1.3700000e+02 0.0000000e+00\n",
            "  0.0000000e+00]]\n",
            "Epoch [11/30] training Loss: -3075.8003\n",
            "Epoch [11/30] training Loss: -3117.5542\n",
            "Epoch [11/30] training Loss: -2526.5254\n",
            "Epoch [11/30] training Loss: -3646.7881\n",
            "Epoch [11/30] training Loss: -3256.8623\n",
            "Epoch [11/30] training Loss: -1166.2329\n",
            "Epoch [11/30] training Loss: -2331.0200\n",
            "Epoch [11/30] training Loss: -3189.9668\n",
            "Epoch [11/30] training Loss: -1071.4564\n",
            "Epoch [11/30] training Loss: -1912.8839\n",
            "Epoch [11/30] training Loss: -3027.1787\n",
            "Epoch [11/30] training Loss: -2666.5447\n",
            "Epoch [11/30] training Loss: -3373.2539\n",
            "Epoch [11/30] training Loss: -2717.2612\n",
            "Epoch [11/30] training Loss: -1286.9944\n",
            "Epoch [11/30] training Loss: -2649.7622\n",
            "Epoch [11/30] training Loss: -2808.8252\n",
            "Epoch [11/30] training Loss: -2229.7053\n",
            "Epoch [11/30] training Loss: -3190.1523\n",
            "Epoch [11/30] training Loss: -3378.7981\n",
            "Epoch [11/30] training Loss: -1898.2079\n",
            "Epoch [11/30] training Loss: -2246.5417\n",
            "Epoch [11/30] training Loss: -3930.9717\n",
            "Epoch [11/30] training Loss: -2753.6174\n",
            "Epoch [11/30] training Loss: -2620.9553\n",
            "Epoch [11/30] training Loss: -2975.5183\n",
            "Epoch [11/30] training Loss: -4505.0933\n",
            "Epoch [11/30] training Loss: -2376.8691\n",
            "Epoch [11/30] training Loss: -11594.0596\n",
            "Epoch [11/30] training Loss: -3554.4341\n",
            "Epoch [11/30] training Loss: -667.9244\n",
            "Epoch [11/30] training Loss: -2645.0767\n",
            "Epoch [11/30] training Loss: -3263.4031\n",
            "Epoch [11/30] training Loss: -3176.1445\n",
            "Epoch [11/30] training Loss: -2558.1548\n",
            "Epoch [11/30] training Loss: -3446.4575\n",
            "Epoch [11/30] training Loss: -4195.4385\n",
            "Epoch [11/30] training Loss: -2256.7629\n",
            "Epoch [11/30] training Loss: -2371.9355\n",
            "Epoch [11/30] training Loss: -3080.9258\n",
            "Epoch [11/30] training Loss: -2712.6589\n",
            "Epoch [11/30] training Loss: -2519.4971\n",
            "Epoch [11/30] training Loss: 723.1848\n",
            "Epoch [11/30] training Loss: 2037.0833\n",
            "Epoch [11/30] training Loss: -6114.6338\n",
            "Epoch [11/30] training Loss: 606.3004\n",
            "Epoch [11/30] training Loss: -2931.0217\n",
            "Epoch [11/30] training Loss: -3123.0674\n",
            "Epoch [11/30] training Loss: -3397.3906\n",
            "Epoch [11/30] training Loss: -2960.3748\n",
            "Epoch [11/30] training Loss: -5432.2012\n",
            "Epoch [11/30] training Loss: -1981.1104\n",
            "Epoch [11/30] training Loss: -3072.9731\n",
            "Epoch [11/30] training Loss: -3130.1704\n",
            "Epoch [11/30] training Loss: -3421.4136\n",
            "Epoch [11/30] training Loss: -137.2614\n",
            "Epoch [11/30] training Loss: -2739.7520\n",
            "Epoch [11/30] training Loss: -1506.8557\n",
            "Epoch [11/30] training Loss: -1830.7701\n",
            "Epoch [11/30] training Loss: -1782.9844\n",
            "Epoch [11/30] training Loss: 3078.8589\n",
            "Epoch [11/30] training Loss: -238.7933\n",
            "Epoch [11/30] training Loss: 484.0479\n",
            "Epoch [11/30] training Loss: -624.8806\n",
            "Epoch [11/30] training Loss: -2844.5901\n",
            "Epoch [11/30] training Loss: -3210.6663\n",
            "Epoch [11/30] training Loss: -4212.8252\n",
            "Epoch [11/30] training Loss: -2314.2219\n",
            "Epoch [11/30] training Loss: -594.8760\n",
            "Epoch [11/30] training Loss: -1227.2529\n",
            "Epoch [11/30] training Loss: -2275.3296\n",
            "0it [00:00, ?it/s]Epoch [10/30] validation Loss: -1754.3340\n",
            "19it [00:01, 11.02it/s]Epoch [10/30] validation Loss: -7637.1152\n",
            "39it [00:03, 16.65it/s]Epoch [10/30] validation Loss: -251.8239\n",
            "59it [00:04, 16.84it/s]Epoch [10/30] validation Loss: 198.6447\n",
            "79it [00:05, 16.88it/s]Epoch [10/30] validation Loss: 16190.3203\n",
            "99it [00:06, 16.89it/s]Epoch [10/30] validation Loss: -699.1847\n",
            "119it [00:07, 16.97it/s]Epoch [10/30] validation Loss: -9850.8359\n",
            "139it [00:09, 16.80it/s]Epoch [10/30] validation Loss: -310.8579\n",
            "159it [00:10, 16.98it/s]Epoch [10/30] validation Loss: -6502.8774\n",
            "179it [00:11, 16.87it/s]Epoch [10/30] validation Loss: 235923.2188\n",
            "199it [00:12, 16.94it/s]Epoch [10/30] validation Loss: 455.7540\n",
            "219it [00:13, 16.89it/s]Epoch [10/30] validation Loss: -2989.2036\n",
            "239it [00:14, 16.87it/s]Epoch [10/30] validation Loss: -2995.8950\n",
            "259it [00:16, 16.97it/s]Epoch [10/30] validation Loss: 25896.8789\n",
            "279it [00:17, 16.80it/s]Epoch [10/30] validation Loss: 4163.5479\n",
            "299it [00:18, 16.94it/s]Epoch [10/30] validation Loss: 5227.2837\n",
            "319it [00:19, 16.84it/s]Epoch [10/30] validation Loss: -119.9200\n",
            "339it [00:20, 16.89it/s]Epoch [10/30] validation Loss: -4048.4614\n",
            "351it [00:21, 17.55it/s]\n",
            "Pixel Acc:  0.24772807388972123\n",
            "Class Accuracy:  [7.73791139e-01 8.64281798e-02 1.30348124e-01 9.13566079e-05\n",
            " 1.08950488e-02 1.80418989e-03]\n",
            "Mean Class Acc:  0.16722633971199252\n",
            "Freq Weighted IoU:  0.1139997939352876\n",
            "Mean IoU:  0.06405155442788842\n",
            "confusion_matrix [[1.5830524e+07 1.7263920e+06 2.7123740e+06 8.7320000e+03 1.8037200e+05\n",
            "  0.0000000e+00]\n",
            " [9.8179430e+06 1.0976970e+06 1.6695900e+06 5.7490000e+03 1.0970500e+05\n",
            "  0.0000000e+00]\n",
            " [3.9748154e+07 4.5184300e+06 6.7079470e+06 2.1897000e+04 4.5183200e+05\n",
            "  1.3524000e+04]\n",
            " [5.0918510e+06 6.4233800e+05 8.1442200e+05 6.0500000e+02 6.3888000e+04\n",
            "  9.2960000e+03]\n",
            " [2.1491660e+06 3.0485000e+05 3.1649500e+05 0.0000000e+00 3.0615000e+04\n",
            "  8.8660000e+03]\n",
            " [1.1497580e+06 1.4765900e+05 1.8037800e+05 1.9400000e+02 1.4721000e+04\n",
            "  2.6980000e+03]]\n",
            "Epoch [12/30] training Loss: -1316.8103\n",
            "Epoch [12/30] training Loss: -3426.0288\n",
            "Epoch [12/30] training Loss: -3243.1230\n",
            "Epoch [12/30] training Loss: -2577.6235\n",
            "Epoch [12/30] training Loss: -1735.1886\n",
            "Epoch [12/30] training Loss: -5971.4678\n",
            "Epoch [12/30] training Loss: 1411.0696\n",
            "Epoch [12/30] training Loss: 5700.9336\n",
            "Epoch [12/30] training Loss: 266.0986\n",
            "Epoch [12/30] training Loss: -3243.6367\n",
            "Epoch [12/30] training Loss: -3397.9978\n",
            "Epoch [12/30] training Loss: -3995.7546\n",
            "Epoch [12/30] training Loss: -18268.5059\n",
            "Epoch [12/30] training Loss: 312.7447\n",
            "Epoch [12/30] training Loss: 516.4373\n",
            "Epoch [12/30] training Loss: -472.3506\n",
            "Epoch [12/30] training Loss: -3149.1479\n",
            "Epoch [12/30] training Loss: -3311.1562\n",
            "Epoch [12/30] training Loss: -8367.5479\n",
            "Epoch [12/30] training Loss: 826.0382\n",
            "Epoch [12/30] training Loss: 1351.6128\n",
            "Epoch [12/30] training Loss: 20.6699\n",
            "Epoch [12/30] training Loss: -1400.5355\n",
            "Epoch [12/30] training Loss: -3485.0293\n",
            "Epoch [12/30] training Loss: -5708.5474\n",
            "Epoch [12/30] training Loss: -1219.7505\n",
            "Epoch [12/30] training Loss: 5396.0625\n",
            "Epoch [12/30] training Loss: 588.6276\n",
            "Epoch [12/30] training Loss: 22.0247\n",
            "Epoch [12/30] training Loss: -201.8413\n",
            "Epoch [12/30] training Loss: -526.6519\n",
            "Epoch [12/30] training Loss: -3198.4990\n",
            "Epoch [12/30] training Loss: -3246.3474\n",
            "Epoch [12/30] training Loss: 173.6435\n",
            "Epoch [12/30] training Loss: -477.9613\n",
            "Epoch [12/30] training Loss: -9878.3418\n",
            "Epoch [12/30] training Loss: 31.4626\n",
            "Epoch [12/30] training Loss: -201.0776\n",
            "Epoch [12/30] training Loss: -607.3555\n",
            "Epoch [12/30] training Loss: -1316.5828\n",
            "Epoch [12/30] training Loss: -2089.4282\n",
            "Epoch [12/30] training Loss: -2735.1982\n",
            "Epoch [12/30] training Loss: -3070.4924\n",
            "Epoch [12/30] training Loss: -3019.1555\n",
            "Epoch [12/30] training Loss: -3558.2207\n",
            "Epoch [12/30] training Loss: -3220.3425\n",
            "Epoch [12/30] training Loss: -4212.5537\n",
            "Epoch [12/30] training Loss: -1661.4919\n",
            "Epoch [12/30] training Loss: -2125.5615\n",
            "Epoch [12/30] training Loss: -2653.9678\n",
            "Epoch [12/30] training Loss: -2869.4988\n",
            "Epoch [12/30] training Loss: -2963.9421\n",
            "Epoch [12/30] training Loss: -3044.0640\n",
            "Epoch [12/30] training Loss: -3418.8867\n",
            "Epoch [12/30] training Loss: -13413.4092\n",
            "Epoch [12/30] training Loss: -914.7582\n",
            "Epoch [12/30] training Loss: -2595.6707\n",
            "Epoch [12/30] training Loss: -2874.7166\n",
            "Epoch [12/30] training Loss: -3010.2922\n",
            "Epoch [12/30] training Loss: -3058.0508\n",
            "Epoch [12/30] training Loss: -3093.7002\n",
            "Epoch [12/30] training Loss: -3310.5496\n",
            "Epoch [12/30] training Loss: -3154.9041\n",
            "Epoch [12/30] training Loss: -2938.1978\n",
            "Epoch [12/30] training Loss: -2996.7891\n",
            "Epoch [12/30] training Loss: -2999.5994\n",
            "Epoch [12/30] training Loss: -3036.9077\n",
            "Epoch [12/30] training Loss: -3049.5220\n",
            "Epoch [12/30] training Loss: -3057.5161\n",
            "Epoch [12/30] training Loss: -3067.5474\n",
            "Epoch [12/30] training Loss: -3105.1118\n",
            "0it [00:00, ?it/s]Epoch [11/30] validation Loss: -3131.9731\n",
            "19it [00:01, 11.14it/s]Epoch [11/30] validation Loss: -3133.5266\n",
            "39it [00:03, 16.63it/s]Epoch [11/30] validation Loss: -3123.6460\n",
            "59it [00:04, 16.44it/s]Epoch [11/30] validation Loss: -3115.7148\n",
            "79it [00:05, 16.74it/s]Epoch [11/30] validation Loss: -3105.0073\n",
            "99it [00:06, 16.86it/s]Epoch [11/30] validation Loss: -3116.3284\n",
            "119it [00:07, 16.77it/s]Epoch [11/30] validation Loss: -3096.3311\n",
            "139it [00:09, 16.64it/s]Epoch [11/30] validation Loss: -3123.7563\n",
            "159it [00:10, 16.76it/s]Epoch [11/30] validation Loss: -3136.2124\n",
            "179it [00:11, 16.76it/s]Epoch [11/30] validation Loss: -3090.8220\n",
            "199it [00:12, 16.57it/s]Epoch [11/30] validation Loss: -3119.0991\n",
            "219it [00:13, 16.75it/s]Epoch [11/30] validation Loss: -3135.3613\n",
            "239it [00:15, 16.59it/s]Epoch [11/30] validation Loss: -3135.4170\n",
            "259it [00:16, 16.70it/s]Epoch [11/30] validation Loss: -3168.3154\n",
            "279it [00:17, 16.73it/s]Epoch [11/30] validation Loss: -3147.0554\n",
            "299it [00:18, 16.83it/s]Epoch [11/30] validation Loss: -3150.7673\n",
            "319it [00:19, 16.79it/s]Epoch [11/30] validation Loss: -3170.3701\n",
            "339it [00:20, 16.76it/s]Epoch [11/30] validation Loss: -3148.8672\n",
            "351it [00:21, 17.28it/s]\n",
            "Pixel Acc:  0.13073437909575333\n",
            "Class Accuracy:  [0.0102381  0.94388035 0.         0.044412   0.         0.        ]\n",
            "Mean Class Acc:  0.16642173948437572\n",
            "Freq Weighted IoU:  0.02156026971431121\n",
            "Mean IoU:  0.02824463769033961\n",
            "confusion_matrix [[2.0945500e+05 1.9312149e+07 0.0000000e+00 9.3679000e+05 0.0000000e+00\n",
            "  0.0000000e+00]\n",
            " [1.4501300e+05 1.1987926e+07 0.0000000e+00 5.6774500e+05 0.0000000e+00\n",
            "  0.0000000e+00]\n",
            " [6.0600600e+05 4.8546852e+07 0.0000000e+00 2.3089260e+06 0.0000000e+00\n",
            "  0.0000000e+00]\n",
            " [1.0043200e+05 6.2278540e+06 0.0000000e+00 2.9411400e+05 0.0000000e+00\n",
            "  0.0000000e+00]\n",
            " [5.8760000e+04 2.6283390e+06 0.0000000e+00 1.2289300e+05 0.0000000e+00\n",
            "  0.0000000e+00]\n",
            " [2.4330000e+04 1.4049610e+06 0.0000000e+00 6.6117000e+04 0.0000000e+00\n",
            "  0.0000000e+00]]\n",
            "Epoch [13/30] training Loss: -3121.0474\n",
            "Epoch [13/30] training Loss: -3350.3201\n",
            "Epoch [13/30] training Loss: -5558.9688\n",
            "Epoch [13/30] training Loss: 1263.3081\n",
            "Epoch [13/30] training Loss: -753.4514\n",
            "Epoch [13/30] training Loss: -964.0012\n",
            "Epoch [13/30] training Loss: -1323.3536\n",
            "Epoch [13/30] training Loss: -1746.8718\n",
            "Epoch [13/30] training Loss: -2480.1750\n",
            "Epoch [13/30] training Loss: -3020.5425\n",
            "Epoch [13/30] training Loss: -3055.9514\n",
            "Epoch [13/30] training Loss: -3085.0081\n",
            "Epoch [13/30] training Loss: -3206.5168\n",
            "Epoch [13/30] training Loss: -3644.5642\n",
            "Epoch [13/30] training Loss: -6996.1348\n",
            "Epoch [13/30] training Loss: -4062.4973\n",
            "Epoch [13/30] training Loss: -1541.0676\n",
            "Epoch [13/30] training Loss: -1242.3394\n",
            "Epoch [13/30] training Loss: 147785.4531\n",
            "Epoch [13/30] training Loss: -1319.9230\n",
            "Epoch [13/30] training Loss: 16316.9014\n",
            "Epoch [13/30] training Loss: -1227.8383\n",
            "Epoch [13/30] training Loss: -2974.5625\n",
            "Epoch [13/30] training Loss: -14772.7734\n",
            "Epoch [13/30] training Loss: -978.6891\n",
            "Epoch [13/30] training Loss: -1843.7256\n",
            "Epoch [13/30] training Loss: -3510.2012\n",
            "Epoch [13/30] training Loss: -1311.9829\n",
            "Epoch [13/30] training Loss: -1893.5604\n",
            "Epoch [13/30] training Loss: -2227.1104\n",
            "Epoch [13/30] training Loss: -2537.0498\n",
            "Epoch [13/30] training Loss: -2778.0771\n",
            "Epoch [13/30] training Loss: -3396.8853\n",
            "Epoch [13/30] training Loss: -2574.1003\n",
            "Epoch [13/30] training Loss: -2977.7896\n",
            "Epoch [13/30] training Loss: -3069.4197\n",
            "Epoch [13/30] training Loss: -3105.0813\n",
            "Epoch [13/30] training Loss: -3410.0667\n",
            "Epoch [13/30] training Loss: -1586.1705\n",
            "Epoch [13/30] training Loss: -2405.6567\n",
            "Epoch [13/30] training Loss: -2880.9263\n",
            "Epoch [13/30] training Loss: -3002.4014\n",
            "Epoch [13/30] training Loss: -2988.5830\n",
            "Epoch [13/30] training Loss: -3059.8164\n",
            "Epoch [13/30] training Loss: -3062.7839\n",
            "Epoch [13/30] training Loss: -3079.9919\n",
            "Epoch [13/30] training Loss: -3146.9683\n",
            "Epoch [13/30] training Loss: -4056.7400\n",
            "Epoch [13/30] training Loss: -2501.1599\n",
            "Epoch [13/30] training Loss: -2970.9619\n",
            "Epoch [13/30] training Loss: -3198.8989\n",
            "Epoch [13/30] training Loss: -8284.6035\n",
            "Epoch [13/30] training Loss: -1706.5098\n",
            "Epoch [13/30] training Loss: -3053.0325\n",
            "Epoch [13/30] training Loss: -3132.8628\n",
            "Epoch [13/30] training Loss: -3288.8801\n",
            "Epoch [13/30] training Loss: -2326.1077\n",
            "Epoch [13/30] training Loss: -2905.8833\n",
            "Epoch [13/30] training Loss: -3016.5996\n",
            "Epoch [13/30] training Loss: -3060.4250\n",
            "Epoch [13/30] training Loss: -3102.7561\n",
            "Epoch [13/30] training Loss: -3266.0681\n",
            "Epoch [13/30] training Loss: -5645.3931\n",
            "Epoch [13/30] training Loss: -2444.4832\n",
            "Epoch [13/30] training Loss: -2794.5286\n",
            "Epoch [13/30] training Loss: -2954.0183\n",
            "Epoch [13/30] training Loss: -3025.4666\n",
            "Epoch [13/30] training Loss: -3050.9417\n",
            "Epoch [13/30] training Loss: -3050.4382\n",
            "Epoch [13/30] training Loss: -3058.0928\n",
            "Epoch [13/30] training Loss: -3059.3628\n",
            "0it [00:00, ?it/s]Epoch [12/30] validation Loss: -3059.3157\n",
            "19it [00:01, 11.13it/s]Epoch [12/30] validation Loss: -3059.9014\n",
            "39it [00:03, 16.42it/s]Epoch [12/30] validation Loss: -3058.8308\n",
            "59it [00:04, 16.66it/s]Epoch [12/30] validation Loss: -3058.6396\n",
            "79it [00:05, 16.70it/s]Epoch [12/30] validation Loss: -3057.9741\n",
            "99it [00:06, 16.78it/s]Epoch [12/30] validation Loss: -3058.8293\n",
            "119it [00:07, 16.73it/s]Epoch [12/30] validation Loss: -3057.7256\n",
            "139it [00:09, 16.72it/s]Epoch [12/30] validation Loss: -3058.8674\n",
            "159it [00:10, 16.33it/s]Epoch [12/30] validation Loss: -3059.9045\n",
            "179it [00:11, 16.74it/s]Epoch [12/30] validation Loss: -3057.3040\n",
            "199it [00:12, 16.82it/s]Epoch [12/30] validation Loss: -3058.6414\n",
            "219it [00:13, 16.85it/s]Epoch [12/30] validation Loss: -3059.6265\n",
            "239it [00:15, 16.83it/s]Epoch [12/30] validation Loss: -3059.6235\n",
            "259it [00:16, 16.71it/s]Epoch [12/30] validation Loss: -3060.7297\n",
            "279it [00:17, 16.81it/s]Epoch [12/30] validation Loss: -3060.6660\n",
            "299it [00:18, 16.78it/s]Epoch [12/30] validation Loss: -3060.6731\n",
            "319it [00:19, 16.70it/s]Epoch [12/30] validation Loss: -3061.7124\n",
            "339it [00:21, 16.73it/s]Epoch [12/30] validation Loss: -3059.9312\n",
            "351it [00:21, 17.45it/s]\n",
            "Pixel Acc:  0.1436746021624039\n",
            "Class Accuracy:  [4.76123883e-02 9.36230364e-01 1.67566286e-02 1.13402996e-04\n",
            " 0.00000000e+00 0.00000000e+00]\n",
            "Mean Class Acc:  0.16678546392734409\n",
            "Freq Weighted IoU:  0.03511730843711522\n",
            "Mean IoU:  0.03150825357635443\n",
            "confusion_matrix [[9.7407300e+05 1.9131514e+07 3.4004200e+05 1.2765000e+04 0.0000000e+00\n",
            "  0.0000000e+00]\n",
            " [5.8351400e+05 1.1890766e+07 2.1884500e+05 7.5590000e+03 0.0000000e+00\n",
            "  0.0000000e+00]\n",
            " [2.4107890e+06 4.8160551e+07 8.6232600e+05 2.8118000e+04 0.0000000e+00\n",
            "  0.0000000e+00]\n",
            " [3.3101800e+05 6.1826600e+06 1.0797100e+05 7.5100000e+02 0.0000000e+00\n",
            "  0.0000000e+00]\n",
            " [1.5344200e+05 2.6119800e+06 4.4570000e+04 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00]\n",
            " [7.6051000e+04 1.3950320e+06 2.4040000e+04 2.8500000e+02 0.0000000e+00\n",
            "  0.0000000e+00]]\n",
            "Epoch [14/30] training Loss: -3059.7676\n",
            "Epoch [14/30] training Loss: -3062.1177\n",
            "Epoch [14/30] training Loss: -3064.6970\n",
            "Epoch [14/30] training Loss: -3061.2791\n",
            "Epoch [14/30] training Loss: -3078.1401\n",
            "Epoch [14/30] training Loss: -3095.0547\n",
            "Epoch [14/30] training Loss: -3113.5579\n",
            "Epoch [14/30] training Loss: -3271.7954\n",
            "Epoch [14/30] training Loss: -3259.7300\n",
            "Epoch [14/30] training Loss: -2987.8650\n",
            "Epoch [14/30] training Loss: -3040.8823\n",
            "Epoch [14/30] training Loss: -3066.2043\n",
            "Epoch [14/30] training Loss: -3107.1362\n",
            "Epoch [14/30] training Loss: -4182.6699\n",
            "Epoch [14/30] training Loss: -1862.6433\n",
            "Epoch [14/30] training Loss: -2837.0999\n",
            "Epoch [14/30] training Loss: -2989.7004\n",
            "Epoch [14/30] training Loss: -3013.4497\n",
            "Epoch [14/30] training Loss: -3044.7612\n",
            "Epoch [14/30] training Loss: -3054.0659\n",
            "Epoch [14/30] training Loss: -3039.2034\n",
            "Epoch [14/30] training Loss: -3060.5149\n",
            "Epoch [14/30] training Loss: -3065.4771\n",
            "Epoch [14/30] training Loss: -3069.8833\n",
            "Epoch [14/30] training Loss: -3073.8140\n",
            "Epoch [14/30] training Loss: -3080.3225\n",
            "Epoch [14/30] training Loss: -3119.3584\n",
            "Epoch [14/30] training Loss: -2746.9404\n",
            "Epoch [14/30] training Loss: -2940.9470\n",
            "Epoch [14/30] training Loss: -3017.3516\n",
            "Epoch [14/30] training Loss: -3050.1895\n",
            "Epoch [14/30] training Loss: -3073.3086\n",
            "Epoch [14/30] training Loss: -3209.3042\n",
            "Epoch [14/30] training Loss: -3152.4517\n",
            "Epoch [14/30] training Loss: -2910.6292\n",
            "Epoch [14/30] training Loss: -2937.1726\n",
            "Epoch [14/30] training Loss: -3000.5994\n",
            "Epoch [14/30] training Loss: -3035.4404\n",
            "Epoch [14/30] training Loss: -3053.8257\n",
            "Epoch [14/30] training Loss: -3057.2319\n",
            "Epoch [14/30] training Loss: -3061.8677\n",
            "Epoch [14/30] training Loss: -3064.3557\n",
            "Epoch [14/30] training Loss: -3068.1079\n",
            "Epoch [14/30] training Loss: -3076.0334\n",
            "Epoch [14/30] training Loss: -3086.7803\n",
            "Epoch [14/30] training Loss: -3172.6572\n",
            "Epoch [14/30] training Loss: -3095.2485\n",
            "Epoch [14/30] training Loss: -2975.3738\n",
            "Epoch [14/30] training Loss: -3026.8936\n",
            "Epoch [14/30] training Loss: -3054.6702\n",
            "Epoch [14/30] training Loss: -3026.0686\n",
            "Epoch [14/30] training Loss: -3116.6497\n",
            "Epoch [14/30] training Loss: -3043.2349\n",
            "Epoch [14/30] training Loss: -3369.3975\n",
            "Epoch [14/30] training Loss: -3019.5034\n",
            "Epoch [14/30] training Loss: -3036.2476\n",
            "Epoch [14/30] training Loss: -3050.5166\n",
            "Epoch [14/30] training Loss: -3052.5007\n",
            "Epoch [14/30] training Loss: -3060.6147\n",
            "Epoch [14/30] training Loss: -3049.3691\n",
            "Epoch [14/30] training Loss: -3061.5903\n",
            "Epoch [14/30] training Loss: -3038.5078\n",
            "Epoch [14/30] training Loss: -3036.4868\n",
            "Epoch [14/30] training Loss: -3050.0210\n",
            "Epoch [14/30] training Loss: -3048.2446\n",
            "Epoch [14/30] training Loss: -3054.0063\n",
            "Epoch [14/30] training Loss: -2988.6519\n",
            "Epoch [14/30] training Loss: -3062.0056\n",
            "Epoch [14/30] training Loss: -3016.6636\n",
            "Epoch [14/30] training Loss: -3043.3647\n",
            "Epoch [14/30] training Loss: -3050.9583\n",
            "0it [00:00, ?it/s]Epoch [13/30] validation Loss: -3051.7981\n",
            "19it [00:01, 11.05it/s]Epoch [13/30] validation Loss: -3051.7549\n",
            "39it [00:03, 16.31it/s]Epoch [13/30] validation Loss: -3051.9768\n",
            "59it [00:04, 16.43it/s]Epoch [13/30] validation Loss: -3052.1772\n",
            "79it [00:05, 16.58it/s]Epoch [13/30] validation Loss: -3052.4055\n",
            "99it [00:06, 16.81it/s]Epoch [13/30] validation Loss: -3052.1582\n",
            "119it [00:07, 16.68it/s]Epoch [13/30] validation Loss: -3052.6487\n",
            "139it [00:09, 16.69it/s]Epoch [13/30] validation Loss: -3052.0093\n",
            "159it [00:10, 16.80it/s]Epoch [13/30] validation Loss: -3051.6958\n",
            "179it [00:11, 16.60it/s]Epoch [13/30] validation Loss: -3052.7461\n",
            "199it [00:12, 16.69it/s]Epoch [13/30] validation Loss: -3052.0920\n",
            "219it [00:13, 16.84it/s]Epoch [13/30] validation Loss: -3051.7397\n",
            "239it [00:15, 16.79it/s]Epoch [13/30] validation Loss: -3051.7390\n",
            "259it [00:16, 16.72it/s]Epoch [13/30] validation Loss: -3051.0723\n",
            "279it [00:17, 16.76it/s]Epoch [13/30] validation Loss: -3051.4348\n",
            "299it [00:18, 16.71it/s]Epoch [13/30] validation Loss: -3051.3643\n",
            "319it [00:19, 16.70it/s]Epoch [13/30] validation Loss: -3050.9250\n",
            "339it [00:21, 16.80it/s]Epoch [13/30] validation Loss: -3051.4517\n",
            "351it [00:21, 17.51it/s]\n",
            "Pixel Acc:  0.19317230208833275\n",
            "Class Accuracy:  [7.24289258e-01 2.72630120e-01 3.42428859e-03 1.13402996e-04\n",
            " 0.00000000e+00 0.00000000e+00]\n",
            "Mean Class Acc:  0.16674284480978582\n",
            "Freq Weighted IoU:  0.057315231681346376\n",
            "Mean IoU:  0.049980170343584866\n",
            "confusion_matrix [[1.4817795e+07 5.5544460e+06 7.3388000e+04 1.2765000e+04 0.0000000e+00\n",
            "  0.0000000e+00]\n",
            " [9.1819590e+06 3.4625890e+06 4.8577000e+04 7.5590000e+03 0.0000000e+00\n",
            "  0.0000000e+00]\n",
            " [3.7284994e+07 1.3972452e+07 1.7622000e+05 2.8118000e+04 0.0000000e+00\n",
            "  0.0000000e+00]\n",
            " [4.7984840e+06 1.8009730e+06 2.2192000e+04 7.5100000e+02 0.0000000e+00\n",
            "  0.0000000e+00]\n",
            " [2.0275380e+06 7.7233800e+05 1.0116000e+04 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00]\n",
            " [1.0841440e+06 4.0595600e+05 5.0230000e+03 2.8500000e+02 0.0000000e+00\n",
            "  0.0000000e+00]]\n",
            "Epoch [15/30] training Loss: -3051.3372\n",
            "Epoch [15/30] training Loss: -3052.8206\n",
            "Epoch [15/30] training Loss: -3053.6326\n",
            "Epoch [15/30] training Loss: -3054.0520\n",
            "Epoch [15/30] training Loss: -3055.0098\n",
            "Epoch [15/30] training Loss: -3053.5486\n",
            "Epoch [15/30] training Loss: -3052.5781\n",
            "Epoch [15/30] training Loss: -3052.6008\n",
            "Epoch [15/30] training Loss: -3053.8054\n",
            "Epoch [15/30] training Loss: -3055.4724\n",
            "Epoch [15/30] training Loss: -3052.9463\n",
            "Epoch [15/30] training Loss: -3053.7019\n",
            "Epoch [15/30] training Loss: -3053.7766\n",
            "Epoch [15/30] training Loss: -3053.9255\n",
            "Epoch [15/30] training Loss: -3054.0959\n",
            "Epoch [15/30] training Loss: -3053.7368\n",
            "Epoch [15/30] training Loss: -3053.9807\n",
            "Epoch [15/30] training Loss: -3056.1621\n",
            "Epoch [15/30] training Loss: -3053.9182\n",
            "Epoch [15/30] training Loss: -3054.0005\n",
            "Epoch [15/30] training Loss: -3054.1775\n",
            "Epoch [15/30] training Loss: -3054.9624\n",
            "Epoch [15/30] training Loss: -3060.4404\n",
            "Epoch [15/30] training Loss: -3055.2178\n",
            "Epoch [15/30] training Loss: -3046.5286\n",
            "Epoch [15/30] training Loss: -3041.6565\n",
            "Epoch [15/30] training Loss: -3065.5332\n",
            "Epoch [15/30] training Loss: -3052.0415\n",
            "Epoch [15/30] training Loss: -3052.9766\n",
            "Epoch [15/30] training Loss: -3053.2881\n",
            "Epoch [15/30] training Loss: -3052.6030\n",
            "Epoch [15/30] training Loss: -3053.1277\n",
            "Epoch [15/30] training Loss: -3053.5020\n",
            "Epoch [15/30] training Loss: -3049.5371\n",
            "Epoch [15/30] training Loss: -3054.0708\n",
            "Epoch [15/30] training Loss: -3054.2449\n",
            "Epoch [15/30] training Loss: -3054.5122\n",
            "Epoch [15/30] training Loss: -3054.8516\n",
            "Epoch [15/30] training Loss: -3056.7795\n",
            "Epoch [15/30] training Loss: -3052.7395\n",
            "Epoch [15/30] training Loss: -3053.5417\n",
            "Epoch [15/30] training Loss: -3054.9521\n",
            "Epoch [15/30] training Loss: -3052.9360\n",
            "Epoch [15/30] training Loss: -3054.4495\n",
            "Epoch [15/30] training Loss: -3054.1938\n",
            "Epoch [15/30] training Loss: -3053.1956\n",
            "Epoch [15/30] training Loss: -3053.5288\n",
            "Epoch [15/30] training Loss: -3053.7651\n",
            "Epoch [15/30] training Loss: -3053.8179\n",
            "Epoch [15/30] training Loss: -3053.8213\n",
            "Epoch [15/30] training Loss: -3053.8567\n",
            "Epoch [15/30] training Loss: -3053.9907\n",
            "Epoch [15/30] training Loss: -3054.2197\n",
            "Epoch [15/30] training Loss: -3055.8386\n",
            "Epoch [15/30] training Loss: -3053.9822\n",
            "Epoch [15/30] training Loss: -3052.3550\n",
            "Epoch [15/30] training Loss: -3052.5974\n",
            "Epoch [15/30] training Loss: -3053.8484\n",
            "Epoch [15/30] training Loss: -3053.9678\n",
            "Epoch [15/30] training Loss: -3054.0591\n",
            "Epoch [15/30] training Loss: -3054.8987\n",
            "Epoch [15/30] training Loss: -3053.7085\n",
            "Epoch [15/30] training Loss: -3054.0266\n",
            "Epoch [15/30] training Loss: -3053.0337\n",
            "Epoch [15/30] training Loss: -3054.1123\n",
            "Epoch [15/30] training Loss: -3063.8789\n",
            "Epoch [15/30] training Loss: -3052.6406\n",
            "Epoch [15/30] training Loss: -3053.5764\n",
            "Epoch [15/30] training Loss: -3053.8711\n",
            "Epoch [15/30] training Loss: -3053.6294\n",
            "Epoch [15/30] training Loss: -3053.8557\n",
            "0it [00:00, ?it/s]Epoch [14/30] validation Loss: -3053.8811\n",
            "19it [00:01, 11.08it/s]Epoch [14/30] validation Loss: -3053.8660\n",
            "39it [00:03, 16.48it/s]Epoch [14/30] validation Loss: -3053.8953\n",
            "59it [00:04, 16.83it/s]Epoch [14/30] validation Loss: -3053.9031\n",
            "79it [00:05, 16.83it/s]Epoch [14/30] validation Loss: -3053.9224\n",
            "99it [00:06, 16.83it/s]Epoch [14/30] validation Loss: -3053.8977\n",
            "119it [00:07, 16.64it/s]Epoch [14/30] validation Loss: -3053.9314\n",
            "139it [00:09, 16.70it/s]Epoch [14/30] validation Loss: -3053.8962\n",
            "159it [00:10, 16.82it/s]Epoch [14/30] validation Loss: -3053.8652\n",
            "179it [00:11, 16.62it/s]Epoch [14/30] validation Loss: -3053.9431\n",
            "199it [00:12, 16.80it/s]Epoch [14/30] validation Loss: -3053.9021\n",
            "219it [00:13, 16.95it/s]Epoch [14/30] validation Loss: -3053.8738\n",
            "239it [00:14, 16.88it/s]Epoch [14/30] validation Loss: -3053.8735\n",
            "259it [00:16, 16.94it/s]Epoch [14/30] validation Loss: -3053.8381\n",
            "279it [00:17, 16.79it/s]Epoch [14/30] validation Loss: -3053.8430\n",
            "299it [00:18, 16.60it/s]Epoch [14/30] validation Loss: -3053.8416\n",
            "319it [00:19, 16.82it/s]Epoch [14/30] validation Loss: -3053.8113\n",
            "339it [00:20, 16.19it/s]Epoch [14/30] validation Loss: -3053.8618\n",
            "351it [00:21, 17.32it/s]\n",
            "Pixel Acc:  0.03981130578259694\n",
            "Class Accuracy:  [0.00000000e+00 2.82150158e-03 2.00537160e-05 2.51848877e-01\n",
            " 7.47050525e-01 0.00000000e+00]\n",
            "Mean Class Acc:  0.16695682620817864\n",
            "Freq Weighted IoU:  0.005217616247522144\n",
            "Mean IoU:  0.014901319977847197\n",
            "confusion_matrix [[0.0000000e+00 6.6552000e+04 3.1000000e+01 5.1525450e+06 1.5239266e+07\n",
            "  0.0000000e+00]\n",
            " [0.0000000e+00 3.5835000e+04 1.6300000e+02 3.2079330e+06 9.4567530e+06\n",
            "  0.0000000e+00]\n",
            " [0.0000000e+00 1.3698100e+05 1.0320000e+03 1.2983979e+07 3.8339792e+07\n",
            "  0.0000000e+00]\n",
            " [0.0000000e+00 1.5187000e+04 5.3000000e+01 1.6678440e+06 4.9393160e+06\n",
            "  0.0000000e+00]\n",
            " [0.0000000e+00 6.5620000e+03 0.0000000e+00 7.0422400e+05 2.0992060e+06\n",
            "  0.0000000e+00]\n",
            " [0.0000000e+00 3.4950000e+03 2.2000000e+01 3.7481200e+05 1.1170790e+06\n",
            "  0.0000000e+00]]\n",
            "Epoch [16/30] training Loss: -3053.8936\n",
            "Epoch [16/30] training Loss: -3053.9924\n",
            "Epoch [16/30] training Loss: -3054.1514\n",
            "Epoch [16/30] training Loss: -3053.8203\n",
            "Epoch [16/30] training Loss: -3053.9561\n",
            "Epoch [16/30] training Loss: -3053.9890\n",
            "Epoch [16/30] training Loss: -3054.3394\n",
            "Epoch [16/30] training Loss: -3053.9226\n",
            "Epoch [16/30] training Loss: -3053.9634\n",
            "Epoch [16/30] training Loss: -3054.0012\n",
            "Epoch [16/30] training Loss: -3053.9426\n",
            "Epoch [16/30] training Loss: -3053.9653\n",
            "Epoch [16/30] training Loss: -3053.9810\n",
            "Epoch [16/30] training Loss: -3053.9875\n",
            "Epoch [16/30] training Loss: -3053.9902\n",
            "Epoch [16/30] training Loss: -3053.9976\n",
            "Epoch [16/30] training Loss: -3054.0051\n",
            "Epoch [16/30] training Loss: -3054.0410\n",
            "Epoch [16/30] training Loss: -3054.2510\n",
            "Epoch [16/30] training Loss: -3053.6084\n",
            "Epoch [16/30] training Loss: -3056.7573\n",
            "Epoch [16/30] training Loss: -3053.7527\n",
            "Epoch [16/30] training Loss: -3053.0935\n",
            "Epoch [16/30] training Loss: -3053.8623\n",
            "Epoch [16/30] training Loss: -3053.8970\n",
            "Epoch [16/30] training Loss: -3053.9387\n",
            "Epoch [16/30] training Loss: -3053.9688\n",
            "Epoch [16/30] training Loss: -3053.9739\n",
            "Epoch [16/30] training Loss: -3053.9763\n",
            "Epoch [16/30] training Loss: -3053.9834\n",
            "Epoch [16/30] training Loss: -3053.9922\n",
            "Epoch [16/30] training Loss: -3053.9946\n",
            "Epoch [16/30] training Loss: -3053.9944\n",
            "Epoch [16/30] training Loss: -3053.9951\n",
            "Epoch [16/30] training Loss: -3054.0090\n",
            "Epoch [16/30] training Loss: -3054.1694\n",
            "Epoch [16/30] training Loss: -3053.9844\n",
            "Epoch [16/30] training Loss: -3053.9929\n",
            "Epoch [16/30] training Loss: -3054.0010\n",
            "Epoch [16/30] training Loss: -3053.9727\n",
            "Epoch [16/30] training Loss: -3053.9929\n",
            "Epoch [16/30] training Loss: -3053.9998\n",
            "Epoch [16/30] training Loss: -3053.9426\n",
            "Epoch [16/30] training Loss: -3053.9937\n",
            "Epoch [16/30] training Loss: -3053.9971\n",
            "Epoch [16/30] training Loss: -3053.9985\n",
            "Epoch [16/30] training Loss: -3054.0007\n",
            "Epoch [16/30] training Loss: -3054.0105\n",
            "Epoch [16/30] training Loss: -3053.9951\n",
            "Epoch [16/30] training Loss: -3053.9983\n",
            "Epoch [16/30] training Loss: -3054.0020\n",
            "Epoch [16/30] training Loss: -3053.9910\n",
            "Epoch [16/30] training Loss: -3053.9956\n",
            "Epoch [16/30] training Loss: -3054.0098\n",
            "Epoch [16/30] training Loss: -3054.0281\n",
            "Epoch [16/30] training Loss: -3054.0647\n",
            "Epoch [16/30] training Loss: -3053.3740\n",
            "Epoch [16/30] training Loss: -3054.1965\n",
            "Epoch [16/30] training Loss: -3053.6094\n",
            "Epoch [16/30] training Loss: -3054.9033\n",
            "Epoch [16/30] training Loss: -3053.6121\n",
            "Epoch [16/30] training Loss: -3053.8757\n",
            "Epoch [16/30] training Loss: -3053.8420\n",
            "Epoch [16/30] training Loss: -3053.9761\n",
            "Epoch [16/30] training Loss: -3053.9961\n",
            "Epoch [16/30] training Loss: -3054.0029\n",
            "Epoch [16/30] training Loss: -3054.0029\n",
            "Epoch [16/30] training Loss: -3054.0076\n",
            "Epoch [16/30] training Loss: -3054.0205\n",
            "Epoch [16/30] training Loss: -3054.0017\n",
            "Epoch [16/30] training Loss: -3054.0210\n",
            "0it [00:00, ?it/s]Epoch [15/30] validation Loss: -3054.0449\n",
            "19it [00:01, 10.97it/s]Epoch [15/30] validation Loss: -3054.0457\n",
            "39it [00:03, 16.50it/s]Epoch [15/30] validation Loss: -3054.0432\n",
            "59it [00:04, 16.74it/s]Epoch [15/30] validation Loss: -3054.0415\n",
            "79it [00:05, 16.66it/s]Epoch [15/30] validation Loss: -3054.0393\n",
            "99it [00:06, 16.86it/s]Epoch [15/30] validation Loss: -3054.0415\n",
            "119it [00:07, 16.75it/s]Epoch [15/30] validation Loss: -3054.0371\n",
            "139it [00:09, 16.84it/s]Epoch [15/30] validation Loss: -3054.0432\n",
            "159it [00:10, 16.68it/s]Epoch [15/30] validation Loss: -3054.0457\n",
            "179it [00:11, 16.74it/s]Epoch [15/30] validation Loss: -3054.0364\n",
            "199it [00:12, 16.81it/s]Epoch [15/30] validation Loss: -3054.0422\n",
            "219it [00:13, 16.77it/s]Epoch [15/30] validation Loss: -3054.0457\n",
            "239it [00:15, 16.75it/s]Epoch [15/30] validation Loss: -3054.0452\n",
            "259it [00:16, 16.71it/s]Epoch [15/30] validation Loss: -3054.0513\n",
            "279it [00:17, 16.56it/s]Epoch [15/30] validation Loss: -3054.0488\n",
            "299it [00:18, 16.53it/s]Epoch [15/30] validation Loss: -3054.0491\n",
            "319it [00:19, 16.86it/s]Epoch [15/30] validation Loss: -3054.0532\n",
            "339it [00:21, 16.92it/s]Epoch [15/30] validation Loss: -3054.0481\n",
            "351it [00:21, 17.53it/s]\n",
            "Pixel Acc:  0.07296942577803968\n",
            "Class Accuracy:  [0.00000000e+00 1.95495376e-01 4.44743618e-02 1.72472216e-02\n",
            " 7.42376847e-01 1.23712057e-04]\n",
            "Mean Class Acc:  0.1666195864154547\n",
            "Freq Weighted IoU:  0.03634532584674844\n",
            "Mean IoU:  0.028704504117222866\n",
            "confusion_matrix [[0.0000000e+00 3.9751960e+06 9.3979200e+05 3.0414000e+05 1.5239266e+07\n",
            "  0.0000000e+00]\n",
            " [0.0000000e+00 2.4829250e+06 5.7268900e+05 1.8831700e+05 9.4567530e+06\n",
            "  0.0000000e+00]\n",
            " [0.0000000e+00 1.0069048e+07 2.2887300e+06 7.8315200e+05 3.8320086e+07\n",
            "  7.6800000e+02]\n",
            " [0.0000000e+00 1.3043180e+06 2.7780500e+05 1.1421800e+05 4.9254480e+06\n",
            "  6.1100000e+02]\n",
            " [0.0000000e+00 5.4809500e+05 1.0709300e+05 6.8083000e+04 2.0860730e+06\n",
            "  6.4800000e+02]\n",
            " [0.0000000e+00 2.9223700e+05 6.1158000e+04 2.8720000e+04 1.1131080e+06\n",
            "  1.8500000e+02]]\n",
            "Epoch [17/30] training Loss: -3054.0696\n",
            "Epoch [17/30] training Loss: -3053.9973\n",
            "Epoch [17/30] training Loss: -3054.0015\n",
            "Epoch [17/30] training Loss: -3054.0039\n",
            "Epoch [17/30] training Loss: -3054.0159\n",
            "Epoch [17/30] training Loss: -3053.9976\n",
            "Epoch [17/30] training Loss: -3053.9993\n",
            "Epoch [17/30] training Loss: -3054.0007\n",
            "Epoch [17/30] training Loss: -3054.0049\n",
            "Epoch [17/30] training Loss: -3053.9875\n",
            "Epoch [17/30] training Loss: -3053.9983\n",
            "Epoch [17/30] training Loss: -3054.0056\n",
            "Epoch [17/30] training Loss: -3053.6938\n",
            "Epoch [17/30] training Loss: -3053.9832\n",
            "Epoch [17/30] training Loss: -3053.9941\n",
            "Epoch [17/30] training Loss: -3054.0112\n",
            "Epoch [17/30] training Loss: -3053.9741\n",
            "Epoch [17/30] training Loss: -3052.6855\n",
            "Epoch [17/30] training Loss: -3053.9990\n",
            "Epoch [17/30] training Loss: -3054.0024\n",
            "Epoch [17/30] training Loss: -3054.0078\n",
            "Epoch [17/30] training Loss: -3053.9941\n",
            "Epoch [17/30] training Loss: -3053.9993\n",
            "Epoch [17/30] training Loss: -3053.9990\n",
            "Epoch [17/30] training Loss: -3054.0002\n",
            "Epoch [17/30] training Loss: -3054.0015\n",
            "Epoch [17/30] training Loss: -3054.0039\n",
            "Epoch [17/30] training Loss: -3053.9810\n",
            "Epoch [17/30] training Loss: -3053.9995\n",
            "Epoch [17/30] training Loss: -3054.0068\n",
            "Epoch [17/30] training Loss: -3053.0820\n",
            "Epoch [17/30] training Loss: -3053.9768\n",
            "Epoch [17/30] training Loss: -3053.9995\n",
            "Epoch [17/30] training Loss: -3057.2979\n",
            "Epoch [17/30] training Loss: -3053.9766\n",
            "Epoch [17/30] training Loss: -3053.9919\n",
            "Epoch [17/30] training Loss: -3053.9978\n",
            "Epoch [17/30] training Loss: -3053.9958\n",
            "Epoch [17/30] training Loss: -3054.0044\n",
            "Epoch [17/30] training Loss: -3054.0186\n",
            "Epoch [17/30] training Loss: -3054.0000\n",
            "Epoch [17/30] training Loss: -3054.0012\n",
            "Epoch [17/30] training Loss: -3054.0022\n",
            "Epoch [17/30] training Loss: -3054.0056\n",
            "Epoch [17/30] training Loss: -3054.0884\n",
            "Epoch [17/30] training Loss: -3054.0002\n",
            "Epoch [17/30] training Loss: -3054.0122\n",
            "Epoch [17/30] training Loss: -3053.9939\n",
            "Epoch [17/30] training Loss: -3053.9995\n",
            "Epoch [17/30] training Loss: -3054.0225\n",
            "Epoch [17/30] training Loss: -3054.0845\n",
            "Epoch [17/30] training Loss: -3057.4497\n",
            "Epoch [17/30] training Loss: -3055.1826\n",
            "Epoch [17/30] training Loss: -3053.8562\n",
            "Epoch [17/30] training Loss: -3052.6240\n",
            "Epoch [17/30] training Loss: -3053.8105\n",
            "Epoch [17/30] training Loss: -3053.5874\n",
            "Epoch [17/30] training Loss: -3053.9399\n",
            "Epoch [17/30] training Loss: -3053.8770\n",
            "Epoch [17/30] training Loss: -3053.9470\n",
            "Epoch [17/30] training Loss: -3053.9685\n",
            "Epoch [17/30] training Loss: -3053.9814\n",
            "Epoch [17/30] training Loss: -3053.9875\n",
            "Epoch [17/30] training Loss: -3053.9919\n",
            "Epoch [17/30] training Loss: -3053.9944\n",
            "Epoch [17/30] training Loss: -3053.9944\n",
            "Epoch [17/30] training Loss: -3054.0010\n",
            "Epoch [17/30] training Loss: -3053.9861\n",
            "Epoch [17/30] training Loss: -3054.0044\n",
            "Epoch [17/30] training Loss: -3054.0059\n",
            "Epoch [17/30] training Loss: -3054.0093\n",
            "0it [00:00, ?it/s]Epoch [16/30] validation Loss: -3054.0078\n",
            "19it [00:01, 11.12it/s]Epoch [16/30] validation Loss: -3054.0076\n",
            "39it [00:03, 16.43it/s]Epoch [16/30] validation Loss: -3054.0073\n",
            "59it [00:04, 16.81it/s]Epoch [16/30] validation Loss: -3054.0071\n",
            "79it [00:05, 16.48it/s]Epoch [16/30] validation Loss: -3054.0066\n",
            "99it [00:06, 16.75it/s]Epoch [16/30] validation Loss: -3054.0068\n",
            "119it [00:07, 16.83it/s]Epoch [16/30] validation Loss: -3054.0061\n",
            "139it [00:09, 16.79it/s]Epoch [16/30] validation Loss: -3054.0071\n",
            "159it [00:10, 16.84it/s]Epoch [16/30] validation Loss: -3054.0076\n",
            "179it [00:11, 16.70it/s]Epoch [16/30] validation Loss: -3054.0061\n",
            "199it [00:12, 16.67it/s]Epoch [16/30] validation Loss: -3054.0073\n",
            "219it [00:13, 16.88it/s]Epoch [16/30] validation Loss: -3054.0076\n",
            "239it [00:15, 16.85it/s]Epoch [16/30] validation Loss: -3054.0073\n",
            "259it [00:16, 16.82it/s]Epoch [16/30] validation Loss: -3054.0088\n",
            "279it [00:17, 16.71it/s]Epoch [16/30] validation Loss: -3054.0081\n",
            "299it [00:18, 16.79it/s]Epoch [16/30] validation Loss: -3054.0081\n",
            "319it [00:19, 16.74it/s]Epoch [16/30] validation Loss: -3054.0090\n",
            "339it [00:20, 16.72it/s]Epoch [16/30] validation Loss: -3054.0081\n",
            "351it [00:21, 17.48it/s]\n",
            "Pixel Acc:  0.05612438612693499\n",
            "Class Accuracy:  [0.         0.01091492 0.05002504 0.00238675 0.93729769 0.        ]\n",
            "Mean Class Acc:  0.1667707336737245\n",
            "Freq Weighted IoU:  0.028198039519322614\n",
            "Mean IoU:  0.014967793892063075\n",
            "confusion_matrix [[0.0000000e+00 2.1911600e+05 1.0674330e+06 4.2956000e+04 1.9128889e+07\n",
            "  0.0000000e+00]\n",
            " [0.0000000e+00 1.3862700e+05 6.4613900e+05 2.6664000e+04 1.1889254e+07\n",
            "  0.0000000e+00]\n",
            " [0.0000000e+00 5.9203900e+05 2.5743780e+06 1.0963000e+05 4.8185737e+07\n",
            "  0.0000000e+00]\n",
            " [0.0000000e+00 7.9013000e+04 3.2420900e+05 1.5806000e+04 6.2033720e+06\n",
            "  0.0000000e+00]\n",
            " [0.0000000e+00 4.4751000e+04 1.2287500e+05 8.5670000e+03 2.6337990e+06\n",
            "  0.0000000e+00]\n",
            " [0.0000000e+00 1.9838000e+04 7.0419000e+04 3.7450000e+03 1.4014060e+06\n",
            "  0.0000000e+00]]\n",
            "Epoch [18/30] training Loss: -3054.0083\n",
            "Epoch [18/30] training Loss: -3054.0156\n",
            "Epoch [18/30] training Loss: -3053.9690\n",
            "Epoch [18/30] training Loss: -3054.0039\n",
            "Epoch [18/30] training Loss: -3053.9983\n",
            "Epoch [18/30] training Loss: -3053.9231\n",
            "Epoch [18/30] training Loss: -3053.9929\n",
            "Epoch [18/30] training Loss: -3054.0725\n",
            "Epoch [18/30] training Loss: -3053.9917\n",
            "Epoch [18/30] training Loss: -3054.0027\n",
            "Epoch [18/30] training Loss: -3054.0029\n",
            "Epoch [18/30] training Loss: -3054.0088\n",
            "Epoch [18/30] training Loss: -3053.9666\n",
            "Epoch [18/30] training Loss: -3053.9980\n",
            "Epoch [18/30] training Loss: -3053.9905\n",
            "Epoch [18/30] training Loss: -3054.0073\n",
            "Epoch [18/30] training Loss: -3054.4597\n",
            "Epoch [18/30] training Loss: -3054.0032\n",
            "Epoch [18/30] training Loss: -3054.0054\n",
            "Epoch [18/30] training Loss: -3054.0156\n",
            "Epoch [18/30] training Loss: -3053.9951\n",
            "Epoch [18/30] training Loss: -3053.9385\n",
            "Epoch [18/30] training Loss: -3053.9985\n",
            "Epoch [18/30] training Loss: -3054.0112\n",
            "Epoch [18/30] training Loss: -3054.0461\n",
            "Epoch [18/30] training Loss: -3054.2009\n",
            "Epoch [18/30] training Loss: -3054.2302\n",
            "Epoch [18/30] training Loss: -3053.7349\n",
            "Epoch [18/30] training Loss: -3050.9922\n",
            "Epoch [18/30] training Loss: -3053.8083\n",
            "Epoch [18/30] training Loss: -3053.5986\n",
            "Epoch [18/30] training Loss: -3053.9167\n",
            "Epoch [18/30] training Loss: -3053.7932\n",
            "Epoch [18/30] training Loss: -3053.9319\n",
            "Epoch [18/30] training Loss: -3053.9685\n",
            "Epoch [18/30] training Loss: -3053.9856\n",
            "Epoch [18/30] training Loss: -3053.9846\n",
            "Epoch [18/30] training Loss: -3053.9963\n",
            "Epoch [18/30] training Loss: -3054.0005\n",
            "Epoch [18/30] training Loss: -3054.0017\n",
            "Epoch [18/30] training Loss: -3054.0081\n",
            "Epoch [18/30] training Loss: -3054.0149\n",
            "Epoch [18/30] training Loss: -3054.0217\n",
            "Epoch [18/30] training Loss: -3054.0425\n",
            "Epoch [18/30] training Loss: -3053.9861\n",
            "Epoch [18/30] training Loss: -3054.0054\n",
            "Epoch [18/30] training Loss: -3054.0088\n",
            "Epoch [18/30] training Loss: -3054.0122\n",
            "Epoch [18/30] training Loss: -3054.0540\n",
            "Epoch [18/30] training Loss: -3053.9771\n",
            "Epoch [18/30] training Loss: -3053.9907\n",
            "Epoch [18/30] training Loss: -3053.9995\n",
            "Epoch [18/30] training Loss: -3054.0107\n",
            "Epoch [18/30] training Loss: -3053.7314\n",
            "Epoch [18/30] training Loss: -3054.0090\n",
            "Epoch [18/30] training Loss: -3053.8777\n",
            "Epoch [18/30] training Loss: -3053.9810\n",
            "Epoch [18/30] training Loss: -3053.9966\n",
            "Epoch [18/30] training Loss: -3054.0005\n",
            "Epoch [18/30] training Loss: -3054.0066\n",
            "Epoch [18/30] training Loss: -3054.0107\n",
            "Epoch [18/30] training Loss: -3054.0547\n",
            "Epoch [18/30] training Loss: -3054.0054\n",
            "Epoch [18/30] training Loss: -3054.0120\n",
            "Epoch [18/30] training Loss: -3054.0803\n",
            "Epoch [18/30] training Loss: -3053.9722\n",
            "Epoch [18/30] training Loss: -3053.9941\n",
            "Epoch [18/30] training Loss: -3054.0122\n",
            "Epoch [18/30] training Loss: -3054.0491\n",
            "Epoch [18/30] training Loss: -3054.2354\n",
            "Epoch [18/30] training Loss: -3053.9978\n",
            "0it [00:00, ?it/s]Epoch [17/30] validation Loss: -3054.1416\n",
            "19it [00:01, 11.15it/s]Epoch [17/30] validation Loss: -3054.1616\n",
            "39it [00:03, 16.55it/s]Epoch [17/30] validation Loss: -3054.1238\n",
            "59it [00:04, 16.76it/s]Epoch [17/30] validation Loss: -3054.1152\n",
            "79it [00:05, 16.59it/s]Epoch [17/30] validation Loss: -3054.0911\n",
            "99it [00:06, 16.69it/s]Epoch [17/30] validation Loss: -3054.1226\n",
            "119it [00:07, 16.69it/s]Epoch [17/30] validation Loss: -3054.0811\n",
            "139it [00:09, 16.64it/s]Epoch [17/30] validation Loss: -3054.1233\n",
            "159it [00:10, 16.79it/s]Epoch [17/30] validation Loss: -3054.1624\n",
            "179it [00:11, 16.85it/s]Epoch [17/30] validation Loss: -3054.0662\n",
            "199it [00:12, 16.90it/s]Epoch [17/30] validation Loss: -3054.1160\n",
            "219it [00:13, 16.89it/s]Epoch [17/30] validation Loss: -3054.1511\n",
            "239it [00:14, 16.85it/s]Epoch [17/30] validation Loss: -3054.1514\n",
            "259it [00:16, 16.93it/s]Epoch [17/30] validation Loss: -3054.1938\n",
            "279it [00:17, 16.77it/s]Epoch [17/30] validation Loss: -3054.1899\n",
            "299it [00:18, 16.83it/s]Epoch [17/30] validation Loss: -3054.1907\n",
            "319it [00:19, 16.73it/s]Epoch [17/30] validation Loss: -3054.2288\n",
            "339it [00:20, 16.90it/s]Epoch [17/30] validation Loss: -3054.1650\n",
            "351it [00:21, 17.57it/s]\n",
            "Pixel Acc:  0.16960997318832158\n",
            "Class Accuracy:  [0.74489063 0.         0.         0.06327223 0.19492084 0.        ]\n",
            "Mean Class Acc:  0.16718061624099648\n",
            "Freq Weighted IoU:  0.04587387960079042\n",
            "Mean IoU:  0.043374469071683706\n",
            "confusion_matrix [[15239266.        0.        0.  1329505.  3889623.        0.]\n",
            " [ 9456753.        0.        0.   811430.  2432501.        0.]\n",
            " [38320086.        0.        0.  3275869.  9865829.        0.]\n",
            " [ 4925448.        0.        0.   419014.  1277938.        0.]\n",
            " [ 2086073.        0.        0.   176193.   547726.        0.]\n",
            " [ 1113108.        0.        0.    93993.   288307.        0.]]\n",
            "Epoch [19/30] training Loss: -3054.1196\n",
            "Epoch [19/30] training Loss: -3052.0671\n",
            "Epoch [19/30] training Loss: -3053.7847\n",
            "Epoch [19/30] training Loss: -3053.4517\n",
            "Epoch [19/30] training Loss: -3053.9048\n",
            "Epoch [19/30] training Loss: -3056.3123\n",
            "Epoch [19/30] training Loss: -3053.9541\n",
            "Epoch [19/30] training Loss: -3053.9919\n",
            "Epoch [19/30] training Loss: -3053.9988\n",
            "Epoch [19/30] training Loss: -3054.0024\n",
            "Epoch [19/30] training Loss: -3054.0078\n",
            "Epoch [19/30] training Loss: -3054.0073\n",
            "Epoch [19/30] training Loss: -3054.0210\n",
            "Epoch [19/30] training Loss: -3054.0369\n",
            "Epoch [19/30] training Loss: -3053.8064\n",
            "Epoch [19/30] training Loss: -3054.0000\n",
            "Epoch [19/30] training Loss: -3053.9431\n",
            "Epoch [19/30] training Loss: -3054.0107\n",
            "Epoch [19/30] training Loss: -3054.0342\n",
            "Epoch [19/30] training Loss: -3053.9390\n",
            "Epoch [19/30] training Loss: -3053.9944\n",
            "Epoch [19/30] training Loss: -3054.0125\n",
            "Epoch [19/30] training Loss: -3054.0278\n",
            "Epoch [19/30] training Loss: -3052.2502\n",
            "Epoch [19/30] training Loss: -3053.9700\n",
            "Epoch [19/30] training Loss: -3054.0281\n",
            "Epoch [19/30] training Loss: -3053.8479\n",
            "Epoch [19/30] training Loss: -3053.9778\n",
            "Epoch [19/30] training Loss: -3052.9478\n",
            "Epoch [19/30] training Loss: -3053.9873\n",
            "Epoch [19/30] training Loss: -3054.0032\n",
            "Epoch [19/30] training Loss: -3054.0088\n",
            "Epoch [19/30] training Loss: -3054.0200\n",
            "Epoch [19/30] training Loss: -3054.0425\n",
            "Epoch [19/30] training Loss: -3054.0569\n",
            "Epoch [19/30] training Loss: -3053.9792\n",
            "Epoch [19/30] training Loss: -3053.9927\n",
            "Epoch [19/30] training Loss: -3053.3113\n",
            "Epoch [19/30] training Loss: -3053.9751\n",
            "Epoch [19/30] training Loss: -3053.9937\n",
            "Epoch [19/30] training Loss: -3053.9983\n",
            "Epoch [19/30] training Loss: -3054.0125\n",
            "Epoch [19/30] training Loss: -3053.9973\n",
            "Epoch [19/30] training Loss: -3053.9995\n",
            "Epoch [19/30] training Loss: -3053.9399\n",
            "Epoch [19/30] training Loss: -3053.9951\n",
            "Epoch [19/30] training Loss: -3054.0005\n",
            "Epoch [19/30] training Loss: -3054.0034\n",
            "Epoch [19/30] training Loss: -3054.0444\n",
            "Epoch [19/30] training Loss: -3053.9980\n",
            "Epoch [19/30] training Loss: -3054.0012\n",
            "Epoch [19/30] training Loss: -3054.0046\n",
            "Epoch [19/30] training Loss: -3054.0571\n",
            "Epoch [19/30] training Loss: -3054.0093\n",
            "Epoch [19/30] training Loss: -3053.9922\n",
            "Epoch [19/30] training Loss: -3054.0100\n",
            "Epoch [19/30] training Loss: -3054.0439\n",
            "Epoch [19/30] training Loss: -3053.4111\n",
            "Epoch [19/30] training Loss: -3053.6143\n",
            "Epoch [19/30] training Loss: -3053.9985\n",
            "Epoch [19/30] training Loss: -3053.8555\n",
            "Epoch [19/30] training Loss: -3053.9724\n",
            "Epoch [19/30] training Loss: -3053.9292\n",
            "Epoch [19/30] training Loss: -3053.9536\n",
            "Epoch [19/30] training Loss: -3053.9919\n",
            "Epoch [19/30] training Loss: -3053.9961\n",
            "Epoch [19/30] training Loss: -3054.0007\n",
            "Epoch [19/30] training Loss: -3054.0044\n",
            "Epoch [19/30] training Loss: -3054.0100\n",
            "Epoch [19/30] training Loss: -3053.9724\n",
            "Epoch [19/30] training Loss: -3053.9963\n",
            "0it [00:00, ?it/s]Epoch [18/30] validation Loss: -3053.9983\n",
            "19it [00:01, 11.18it/s]Epoch [18/30] validation Loss: -3053.9985\n",
            "39it [00:03, 16.47it/s]Epoch [18/30] validation Loss: -3053.9983\n",
            "59it [00:04, 16.84it/s]Epoch [18/30] validation Loss: -3053.9988\n",
            "79it [00:05, 16.89it/s]Epoch [18/30] validation Loss: -3053.9985\n",
            "99it [00:06, 16.86it/s]Epoch [18/30] validation Loss: -3053.9985\n",
            "119it [00:07, 16.88it/s]Epoch [18/30] validation Loss: -3053.9988\n",
            "139it [00:09, 16.81it/s]Epoch [18/30] validation Loss: -3053.9985\n",
            "159it [00:10, 16.85it/s]Epoch [18/30] validation Loss: -3053.9985\n",
            "179it [00:11, 16.81it/s]Epoch [18/30] validation Loss: -3053.9988\n",
            "199it [00:12, 16.86it/s]Epoch [18/30] validation Loss: -3053.9988\n",
            "219it [00:13, 16.98it/s]Epoch [18/30] validation Loss: -3053.9985\n",
            "239it [00:14, 16.74it/s]Epoch [18/30] validation Loss: -3053.9985\n",
            "259it [00:16, 16.97it/s]Epoch [18/30] validation Loss: -3053.9983\n",
            "279it [00:17, 17.03it/s]Epoch [18/30] validation Loss: -3053.9985\n",
            "299it [00:18, 16.90it/s]Epoch [18/30] validation Loss: -3053.9983\n",
            "319it [00:19, 16.74it/s]Epoch [18/30] validation Loss: -3053.9985\n",
            "339it [00:20, 16.85it/s]Epoch [18/30] validation Loss: -3053.9983\n",
            "351it [00:21, 17.58it/s]\n",
            "Pixel Acc:  0.22641245358307582\n",
            "Class Accuracy:  [0.9341809  0.00471982 0.04573001 0.01166556 0.01103882 0.        ]\n",
            "Mean Class Acc:  0.16788918687566912\n",
            "Freq Weighted IoU:  0.07044202289557029\n",
            "Mean IoU:  0.04661171928574994\n",
            "confusion_matrix [[1.9111841e+07 9.7254000e+04 9.5983700e+05 2.5919000e+05 3.0272000e+04\n",
            "  0.0000000e+00]\n",
            " [1.1877250e+07 5.9945000e+04 5.8566600e+05 1.5850900e+05 1.9314000e+04\n",
            "  0.0000000e+00]\n",
            " [4.8121554e+07 2.3849900e+05 2.3533480e+06 6.3239400e+05 1.1598900e+05\n",
            "  0.0000000e+00]\n",
            " [6.1860910e+06 3.0856000e+04 2.9287500e+05 7.7254000e+04 3.5324000e+04\n",
            "  0.0000000e+00]\n",
            " [2.6186070e+06 1.3863000e+04 1.1652000e+05 2.9983000e+04 3.1019000e+04\n",
            "  0.0000000e+00]\n",
            " [1.3964100e+06 6.9920000e+03 6.4854000e+04 1.7045000e+04 1.0107000e+04\n",
            "  0.0000000e+00]]\n",
            "Epoch [20/30] training Loss: -3053.9976\n",
            "Epoch [20/30] training Loss: -3054.0002\n",
            "Epoch [20/30] training Loss: -3054.0027\n",
            "Epoch [20/30] training Loss: -3054.0063\n",
            "Epoch [20/30] training Loss: -3054.0332\n",
            "Epoch [20/30] training Loss: -3053.9971\n",
            "Epoch [20/30] training Loss: -3054.0007\n",
            "Epoch [20/30] training Loss: -3054.0049\n",
            "Epoch [20/30] training Loss: -3054.0156\n",
            "Epoch [20/30] training Loss: -3054.1106\n",
            "Epoch [20/30] training Loss: -3053.9919\n",
            "Epoch [20/30] training Loss: -3054.0049\n",
            "Epoch [20/30] training Loss: -3054.0295\n",
            "Epoch [20/30] training Loss: -3054.1379\n",
            "Epoch [20/30] training Loss: -3053.8242\n",
            "Epoch [20/30] training Loss: -3053.9246\n",
            "Epoch [20/30] training Loss: -3053.6917\n",
            "Epoch [20/30] training Loss: -3053.9150\n",
            "Epoch [20/30] training Loss: -3053.8999\n",
            "Epoch [20/30] training Loss: -3053.9636\n",
            "Epoch [20/30] training Loss: -3053.9854\n",
            "Epoch [20/30] training Loss: -3053.9922\n",
            "Epoch [20/30] training Loss: -3053.9966\n",
            "Epoch [20/30] training Loss: -3053.9995\n",
            "Epoch [20/30] training Loss: -3054.0017\n",
            "Epoch [20/30] training Loss: -3054.0027\n",
            "Epoch [20/30] training Loss: -3054.0044\n",
            "Epoch [20/30] training Loss: -3054.0059\n",
            "Epoch [20/30] training Loss: -3054.0073\n",
            "Epoch [20/30] training Loss: -3054.0149\n",
            "Epoch [20/30] training Loss: -3053.9739\n",
            "Epoch [20/30] training Loss: -3054.0012\n",
            "Epoch [20/30] training Loss: -3054.0054\n",
            "Epoch [20/30] training Loss: -3054.0095\n",
            "Epoch [20/30] training Loss: -3054.0186\n",
            "Epoch [20/30] training Loss: -3053.9473\n",
            "Epoch [20/30] training Loss: -3054.0034\n",
            "Epoch [20/30] training Loss: -3055.2537\n",
            "Epoch [20/30] training Loss: -3054.0051\n",
            "Epoch [20/30] training Loss: -3053.9861\n",
            "Epoch [20/30] training Loss: -3053.9995\n",
            "Epoch [20/30] training Loss: -3054.0210\n",
            "Epoch [20/30] training Loss: -3054.1196\n",
            "Epoch [20/30] training Loss: -3053.9656\n",
            "Epoch [20/30] training Loss: -3053.0417\n",
            "Epoch [20/30] training Loss: -3053.8872\n",
            "Epoch [20/30] training Loss: -3054.1348\n",
            "Epoch [20/30] training Loss: -3053.9670\n",
            "Epoch [20/30] training Loss: -3053.9919\n",
            "Epoch [20/30] training Loss: -3054.0005\n",
            "Epoch [20/30] training Loss: -3053.9912\n",
            "Epoch [20/30] training Loss: -3054.0073\n",
            "Epoch [20/30] training Loss: -3054.0073\n",
            "Epoch [20/30] training Loss: -3054.0139\n",
            "Epoch [20/30] training Loss: -3054.0232\n",
            "Epoch [20/30] training Loss: -3054.0947\n",
            "Epoch [20/30] training Loss: -3053.9714\n",
            "Epoch [20/30] training Loss: -3053.9871\n",
            "Epoch [20/30] training Loss: -3053.6152\n",
            "Epoch [20/30] training Loss: -3053.9812\n",
            "Epoch [20/30] training Loss: -3053.9941\n",
            "Epoch [20/30] training Loss: -3053.9973\n",
            "Epoch [20/30] training Loss: -3053.9985\n",
            "Epoch [20/30] training Loss: -3054.0007\n",
            "Epoch [20/30] training Loss: -3053.9824\n",
            "Epoch [20/30] training Loss: -3053.9976\n",
            "Epoch [20/30] training Loss: -3054.0010\n",
            "Epoch [20/30] training Loss: -3054.3760\n",
            "Epoch [20/30] training Loss: -3053.9993\n",
            "Epoch [20/30] training Loss: -3054.0022\n",
            "Epoch [20/30] training Loss: -3053.9924\n",
            "0it [00:00, ?it/s]Epoch [19/30] validation Loss: -3053.9958\n",
            "19it [00:01, 11.27it/s]Epoch [19/30] validation Loss: -3053.9958\n",
            "39it [00:03, 16.57it/s]Epoch [19/30] validation Loss: -3053.9961\n",
            "59it [00:04, 16.95it/s]Epoch [19/30] validation Loss: -3053.9961\n",
            "79it [00:05, 16.72it/s]Epoch [19/30] validation Loss: -3053.9961\n",
            "99it [00:06, 16.77it/s]Epoch [19/30] validation Loss: -3053.9961\n",
            "119it [00:07, 16.73it/s]Epoch [19/30] validation Loss: -3053.9961\n",
            "139it [00:09, 16.61it/s]Epoch [19/30] validation Loss: -3053.9961\n",
            "159it [00:10, 16.60it/s]Epoch [19/30] validation Loss: -3053.9958\n",
            "179it [00:11, 16.41it/s]Epoch [19/30] validation Loss: -3053.9961\n",
            "199it [00:12, 16.76it/s]Epoch [19/30] validation Loss: -3053.9958\n",
            "219it [00:13, 16.75it/s]Epoch [19/30] validation Loss: -3053.9958\n",
            "239it [00:14, 16.77it/s]Epoch [19/30] validation Loss: -3053.9958\n",
            "259it [00:16, 16.73it/s]Epoch [19/30] validation Loss: -3053.9956\n",
            "279it [00:17, 16.57it/s]Epoch [19/30] validation Loss: -3053.9956\n",
            "299it [00:18, 16.67it/s]Epoch [19/30] validation Loss: -3053.9956\n",
            "319it [00:19, 16.71it/s]Epoch [19/30] validation Loss: -3053.9956\n",
            "339it [00:20, 16.65it/s]Epoch [19/30] validation Loss: -3053.9958\n",
            "351it [00:21, 17.33it/s]\n",
            "Pixel Acc:  0.21308297336492268\n",
            "Class Accuracy:  [9.93803082e-01 0.00000000e+00 0.00000000e+00 2.66972699e-03\n",
            " 3.68719911e-03 9.16137937e-05]\n",
            "Mean Class Acc:  0.16670860356716777\n",
            "Freq Weighted IoU:  0.046059516284452255\n",
            "Mean IoU:  0.036634333019011096\n",
            "confusion_matrix [[2.0331615e+07 0.0000000e+00 0.0000000e+00 5.4099000e+04 6.6267000e+04\n",
            "  6.4130000e+03]\n",
            " [1.2623269e+07 0.0000000e+00 0.0000000e+00 3.0315000e+04 4.3430000e+04\n",
            "  3.6700000e+03]\n",
            " [5.1149167e+07 0.0000000e+00 0.0000000e+00 1.2059100e+05 1.7840700e+05\n",
            "  1.3619000e+04]\n",
            " [6.5810040e+06 0.0000000e+00 0.0000000e+00 1.7680000e+04 2.3366000e+04\n",
            "  3.5000000e+02]\n",
            " [2.7909200e+06 0.0000000e+00 0.0000000e+00 8.7110000e+03 1.0361000e+04\n",
            "  0.0000000e+00]\n",
            " [1.4859010e+06 0.0000000e+00 0.0000000e+00 4.0620000e+03 5.3080000e+03\n",
            "  1.3700000e+02]]\n",
            "Epoch [21/30] training Loss: -3053.9946\n",
            "Epoch [21/30] training Loss: -3053.9966\n",
            "Epoch [21/30] training Loss: -3053.9968\n",
            "Epoch [21/30] training Loss: -3053.9980\n",
            "Epoch [21/30] training Loss: -3053.9978\n",
            "Epoch [21/30] training Loss: -3053.9985\n",
            "Epoch [21/30] training Loss: -3053.9988\n",
            "Epoch [21/30] training Loss: -3053.9985\n",
            "Epoch [21/30] training Loss: -3053.9983\n",
            "Epoch [21/30] training Loss: -3053.9988\n",
            "Epoch [21/30] training Loss: -3053.9993\n",
            "Epoch [21/30] training Loss: -3054.0002\n",
            "Epoch [21/30] training Loss: -3054.0007\n",
            "Epoch [21/30] training Loss: -3054.0017\n",
            "Epoch [21/30] training Loss: -3054.0037\n",
            "Epoch [21/30] training Loss: -3054.0120\n",
            "Epoch [21/30] training Loss: -3053.9380\n",
            "Epoch [21/30] training Loss: -3053.9768\n",
            "Epoch [21/30] training Loss: -3053.9609\n",
            "Epoch [21/30] training Loss: -3053.9902\n",
            "Epoch [21/30] training Loss: -3053.9902\n",
            "Epoch [21/30] training Loss: -3053.9941\n",
            "Epoch [21/30] training Loss: -3053.9954\n",
            "Epoch [21/30] training Loss: -3053.9983\n",
            "Epoch [21/30] training Loss: -3053.9990\n",
            "Epoch [21/30] training Loss: -3053.9990\n",
            "Epoch [21/30] training Loss: -3053.9390\n",
            "Epoch [21/30] training Loss: -3053.9995\n",
            "Epoch [21/30] training Loss: -3053.9995\n",
            "Epoch [21/30] training Loss: -3053.9995\n",
            "Epoch [21/30] training Loss: -3053.9998\n",
            "Epoch [21/30] training Loss: -3054.0005\n",
            "Epoch [21/30] training Loss: -3054.0005\n",
            "Epoch [21/30] training Loss: -3054.0007\n",
            "Epoch [21/30] training Loss: -3054.0017\n",
            "Epoch [21/30] training Loss: -3053.9988\n",
            "Epoch [21/30] training Loss: -3054.0002\n",
            "Epoch [21/30] training Loss: -3054.0007\n",
            "Epoch [21/30] training Loss: -3054.0032\n",
            "Epoch [21/30] training Loss: -3053.9988\n",
            "Epoch [21/30] training Loss: -3054.0105\n",
            "Epoch [21/30] training Loss: -3053.9885\n",
            "Epoch [21/30] training Loss: -3053.9983\n",
            "Epoch [21/30] training Loss: -3054.0032\n",
            "Epoch [21/30] training Loss: -3054.0112\n",
            "Epoch [21/30] training Loss: -3054.0366\n",
            "Epoch [21/30] training Loss: -3053.9980\n",
            "Epoch [21/30] training Loss: -3053.9902\n",
            "Epoch [21/30] training Loss: -3053.9949\n",
            "Epoch [21/30] training Loss: -3053.9971\n",
            "Epoch [21/30] training Loss: -3053.9978\n",
            "Epoch [21/30] training Loss: -3053.9988\n",
            "Epoch [21/30] training Loss: -3053.9995\n",
            "Epoch [21/30] training Loss: -3053.9998\n",
            "Epoch [21/30] training Loss: -3054.0000\n",
            "Epoch [21/30] training Loss: -3054.0005\n",
            "Epoch [21/30] training Loss: -3054.0010\n",
            "Epoch [21/30] training Loss: -3054.0017\n",
            "Epoch [21/30] training Loss: -3054.0112\n",
            "Epoch [21/30] training Loss: -3054.0029\n",
            "Epoch [21/30] training Loss: -3053.9980\n",
            "Epoch [21/30] training Loss: -3053.9951\n",
            "Epoch [21/30] training Loss: -3054.0012\n",
            "Epoch [21/30] training Loss: -3054.0120\n",
            "Epoch [21/30] training Loss: -3053.9175\n",
            "Epoch [21/30] training Loss: -3054.0093\n",
            "Epoch [21/30] training Loss: -3054.0264\n",
            "Epoch [21/30] training Loss: -3053.9731\n",
            "Epoch [21/30] training Loss: -3053.9902\n",
            "Epoch [21/30] training Loss: -3053.9956\n",
            "Epoch [21/30] training Loss: -3053.9963\n",
            "0it [00:00, ?it/s]Epoch [20/30] validation Loss: -3053.9971\n",
            "19it [00:01, 11.05it/s]Epoch [20/30] validation Loss: -3053.9968\n",
            "39it [00:03, 16.54it/s]Epoch [20/30] validation Loss: -3053.9973\n",
            "59it [00:04, 16.82it/s]Epoch [20/30] validation Loss: -3053.9976\n",
            "79it [00:05, 16.74it/s]Epoch [20/30] validation Loss: -3053.9978\n",
            "99it [00:06, 16.52it/s]Epoch [20/30] validation Loss: -3053.9973\n",
            "119it [00:07, 16.83it/s]Epoch [20/30] validation Loss: -3053.9980\n",
            "139it [00:09, 16.71it/s]Epoch [20/30] validation Loss: -3053.9973\n",
            "159it [00:10, 16.56it/s]Epoch [20/30] validation Loss: -3053.9966\n",
            "179it [00:11, 16.77it/s]Epoch [20/30] validation Loss: -3053.9985\n",
            "199it [00:12, 16.70it/s]Epoch [20/30] validation Loss: -3053.9976\n",
            "219it [00:13, 16.80it/s]Epoch [20/30] validation Loss: -3053.9968\n",
            "239it [00:15, 16.79it/s]Epoch [20/30] validation Loss: -3053.9968\n",
            "259it [00:16, 16.83it/s]Epoch [20/30] validation Loss: -3053.9961\n",
            "279it [00:17, 16.83it/s]Epoch [20/30] validation Loss: -3053.9963\n",
            "299it [00:18, 16.70it/s]Epoch [20/30] validation Loss: -3053.9961\n",
            "319it [00:19, 16.82it/s]Epoch [20/30] validation Loss: -3053.9958\n",
            "339it [00:20, 16.78it/s]Epoch [20/30] validation Loss: -3053.9963\n",
            "351it [00:21, 17.51it/s]\n",
            "Pixel Acc:  0.07037562702866525\n",
            "Class Accuracy:  [0.27568894 0.         0.         0.         0.         0.72498208]\n",
            "Mean Class Acc:  0.16677850343701683\n",
            "Freq Weighted IoU:  0.02957616076729871\n",
            "Mean IoU:  0.025428144517774486\n",
            "confusion_matrix [[ 5640153.        0.        0.        0.        0. 14818241.]\n",
            " [ 3518541.        0.        0.        0.        0.  9182143.]\n",
            " [14176329.        0.        0.        0.        0. 37285455.]\n",
            " [ 1823907.        0.        0.        0.        0.  4798493.]\n",
            " [  782454.        0.        0.        0.        0.  2027538.]\n",
            " [  411264.        0.        0.        0.        0.  1084144.]]\n",
            "Epoch [22/30] training Loss: -3053.9971\n",
            "Epoch [22/30] training Loss: -3053.9978\n",
            "Epoch [22/30] training Loss: -3053.9185\n",
            "Epoch [22/30] training Loss: -3053.9990\n",
            "Epoch [22/30] training Loss: -3053.9995\n",
            "Epoch [22/30] training Loss: -3053.9998\n",
            "Epoch [22/30] training Loss: -3054.0002\n",
            "Epoch [22/30] training Loss: -3054.0002\n",
            "Epoch [22/30] training Loss: -3054.0000\n",
            "Epoch [22/30] training Loss: -3054.0005\n",
            "Epoch [22/30] training Loss: -3054.0005\n",
            "Epoch [22/30] training Loss: -3054.0007\n",
            "Epoch [22/30] training Loss: -3054.0010\n",
            "Epoch [22/30] training Loss: -3054.0017\n",
            "Epoch [22/30] training Loss: -3054.0051\n",
            "Epoch [22/30] training Loss: -3054.0078\n",
            "Epoch [22/30] training Loss: -3053.9978\n",
            "Epoch [22/30] training Loss: -3053.9985\n",
            "Epoch [22/30] training Loss: -3053.9985\n",
            "Epoch [22/30] training Loss: -3053.9988\n",
            "Epoch [22/30] training Loss: -3053.9993\n",
            "Epoch [22/30] training Loss: -3053.9990\n",
            "Epoch [22/30] training Loss: -3053.9988\n",
            "Epoch [22/30] training Loss: -3053.9993\n",
            "Epoch [22/30] training Loss: -3053.9990\n",
            "Epoch [22/30] training Loss: -3053.9998\n",
            "Epoch [22/30] training Loss: -3054.0000\n",
            "Epoch [22/30] training Loss: -3054.0044\n",
            "Epoch [22/30] training Loss: -3053.9980\n",
            "Epoch [22/30] training Loss: -3053.9980\n",
            "Epoch [22/30] training Loss: -3053.9985\n",
            "Epoch [22/30] training Loss: -3053.9985\n",
            "Epoch [22/30] training Loss: -3053.9988\n",
            "Epoch [22/30] training Loss: -3053.9988\n",
            "Epoch [22/30] training Loss: -3053.9988\n",
            "Epoch [22/30] training Loss: -3053.9988\n",
            "Epoch [22/30] training Loss: -3053.9985\n",
            "Epoch [22/30] training Loss: -3054.0017\n",
            "Epoch [22/30] training Loss: -3053.9978\n",
            "Epoch [22/30] training Loss: -3053.9990\n",
            "Epoch [22/30] training Loss: -3053.9988\n",
            "Epoch [22/30] training Loss: -3053.9990\n",
            "Epoch [22/30] training Loss: -3053.9993\n",
            "Epoch [22/30] training Loss: -3053.9995\n",
            "Epoch [22/30] training Loss: -3053.9993\n",
            "Epoch [22/30] training Loss: -3053.9993\n",
            "Epoch [22/30] training Loss: -3053.9995\n",
            "Epoch [22/30] training Loss: -3053.9995\n",
            "Epoch [22/30] training Loss: -3054.0000\n",
            "Epoch [22/30] training Loss: -3054.0000\n",
            "Epoch [22/30] training Loss: -3053.9993\n",
            "Epoch [22/30] training Loss: -3053.9993\n",
            "Epoch [22/30] training Loss: -3053.9993\n",
            "Epoch [22/30] training Loss: -3053.9998\n",
            "Epoch [22/30] training Loss: -3054.0005\n",
            "Epoch [22/30] training Loss: -3053.9985\n",
            "Epoch [22/30] training Loss: -3053.9990\n",
            "Epoch [22/30] training Loss: -3053.9990\n",
            "Epoch [22/30] training Loss: -3053.9995\n",
            "Epoch [22/30] training Loss: -3053.9990\n",
            "Epoch [22/30] training Loss: -3053.9995\n",
            "Epoch [22/30] training Loss: -3053.9998\n",
            "Epoch [22/30] training Loss: -3053.9995\n",
            "Epoch [22/30] training Loss: -3053.9995\n",
            "Epoch [22/30] training Loss: -3053.9998\n",
            "Epoch [22/30] training Loss: -3053.9995\n",
            "Epoch [22/30] training Loss: -3053.9998\n",
            "Epoch [22/30] training Loss: -3054.0000\n",
            "Epoch [22/30] training Loss: -3054.0002\n",
            "Epoch [22/30] training Loss: -3054.0002\n",
            "Epoch [22/30] training Loss: -3053.9993\n",
            "0it [00:00, ?it/s]Epoch [21/30] validation Loss: -3053.9993\n",
            "19it [00:01, 11.19it/s]Epoch [21/30] validation Loss: -3053.9995\n",
            "39it [00:03, 16.44it/s]Epoch [21/30] validation Loss: -3053.9995\n",
            "59it [00:04, 16.65it/s]Epoch [21/30] validation Loss: -3053.9993\n",
            "79it [00:05, 16.64it/s]Epoch [21/30] validation Loss: -3053.9993\n",
            "99it [00:06, 16.56it/s]Epoch [21/30] validation Loss: -3053.9993\n",
            "119it [00:07, 16.76it/s]Epoch [21/30] validation Loss: -3053.9993\n",
            "139it [00:09, 16.81it/s]Epoch [21/30] validation Loss: -3053.9993\n",
            "159it [00:10, 16.60it/s]Epoch [21/30] validation Loss: -3053.9995\n",
            "179it [00:11, 16.75it/s]Epoch [21/30] validation Loss: -3053.9995\n",
            "199it [00:12, 16.76it/s]Epoch [21/30] validation Loss: -3053.9995\n",
            "219it [00:13, 16.68it/s]Epoch [21/30] validation Loss: -3053.9995\n",
            "239it [00:15, 16.75it/s]Epoch [21/30] validation Loss: -3053.9995\n",
            "259it [00:16, 16.75it/s]Epoch [21/30] validation Loss: -3053.9995\n",
            "279it [00:17, 16.71it/s]Epoch [21/30] validation Loss: -3053.9998\n",
            "299it [00:18, 16.87it/s]Epoch [21/30] validation Loss: -3053.9995\n",
            "319it [00:19, 16.76it/s]Epoch [21/30] validation Loss: -3053.9998\n",
            "339it [00:20, 16.67it/s]Epoch [21/30] validation Loss: -3053.9995\n",
            "351it [00:21, 17.41it/s]\n",
            "Pixel Acc:  0.019252922662590502\n",
            "Class Accuracy:  [0.0184818  0.         0.         0.         0.         0.97731388]\n",
            "Mean Class Acc:  0.16596594769953318\n",
            "Freq Weighted IoU:  0.003938466586116626\n",
            "Mean IoU:  0.005473984868741447\n",
            "confusion_matrix [[3.7810800e+05 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  2.0080286e+07]\n",
            " [2.3317800e+05 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  1.2467506e+07]\n",
            " [9.7025200e+05 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  5.0491532e+07]\n",
            " [1.4295700e+05 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  6.4794430e+06]\n",
            " [7.4659000e+04 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  2.7353330e+06]\n",
            " [3.3925000e+04 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  1.4614830e+06]]\n",
            "Epoch [23/30] training Loss: -3053.9990\n",
            "Epoch [23/30] training Loss: -3053.9995\n",
            "Epoch [23/30] training Loss: -3053.9995\n",
            "Epoch [23/30] training Loss: -3053.9995\n",
            "Epoch [23/30] training Loss: -3053.9993\n",
            "Epoch [23/30] training Loss: -3054.0000\n",
            "Epoch [23/30] training Loss: -3053.9995\n",
            "Epoch [23/30] training Loss: -3053.9995\n",
            "Epoch [23/30] training Loss: -3053.9995\n",
            "Epoch [23/30] training Loss: -3053.9995\n",
            "Epoch [23/30] training Loss: -3053.9998\n",
            "Epoch [23/30] training Loss: -3053.9995\n",
            "Epoch [23/30] training Loss: -3054.0012\n",
            "Epoch [23/30] training Loss: -3053.9988\n",
            "Epoch [23/30] training Loss: -3053.9993\n",
            "Epoch [23/30] training Loss: -3053.9993\n",
            "Epoch [23/30] training Loss: -3053.9993\n",
            "Epoch [23/30] training Loss: -3053.9993\n",
            "Epoch [23/30] training Loss: -3053.9995\n",
            "Epoch [23/30] training Loss: -3053.9998\n",
            "Epoch [23/30] training Loss: -3053.9995\n",
            "Epoch [23/30] training Loss: -3053.9995\n",
            "Epoch [23/30] training Loss: -3053.9998\n",
            "Epoch [23/30] training Loss: -3053.9998\n",
            "Epoch [23/30] training Loss: -3053.9998\n",
            "Epoch [23/30] training Loss: -3054.0000\n",
            "Epoch [23/30] training Loss: -3053.9998\n",
            "Epoch [23/30] training Loss: -3053.9998\n",
            "Epoch [23/30] training Loss: -3054.0000\n",
            "Epoch [23/30] training Loss: -3053.9998\n",
            "Epoch [23/30] training Loss: -3053.9998\n",
            "Epoch [23/30] training Loss: -3053.9998\n",
            "Epoch [23/30] training Loss: -3054.0007\n",
            "Epoch [23/30] training Loss: -3053.9995\n",
            "Epoch [23/30] training Loss: -3053.9998\n",
            "Epoch [23/30] training Loss: -3053.9995\n",
            "Epoch [23/30] training Loss: -3053.9995\n",
            "Epoch [23/30] training Loss: -3053.9993\n",
            "Epoch [23/30] training Loss: -3053.9998\n",
            "Epoch [23/30] training Loss: -3054.0000\n",
            "Epoch [23/30] training Loss: -3053.9998\n",
            "Epoch [23/30] training Loss: -3053.9998\n",
            "Epoch [23/30] training Loss: -3053.9995\n",
            "Epoch [23/30] training Loss: -3054.0000\n",
            "Epoch [23/30] training Loss: -3054.0005\n",
            "Epoch [23/30] training Loss: -3054.0728\n",
            "Epoch [23/30] training Loss: -3053.9988\n",
            "Epoch [23/30] training Loss: -3053.9995\n",
            "Epoch [23/30] training Loss: -3053.9993\n",
            "Epoch [23/30] training Loss: -3053.9995\n",
            "Epoch [23/30] training Loss: -3053.9995\n",
            "Epoch [23/30] training Loss: -3053.9998\n",
            "Epoch [23/30] training Loss: -3053.9998\n",
            "Epoch [23/30] training Loss: -3054.0000\n",
            "Epoch [23/30] training Loss: -3053.9998\n",
            "Epoch [23/30] training Loss: -3053.9998\n",
            "Epoch [23/30] training Loss: -3053.9998\n",
            "Epoch [23/30] training Loss: -3053.9998\n",
            "Epoch [23/30] training Loss: -3053.9998\n",
            "Epoch [23/30] training Loss: -3054.0000\n",
            "Epoch [23/30] training Loss: -3054.0000\n",
            "Epoch [23/30] training Loss: -3053.9998\n",
            "Epoch [23/30] training Loss: -3054.0000\n",
            "Epoch [23/30] training Loss: -3054.0002\n",
            "Epoch [23/30] training Loss: -3054.0007\n",
            "Epoch [23/30] training Loss: -3053.9988\n",
            "Epoch [23/30] training Loss: -3053.9995\n",
            "Epoch [23/30] training Loss: -3053.9995\n",
            "Epoch [23/30] training Loss: -3054.0017\n",
            "Epoch [23/30] training Loss: -3053.9973\n",
            "Epoch [23/30] training Loss: -3053.9993\n",
            "0it [00:00, ?it/s]Epoch [22/30] validation Loss: -3053.9995\n",
            "19it [00:01, 11.17it/s]Epoch [22/30] validation Loss: -3053.9995\n",
            "39it [00:03, 16.47it/s]Epoch [22/30] validation Loss: -3053.9995\n",
            "59it [00:04, 16.74it/s]Epoch [22/30] validation Loss: -3054.0000\n",
            "79it [00:05, 16.79it/s]Epoch [22/30] validation Loss: -3054.0000\n",
            "99it [00:06, 16.77it/s]Epoch [22/30] validation Loss: -3054.0000\n",
            "119it [00:07, 16.49it/s]Epoch [22/30] validation Loss: -3054.0000\n",
            "139it [00:09, 16.60it/s]Epoch [22/30] validation Loss: -3054.0000\n",
            "159it [00:10, 16.87it/s]Epoch [22/30] validation Loss: -3053.9998\n",
            "179it [00:11, 16.79it/s]Epoch [22/30] validation Loss: -3053.9998\n",
            "199it [00:12, 16.64it/s]Epoch [22/30] validation Loss: -3053.9995\n",
            "219it [00:13, 16.78it/s]Epoch [22/30] validation Loss: -3053.9998\n",
            "239it [00:15, 16.78it/s]Epoch [22/30] validation Loss: -3053.9995\n",
            "259it [00:16, 16.65it/s]Epoch [22/30] validation Loss: -3053.9995\n",
            "279it [00:17, 16.72it/s]Epoch [22/30] validation Loss: -3053.9995\n",
            "299it [00:18, 16.82it/s]Epoch [22/30] validation Loss: -3053.9998\n",
            "319it [00:19, 16.81it/s]Epoch [22/30] validation Loss: -3053.9995\n",
            "339it [00:21, 16.61it/s]Epoch [22/30] validation Loss: -3053.9998\n",
            "351it [00:21, 17.51it/s]\n",
            "Pixel Acc:  0.024510631033221587\n",
            "Class Accuracy:  [0.04590023 0.         0.         0.         0.         0.93814731]\n",
            "Mean Class Acc:  0.1640079242445933\n",
            "Freq Weighted IoU:  0.008420144587404975\n",
            "Mean IoU:  0.008947057223201563\n",
            "confusion_matrix [[  939045.        0.        0.        0.        0. 19519349.]\n",
            " [  683225.        0.        0.        0.        0. 12017459.]\n",
            " [ 2757537.        0.        0.        0.        0. 48704247.]\n",
            " [  392921.        0.        0.        0.        0.  6229479.]\n",
            " [  202154.        0.        0.        0.        0.  2607838.]\n",
            " [   92495.        0.        0.        0.        0.  1402913.]]\n",
            "Epoch [24/30] training Loss: -3053.9995\n",
            "Epoch [24/30] training Loss: -3053.9995\n",
            "Epoch [24/30] training Loss: -3053.9998\n",
            "Epoch [24/30] training Loss: -3053.9998\n",
            "Epoch [24/30] training Loss: -3053.9998\n",
            "Epoch [24/30] training Loss: -3054.0000\n",
            "Epoch [24/30] training Loss: -3053.9995\n",
            "Epoch [24/30] training Loss: -3053.9998\n",
            "Epoch [24/30] training Loss: -3053.9998\n",
            "Epoch [24/30] training Loss: -3054.0000\n",
            "Epoch [24/30] training Loss: -3054.0000\n",
            "Epoch [24/30] training Loss: -3053.9998\n",
            "Epoch [24/30] training Loss: -3054.0000\n",
            "Epoch [24/30] training Loss: -3054.0000\n",
            "Epoch [24/30] training Loss: -3054.0002\n",
            "Epoch [24/30] training Loss: -3054.0002\n",
            "Epoch [24/30] training Loss: -3054.0002\n",
            "Epoch [24/30] training Loss: -3054.0002\n",
            "Epoch [24/30] training Loss: -3054.0005\n",
            "Epoch [24/30] training Loss: -3054.0007\n",
            "Epoch [24/30] training Loss: -3053.9998\n",
            "Epoch [24/30] training Loss: -3054.0000\n",
            "Epoch [24/30] training Loss: -3054.0010\n",
            "Epoch [24/30] training Loss: -3053.9988\n",
            "Epoch [24/30] training Loss: -3054.0010\n",
            "Epoch [24/30] training Loss: -3054.0022\n",
            "Epoch [24/30] training Loss: -3054.0076\n",
            "Epoch [24/30] training Loss: -3053.9990\n",
            "Epoch [24/30] training Loss: -3053.9893\n",
            "Epoch [24/30] training Loss: -3053.9807\n",
            "Epoch [24/30] training Loss: -3053.9956\n",
            "Epoch [24/30] training Loss: -3053.9985\n",
            "Epoch [24/30] training Loss: -3053.9990\n",
            "Epoch [24/30] training Loss: -3053.9995\n",
            "Epoch [24/30] training Loss: -3053.9998\n",
            "Epoch [24/30] training Loss: -3053.9995\n",
            "Epoch [24/30] training Loss: -3053.9998\n",
            "Epoch [24/30] training Loss: -3053.9998\n",
            "Epoch [24/30] training Loss: -3053.9998\n",
            "Epoch [24/30] training Loss: -3053.9995\n",
            "Epoch [24/30] training Loss: -3053.9998\n",
            "Epoch [24/30] training Loss: -3053.9998\n",
            "Epoch [24/30] training Loss: -3053.9998\n",
            "Epoch [24/30] training Loss: -3054.0000\n",
            "Epoch [24/30] training Loss: -3053.9995\n",
            "Epoch [24/30] training Loss: -3053.9995\n",
            "Epoch [24/30] training Loss: -3053.9998\n",
            "Epoch [24/30] training Loss: -3053.9998\n",
            "Epoch [24/30] training Loss: -3053.9998\n",
            "Epoch [24/30] training Loss: -3053.9998\n",
            "Epoch [24/30] training Loss: -3053.9998\n",
            "Epoch [24/30] training Loss: -3054.0000\n",
            "Epoch [24/30] training Loss: -3053.9998\n",
            "Epoch [24/30] training Loss: -3054.0000\n",
            "Epoch [24/30] training Loss: -3054.0000\n",
            "Epoch [24/30] training Loss: -3053.9998\n",
            "Epoch [24/30] training Loss: -3054.0000\n",
            "Epoch [24/30] training Loss: -3053.9998\n",
            "Epoch [24/30] training Loss: -3053.9998\n",
            "Epoch [24/30] training Loss: -3054.0000\n",
            "Epoch [24/30] training Loss: -3053.9998\n",
            "Epoch [24/30] training Loss: -3053.9998\n",
            "Epoch [24/30] training Loss: -3053.9998\n",
            "Epoch [24/30] training Loss: -3054.0000\n",
            "Epoch [24/30] training Loss: -3054.0000\n",
            "Epoch [24/30] training Loss: -3053.9998\n",
            "Epoch [24/30] training Loss: -3053.9998\n",
            "Epoch [24/30] training Loss: -3054.0000\n",
            "Epoch [24/30] training Loss: -3054.0000\n",
            "Epoch [24/30] training Loss: -3054.0000\n",
            "Epoch [24/30] training Loss: -3053.9961\n",
            "0it [00:00, ?it/s]Epoch [23/30] validation Loss: -3054.0000\n",
            "19it [00:01, 11.15it/s]Epoch [23/30] validation Loss: -3054.0000\n",
            "39it [00:03, 16.46it/s]Epoch [23/30] validation Loss: -3054.0002\n",
            "59it [00:04, 16.74it/s]Epoch [23/30] validation Loss: -3054.0002\n",
            "79it [00:05, 16.84it/s]Epoch [23/30] validation Loss: -3054.0002\n",
            "99it [00:06, 16.75it/s]Epoch [23/30] validation Loss: -3054.0000\n",
            "119it [00:07, 16.60it/s]Epoch [23/30] validation Loss: -3054.0002\n",
            "139it [00:09, 16.79it/s]Epoch [23/30] validation Loss: -3054.0000\n",
            "159it [00:10, 16.84it/s]Epoch [23/30] validation Loss: -3054.0002\n",
            "179it [00:11, 16.83it/s]Epoch [23/30] validation Loss: -3054.0002\n",
            "199it [00:12, 16.76it/s]Epoch [23/30] validation Loss: -3054.0000\n",
            "219it [00:13, 16.65it/s]Epoch [23/30] validation Loss: -3053.9998\n",
            "239it [00:15, 16.74it/s]Epoch [23/30] validation Loss: -3053.9998\n",
            "259it [00:16, 16.64it/s]Epoch [23/30] validation Loss: -3054.0000\n",
            "279it [00:17, 16.62it/s]Epoch [23/30] validation Loss: -3053.9998\n",
            "299it [00:18, 16.75it/s]Epoch [23/30] validation Loss: -3053.9998\n",
            "319it [00:19, 16.77it/s]Epoch [23/30] validation Loss: -3053.9998\n",
            "339it [00:20, 16.72it/s]Epoch [23/30] validation Loss: -3054.0000\n",
            "351it [00:21, 17.42it/s]\n",
            "Pixel Acc:  0.0225515664468436\n",
            "Class Accuracy:  [0.03533591 0.         0.         0.         0.         0.9575019 ]\n",
            "Mean Class Acc:  0.16547296844270729\n",
            "Freq Weighted IoU:  0.00686545287323298\n",
            "Mean IoU:  0.007749117917968915\n",
            "confusion_matrix [[  722916.        0.        0.        0.        0. 19735478.]\n",
            " [  500466.        0.        0.        0.        0. 12200218.]\n",
            " [ 1942235.        0.        0.        0.        0. 49519549.]\n",
            " [  270117.        0.        0.        0.        0.  6352283.]\n",
            " [  140629.        0.        0.        0.        0.  2669363.]\n",
            " [   63552.        0.        0.        0.        0.  1431856.]]\n",
            "Epoch [25/30] training Loss: -3054.0000\n",
            "Epoch [25/30] training Loss: -3053.9998\n",
            "Epoch [25/30] training Loss: -3053.9998\n",
            "Epoch [25/30] training Loss: -3054.0000\n",
            "Epoch [25/30] training Loss: -3054.0000\n",
            "Epoch [25/30] training Loss: -3054.0000\n",
            "Epoch [25/30] training Loss: -3053.9998\n",
            "Epoch [25/30] training Loss: -3054.0000\n",
            "Epoch [25/30] training Loss: -3054.0000\n",
            "Epoch [25/30] training Loss: -3054.0000\n",
            "Epoch [25/30] training Loss: -3054.0000\n",
            "Epoch [25/30] training Loss: -3053.9998\n",
            "Epoch [25/30] training Loss: -3054.0000\n",
            "Epoch [25/30] training Loss: -3054.0000\n",
            "Epoch [25/30] training Loss: -3054.0005\n",
            "Epoch [25/30] training Loss: -3054.0000\n",
            "Epoch [25/30] training Loss: -3054.0000\n",
            "Epoch [25/30] training Loss: -3054.0000\n",
            "Epoch [25/30] training Loss: -3054.0000\n",
            "Epoch [25/30] training Loss: -3054.0002\n",
            "Epoch [25/30] training Loss: -3054.0000\n",
            "Epoch [25/30] training Loss: -3054.0002\n",
            "Epoch [25/30] training Loss: -3054.0002\n",
            "Epoch [25/30] training Loss: -3054.0005\n",
            "Epoch [25/30] training Loss: -3054.0000\n",
            "Epoch [25/30] training Loss: -3054.0005\n",
            "Epoch [25/30] training Loss: -3053.9946\n",
            "Epoch [25/30] training Loss: -3054.0000\n",
            "Epoch [25/30] training Loss: -3054.0002\n",
            "Epoch [25/30] training Loss: -3054.0005\n",
            "Epoch [25/30] training Loss: -3054.0002\n",
            "Epoch [25/30] training Loss: -3053.9988\n",
            "Epoch [25/30] training Loss: -3054.0005\n",
            "Epoch [25/30] training Loss: -3053.9990\n",
            "Epoch [25/30] training Loss: -3053.9995\n",
            "Epoch [25/30] training Loss: -3053.9995\n",
            "Epoch [25/30] training Loss: -3053.9995\n",
            "Epoch [25/30] training Loss: -3053.9998\n",
            "Epoch [25/30] training Loss: -3054.0000\n",
            "Epoch [25/30] training Loss: -3053.9995\n",
            "Epoch [25/30] training Loss: -3054.0000\n",
            "Epoch [25/30] training Loss: -3054.0002\n",
            "Epoch [25/30] training Loss: -3054.0000\n",
            "Epoch [25/30] training Loss: -3053.9998\n",
            "Epoch [25/30] training Loss: -3054.0005\n",
            "Epoch [25/30] training Loss: -3054.0000\n",
            "Epoch [25/30] training Loss: -3054.0005\n",
            "Epoch [25/30] training Loss: -3054.0012\n",
            "Epoch [25/30] training Loss: -3053.9995\n",
            "Epoch [25/30] training Loss: -3054.0034\n",
            "Epoch [25/30] training Loss: -3054.2786\n",
            "Epoch [25/30] training Loss: -3053.9817\n",
            "Epoch [25/30] training Loss: -3053.9976\n",
            "Epoch [25/30] training Loss: -3053.9983\n",
            "Epoch [25/30] training Loss: -3053.9985\n",
            "Epoch [25/30] training Loss: -3053.9990\n",
            "Epoch [25/30] training Loss: -3053.9993\n",
            "Epoch [25/30] training Loss: -3053.9993\n",
            "Epoch [25/30] training Loss: -3053.9995\n",
            "Epoch [25/30] training Loss: -3053.9995\n",
            "Epoch [25/30] training Loss: -3054.0000\n",
            "Epoch [25/30] training Loss: -3053.9998\n",
            "Epoch [25/30] training Loss: -3054.0000\n",
            "Epoch [25/30] training Loss: -3053.9998\n",
            "Epoch [25/30] training Loss: -3054.0000\n",
            "Epoch [25/30] training Loss: -3053.9998\n",
            "Epoch [25/30] training Loss: -3054.0000\n",
            "Epoch [25/30] training Loss: -3054.0000\n",
            "Epoch [25/30] training Loss: -3054.0002\n",
            "Epoch [25/30] training Loss: -3054.0002\n",
            "Epoch [25/30] training Loss: -3054.0002\n",
            "0it [00:00, ?it/s]Epoch [24/30] validation Loss: -3054.0000\n",
            "19it [00:01, 11.19it/s]Epoch [24/30] validation Loss: -3054.0000\n",
            "39it [00:03, 16.45it/s]Epoch [24/30] validation Loss: -3054.0002\n",
            "59it [00:04, 16.70it/s]Epoch [24/30] validation Loss: -3054.0005\n",
            "79it [00:05, 16.83it/s]Epoch [24/30] validation Loss: -3054.0000\n",
            "99it [00:06, 16.76it/s]Epoch [24/30] validation Loss: -3054.0002\n",
            "119it [00:07, 16.84it/s]Epoch [24/30] validation Loss: -3054.0000\n",
            "139it [00:09, 16.72it/s]Epoch [24/30] validation Loss: -3054.0002\n",
            "159it [00:10, 16.63it/s]Epoch [24/30] validation Loss: -3054.0000\n",
            "179it [00:11, 16.62it/s]Epoch [24/30] validation Loss: -3054.0000\n",
            "199it [00:12, 16.71it/s]Epoch [24/30] validation Loss: -3054.0000\n",
            "219it [00:13, 16.87it/s]Epoch [24/30] validation Loss: -3054.0000\n",
            "239it [00:15, 16.80it/s]Epoch [24/30] validation Loss: -3054.0000\n",
            "259it [00:16, 16.75it/s]Epoch [24/30] validation Loss: -3054.0000\n",
            "279it [00:17, 16.65it/s]Epoch [24/30] validation Loss: -3054.0002\n",
            "299it [00:18, 16.70it/s]Epoch [24/30] validation Loss: -3054.0000\n",
            "319it [00:19, 16.82it/s]Epoch [24/30] validation Loss: -3053.9995\n",
            "339it [00:20, 16.73it/s]Epoch [24/30] validation Loss: -3054.0000\n",
            "351it [00:21, 17.38it/s]\n",
            "Pixel Acc:  0.022135223620399835\n",
            "Class Accuracy:  [0.03326082 0.         0.         0.         0.         0.9592887 ]\n",
            "Mean Class Acc:  0.16542492073676524\n",
            "Freq Weighted IoU:  0.006513918011699451\n",
            "Mean IoU:  0.007475291188323292\n",
            "confusion_matrix [[  680463.        0.        0.        0.        0. 19777931.]\n",
            " [  474613.        0.        0.        0.        0. 12226071.]\n",
            " [ 1848245.        0.        0.        0.        0. 49613539.]\n",
            " [  258340.        0.        0.        0.        0.  6364060.]\n",
            " [  135691.        0.        0.        0.        0.  2674301.]\n",
            " [   60880.        0.        0.        0.        0.  1434528.]]\n",
            "Epoch [26/30] training Loss: -3054.0000\n",
            "Epoch [26/30] training Loss: -3054.0000\n",
            "Epoch [26/30] training Loss: -3054.0005\n",
            "Epoch [26/30] training Loss: -3054.0002\n",
            "Epoch [26/30] training Loss: -3054.0002\n",
            "Epoch [26/30] training Loss: -3054.0000\n",
            "Epoch [26/30] training Loss: -3054.0005\n",
            "Epoch [26/30] training Loss: -3054.0007\n",
            "Epoch [26/30] training Loss: -3054.0010\n",
            "Epoch [26/30] training Loss: -3054.0002\n",
            "Epoch [26/30] training Loss: -3054.0044\n",
            "Epoch [26/30] training Loss: -3053.9954\n",
            "Epoch [26/30] training Loss: -3054.0000\n",
            "Epoch [26/30] training Loss: -3054.0010\n",
            "Epoch [26/30] training Loss: -3054.0012\n",
            "Epoch [26/30] training Loss: -3054.0029\n",
            "Epoch [26/30] training Loss: -3054.0073\n",
            "Epoch [26/30] training Loss: -3053.9988\n",
            "Epoch [26/30] training Loss: -3053.9963\n",
            "Epoch [26/30] training Loss: -3053.9988\n",
            "Epoch [26/30] training Loss: -3053.9995\n",
            "Epoch [26/30] training Loss: -3053.9998\n",
            "Epoch [26/30] training Loss: -3053.9998\n",
            "Epoch [26/30] training Loss: -3054.0000\n",
            "Epoch [26/30] training Loss: -3054.0000\n",
            "Epoch [26/30] training Loss: -3054.0000\n",
            "Epoch [26/30] training Loss: -3054.0007\n",
            "Epoch [26/30] training Loss: -3054.0010\n",
            "Epoch [26/30] training Loss: -3054.0032\n",
            "Epoch [26/30] training Loss: -3054.0002\n",
            "Epoch [26/30] training Loss: -3054.0024\n",
            "Epoch [26/30] training Loss: -3053.9893\n",
            "Epoch [26/30] training Loss: -3053.9993\n",
            "Epoch [26/30] training Loss: -3054.0005\n",
            "Epoch [26/30] training Loss: -3054.0010\n",
            "Epoch [26/30] training Loss: -3054.0015\n",
            "Epoch [26/30] training Loss: -3054.0029\n",
            "Epoch [26/30] training Loss: -3053.9604\n",
            "Epoch [26/30] training Loss: -3053.9956\n",
            "Epoch [26/30] training Loss: -3053.9990\n",
            "Epoch [26/30] training Loss: -3053.9934\n",
            "Epoch [26/30] training Loss: -3053.9976\n",
            "Epoch [26/30] training Loss: -3053.9985\n",
            "Epoch [26/30] training Loss: -3053.9995\n",
            "Epoch [26/30] training Loss: -3053.9995\n",
            "Epoch [26/30] training Loss: -3054.0000\n",
            "Epoch [26/30] training Loss: -3054.0005\n",
            "Epoch [26/30] training Loss: -3054.0005\n",
            "Epoch [26/30] training Loss: -3054.0005\n",
            "Epoch [26/30] training Loss: -3054.0007\n",
            "Epoch [26/30] training Loss: -3054.0010\n",
            "Epoch [26/30] training Loss: -3053.9980\n",
            "Epoch [26/30] training Loss: -3054.0002\n",
            "Epoch [26/30] training Loss: -3054.0027\n",
            "Epoch [26/30] training Loss: -3054.0081\n",
            "Epoch [26/30] training Loss: -3053.9978\n",
            "Epoch [26/30] training Loss: -3054.0007\n",
            "Epoch [26/30] training Loss: -3054.0015\n",
            "Epoch [26/30] training Loss: -3054.0022\n",
            "Epoch [26/30] training Loss: -3054.0237\n",
            "Epoch [26/30] training Loss: -3053.9753\n",
            "Epoch [26/30] training Loss: -3053.9980\n",
            "Epoch [26/30] training Loss: -3053.9985\n",
            "Epoch [26/30] training Loss: -3054.0000\n",
            "Epoch [26/30] training Loss: -3053.9954\n",
            "Epoch [26/30] training Loss: -3053.9985\n",
            "Epoch [26/30] training Loss: -3053.9951\n",
            "Epoch [26/30] training Loss: -3054.0000\n",
            "Epoch [26/30] training Loss: -3053.9998\n",
            "Epoch [26/30] training Loss: -3054.0000\n",
            "Epoch [26/30] training Loss: -3054.0002\n",
            "0it [00:00, ?it/s]Epoch [25/30] validation Loss: -3054.0002\n",
            "19it [00:01, 11.05it/s]Epoch [25/30] validation Loss: -3054.0002\n",
            "39it [00:03, 16.57it/s]Epoch [25/30] validation Loss: -3054.0000\n",
            "59it [00:04, 16.83it/s]Epoch [25/30] validation Loss: -3054.0005\n",
            "79it [00:05, 16.77it/s]Epoch [25/30] validation Loss: -3054.0002\n",
            "99it [00:06, 16.80it/s]Epoch [25/30] validation Loss: -3054.0005\n",
            "119it [00:07, 16.77it/s]Epoch [25/30] validation Loss: -3054.0002\n",
            "139it [00:09, 16.83it/s]Epoch [25/30] validation Loss: -3054.0002\n",
            "159it [00:10, 16.90it/s]Epoch [25/30] validation Loss: -3054.0002\n",
            "179it [00:11, 16.83it/s]Epoch [25/30] validation Loss: -3054.0000\n",
            "199it [00:12, 16.85it/s]Epoch [25/30] validation Loss: -3054.0000\n",
            "219it [00:13, 16.82it/s]Epoch [25/30] validation Loss: -3054.0002\n",
            "239it [00:15, 16.67it/s]Epoch [25/30] validation Loss: -3054.0002\n",
            "259it [00:16, 16.74it/s]Epoch [25/30] validation Loss: -3054.0000\n",
            "279it [00:17, 16.63it/s]Epoch [25/30] validation Loss: -3054.0005\n",
            "299it [00:18, 16.59it/s]Epoch [25/30] validation Loss: -3054.0002\n",
            "319it [00:19, 16.57it/s]Epoch [25/30] validation Loss: -3054.0002\n",
            "339it [00:21, 16.75it/s]Epoch [25/30] validation Loss: -3054.0002\n",
            "351it [00:21, 17.46it/s]\n",
            "Pixel Acc:  0.016284351527601715\n",
            "Class Accuracy:  [0.00361612 0.         0.         0.         0.         0.99101249]\n",
            "Mean Class Acc:  0.16577143430792837\n",
            "Freq Weighted IoU:  0.001004197543391711\n",
            "Mean IoU:  0.0031886903415511876\n",
            "confusion_matrix [[7.3980000e+04 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  2.0384414e+07]\n",
            " [4.6744000e+04 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  1.2653940e+07]\n",
            " [2.2700900e+05 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  5.1234775e+07]\n",
            " [5.0036000e+04 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  6.5723640e+06]\n",
            " [3.7385000e+04 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  2.7726070e+06]\n",
            " [1.3440000e+04 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  1.4819680e+06]]\n",
            "Epoch [27/30] training Loss: -3054.0000\n",
            "Epoch [27/30] training Loss: -3054.0005\n",
            "Epoch [27/30] training Loss: -3054.0010\n",
            "Epoch [27/30] training Loss: -3054.0049\n",
            "Epoch [27/30] training Loss: -3053.9980\n",
            "Epoch [27/30] training Loss: -3053.9993\n",
            "Epoch [27/30] training Loss: -3054.0000\n",
            "Epoch [27/30] training Loss: -3054.0007\n",
            "Epoch [27/30] training Loss: -3054.0063\n",
            "Epoch [27/30] training Loss: -3054.0002\n",
            "Epoch [27/30] training Loss: -3053.9968\n",
            "Epoch [27/30] training Loss: -3053.9988\n",
            "Epoch [27/30] training Loss: -3054.0000\n",
            "Epoch [27/30] training Loss: -3054.0002\n",
            "Epoch [27/30] training Loss: -3054.0002\n",
            "Epoch [27/30] training Loss: -3054.0005\n",
            "Epoch [27/30] training Loss: -3054.0010\n",
            "Epoch [27/30] training Loss: -3054.0015\n",
            "Epoch [27/30] training Loss: -3054.0022\n",
            "Epoch [27/30] training Loss: -3054.0186\n",
            "Epoch [27/30] training Loss: -3054.0012\n",
            "Epoch [27/30] training Loss: -3053.9939\n",
            "Epoch [27/30] training Loss: -3053.9980\n",
            "Epoch [27/30] training Loss: -3054.0005\n",
            "Epoch [27/30] training Loss: -3053.9954\n",
            "Epoch [27/30] training Loss: -3053.9980\n",
            "Epoch [27/30] training Loss: -3053.9988\n",
            "Epoch [27/30] training Loss: -3053.9990\n",
            "Epoch [27/30] training Loss: -3053.9995\n",
            "Epoch [27/30] training Loss: -3053.9995\n",
            "Epoch [27/30] training Loss: -3053.9998\n",
            "Epoch [27/30] training Loss: -3054.0000\n",
            "Epoch [27/30] training Loss: -3054.0000\n",
            "Epoch [27/30] training Loss: -3054.0002\n",
            "Epoch [27/30] training Loss: -3054.0005\n",
            "Epoch [27/30] training Loss: -3054.0005\n",
            "Epoch [27/30] training Loss: -3054.0010\n",
            "Epoch [27/30] training Loss: -3054.0037\n",
            "Epoch [27/30] training Loss: -3053.9985\n",
            "Epoch [27/30] training Loss: -3053.9995\n",
            "Epoch [27/30] training Loss: -3054.0000\n",
            "Epoch [27/30] training Loss: -3054.0002\n",
            "Epoch [27/30] training Loss: -3054.0034\n",
            "Epoch [27/30] training Loss: -3053.9980\n",
            "Epoch [27/30] training Loss: -3053.9995\n",
            "Epoch [27/30] training Loss: -3054.0017\n",
            "Epoch [27/30] training Loss: -3053.9976\n",
            "Epoch [27/30] training Loss: -3053.9988\n",
            "Epoch [27/30] training Loss: -3053.9993\n",
            "Epoch [27/30] training Loss: -3053.9995\n",
            "Epoch [27/30] training Loss: -3054.0000\n",
            "Epoch [27/30] training Loss: -3053.9993\n",
            "Epoch [27/30] training Loss: -3054.0000\n",
            "Epoch [27/30] training Loss: -3054.0000\n",
            "Epoch [27/30] training Loss: -3053.9958\n",
            "Epoch [27/30] training Loss: -3054.0000\n",
            "Epoch [27/30] training Loss: -3054.0005\n",
            "Epoch [27/30] training Loss: -3054.0000\n",
            "Epoch [27/30] training Loss: -3054.0002\n",
            "Epoch [27/30] training Loss: -3054.0005\n",
            "Epoch [27/30] training Loss: -3054.0020\n",
            "Epoch [27/30] training Loss: -3053.9956\n",
            "Epoch [27/30] training Loss: -3053.9990\n",
            "Epoch [27/30] training Loss: -3053.9993\n",
            "Epoch [27/30] training Loss: -3053.9998\n",
            "Epoch [27/30] training Loss: -3054.0015\n",
            "Epoch [27/30] training Loss: -3053.9956\n",
            "Epoch [27/30] training Loss: -3053.9985\n",
            "Epoch [27/30] training Loss: -3053.9990\n",
            "Epoch [27/30] training Loss: -3053.9995\n",
            "Epoch [27/30] training Loss: -3053.9990\n",
            "0it [00:00, ?it/s]Epoch [26/30] validation Loss: -3053.9995\n",
            "19it [00:01, 11.19it/s]Epoch [26/30] validation Loss: -3053.9995\n",
            "39it [00:03, 16.46it/s]Epoch [26/30] validation Loss: -3053.9995\n",
            "59it [00:04, 16.79it/s]Epoch [26/30] validation Loss: -3053.9995\n",
            "79it [00:05, 16.50it/s]Epoch [26/30] validation Loss: -3053.9995\n",
            "99it [00:06, 16.53it/s]Epoch [26/30] validation Loss: -3053.9995\n",
            "119it [00:07, 16.68it/s]Epoch [26/30] validation Loss: -3053.9995\n",
            "139it [00:09, 16.67it/s]Epoch [26/30] validation Loss: -3053.9995\n",
            "159it [00:10, 16.72it/s]Epoch [26/30] validation Loss: -3053.9995\n",
            "179it [00:11, 16.68it/s]Epoch [26/30] validation Loss: -3053.9995\n",
            "199it [00:12, 16.64it/s]Epoch [26/30] validation Loss: -3053.9995\n",
            "219it [00:13, 16.80it/s]Epoch [26/30] validation Loss: -3053.9995\n",
            "239it [00:15, 16.37it/s]Epoch [26/30] validation Loss: -3053.9993\n",
            "259it [00:16, 16.69it/s]Epoch [26/30] validation Loss: -3053.9995\n",
            "279it [00:17, 16.72it/s]Epoch [26/30] validation Loss: -3053.9995\n",
            "299it [00:18, 16.80it/s]Epoch [26/30] validation Loss: -3053.9995\n",
            "319it [00:19, 16.72it/s]Epoch [26/30] validation Loss: -3053.9990\n",
            "339it [00:21, 16.78it/s]Epoch [26/30] validation Loss: -3053.9993\n",
            "351it [00:21, 17.31it/s]\n",
            "Pixel Acc:  0.06558153582516937\n",
            "Class Accuracy:  [0.25164864 0.         0.         0.         0.         0.74755585]\n",
            "Mean Class Acc:  0.16653408161235808\n",
            "Freq Weighted IoU:  0.02822413986192773\n",
            "Mean IoU:  0.024373548828275513\n",
            "confusion_matrix [[ 5148327.        0.        0.        0.        0. 15310067.]\n",
            " [ 3200474.        0.        0.        0.        0.  9500210.]\n",
            " [12969532.        0.        0.        0.        0. 38492252.]\n",
            " [ 1675712.        0.        0.        0.        0.  4946688.]\n",
            " [  714737.        0.        0.        0.        0.  2095255.]\n",
            " [  377507.        0.        0.        0.        0.  1117901.]]\n",
            "Epoch [28/30] training Loss: -3053.9995\n",
            "Epoch [28/30] training Loss: -3053.9978\n",
            "Epoch [28/30] training Loss: -3053.9995\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3053.9998\n",
            "Epoch [28/30] training Loss: -3053.9995\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3053.9998\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3053.9998\n",
            "Epoch [28/30] training Loss: -3053.9998\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3053.9998\n",
            "Epoch [28/30] training Loss: -3053.9995\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3053.9998\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3054.0002\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3053.9998\n",
            "Epoch [28/30] training Loss: -3053.9998\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3054.0005\n",
            "Epoch [28/30] training Loss: -3054.0005\n",
            "Epoch [28/30] training Loss: -3054.0005\n",
            "Epoch [28/30] training Loss: -3054.0032\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3053.9998\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3053.9998\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3054.0002\n",
            "Epoch [28/30] training Loss: -3054.0002\n",
            "Epoch [28/30] training Loss: -3054.0005\n",
            "Epoch [28/30] training Loss: -3054.0015\n",
            "Epoch [28/30] training Loss: -3053.9995\n",
            "Epoch [28/30] training Loss: -3053.9998\n",
            "Epoch [28/30] training Loss: -3053.9998\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3054.0005\n",
            "Epoch [28/30] training Loss: -3054.0002\n",
            "Epoch [28/30] training Loss: -3054.0002\n",
            "Epoch [28/30] training Loss: -3054.0010\n",
            "Epoch [28/30] training Loss: -3053.9993\n",
            "Epoch [28/30] training Loss: -3053.9998\n",
            "Epoch [28/30] training Loss: -3053.9995\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3053.9998\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "Epoch [28/30] training Loss: -3054.0000\n",
            "0it [00:00, ?it/s]Epoch [27/30] validation Loss: -3054.0000\n",
            "19it [00:01, 11.20it/s]Epoch [27/30] validation Loss: -3054.0000\n",
            "39it [00:03, 16.66it/s]Epoch [27/30] validation Loss: -3054.0000\n",
            "59it [00:04, 16.83it/s]Epoch [27/30] validation Loss: -3054.0000\n",
            "79it [00:05, 16.75it/s]Epoch [27/30] validation Loss: -3054.0000\n",
            "99it [00:06, 16.69it/s]Epoch [27/30] validation Loss: -3054.0000\n",
            "119it [00:07, 16.77it/s]Epoch [27/30] validation Loss: -3054.0000\n",
            "139it [00:09, 16.86it/s]Epoch [27/30] validation Loss: -3054.0000\n",
            "159it [00:10, 16.88it/s]Epoch [27/30] validation Loss: -3054.0000\n",
            "179it [00:11, 16.86it/s]Epoch [27/30] validation Loss: -3054.0000\n",
            "199it [00:12, 16.85it/s]Epoch [27/30] validation Loss: -3054.0000\n",
            "219it [00:13, 16.55it/s]Epoch [27/30] validation Loss: -3054.0000\n",
            "239it [00:14, 16.70it/s]Epoch [27/30] validation Loss: -3054.0000\n",
            "259it [00:16, 16.66it/s]Epoch [27/30] validation Loss: -3054.0000\n",
            "279it [00:17, 16.50it/s]Epoch [27/30] validation Loss: -3054.0000\n",
            "299it [00:18, 16.53it/s]Epoch [27/30] validation Loss: -3054.0000\n",
            "319it [00:19, 16.60it/s]Epoch [27/30] validation Loss: -3054.0000\n",
            "339it [00:20, 16.72it/s]Epoch [27/30] validation Loss: -3054.0000\n",
            "351it [00:21, 17.27it/s]\n",
            "Pixel Acc:  0.1270349343039466\n",
            "Class Accuracy:  [0.09799968 0.         0.17563153 0.         0.         0.73210121]\n",
            "Mean Class Acc:  0.16762206922399514\n",
            "Freq Weighted IoU:  0.09804216945292395\n",
            "Mean IoU:  0.04016369984040175\n",
            "confusion_matrix [[ 2004916.        0.  3621637.        0.        0. 14831841.]\n",
            " [ 1220551.        0.  2226885.        0.        0.  9253248.]\n",
            " [ 4858836.        0.  9038312.        0.        0. 37564636.]\n",
            " [  630158.        0.  1150020.        0.        0.  4842222.]\n",
            " [  283681.        0.   473913.        0.        0.  2052398.]\n",
            " [  143385.        0.   257233.        0.        0.  1094790.]]\n",
            "Epoch [29/30] training Loss: -3054.0000\n",
            "Epoch [29/30] training Loss: -3054.0000\n",
            "Epoch [29/30] training Loss: -3054.0000\n",
            "Epoch [29/30] training Loss: -3054.0000\n",
            "Epoch [29/30] training Loss: -3054.0000\n",
            "Epoch [29/30] training Loss: -3054.0000\n",
            "Epoch [29/30] training Loss: -3054.0000\n",
            "Epoch [29/30] training Loss: -3054.0002\n",
            "Epoch [29/30] training Loss: -3054.0000\n",
            "Epoch [29/30] training Loss: -3054.0000\n",
            "Epoch [29/30] training Loss: -3054.0000\n",
            "Epoch [29/30] training Loss: -3054.0000\n",
            "Epoch [29/30] training Loss: -3054.0002\n",
            "Epoch [29/30] training Loss: -3054.0000\n",
            "Epoch [29/30] training Loss: -3054.0005\n",
            "Epoch [29/30] training Loss: -3054.0002\n",
            "Epoch [29/30] training Loss: -3054.0024\n",
            "Epoch [29/30] training Loss: -3053.9995\n",
            "Epoch [29/30] training Loss: -3053.9998\n",
            "Epoch [29/30] training Loss: -3054.0000\n",
            "Epoch [29/30] training Loss: -3054.0000\n",
            "Epoch [29/30] training Loss: -3053.9998\n",
            "Epoch [29/30] training Loss: -3054.0000\n",
            "Epoch [29/30] training Loss: -3054.0002\n",
            "Epoch [29/30] training Loss: -3054.0007\n",
            "Epoch [29/30] training Loss: -3054.0015\n",
            "Epoch [29/30] training Loss: -3053.9998\n",
            "Epoch [29/30] training Loss: -3054.0000\n",
            "Epoch [29/30] training Loss: -3054.0000\n",
            "Epoch [29/30] training Loss: -3054.0000\n",
            "Epoch [29/30] training Loss: -3054.0002\n",
            "Epoch [29/30] training Loss: -3054.0000\n",
            "Epoch [29/30] training Loss: -3054.0002\n",
            "Epoch [29/30] training Loss: -3054.0007\n",
            "Epoch [29/30] training Loss: -3053.9988\n",
            "Epoch [29/30] training Loss: -3054.0000\n",
            "Epoch [29/30] training Loss: -3054.0002\n",
            "Epoch [29/30] training Loss: -3054.0000\n",
            "Epoch [29/30] training Loss: -3054.0002\n",
            "Epoch [29/30] training Loss: -3054.0005\n",
            "Epoch [29/30] training Loss: -3054.0010\n",
            "Epoch [29/30] training Loss: -3054.0012\n",
            "Epoch [29/30] training Loss: -3054.0022\n",
            "Epoch [29/30] training Loss: -3054.0005\n",
            "Epoch [29/30] training Loss: -3053.9966\n",
            "Epoch [29/30] training Loss: -3053.9988\n",
            "Epoch [29/30] training Loss: -3053.9990\n",
            "Epoch [29/30] training Loss: -3053.9995\n",
            "Epoch [29/30] training Loss: -3053.9995\n",
            "Epoch [29/30] training Loss: -3053.9995\n",
            "Epoch [29/30] training Loss: -3054.0010\n",
            "Epoch [29/30] training Loss: -3053.9980\n",
            "Epoch [29/30] training Loss: -3053.9993\n",
            "Epoch [29/30] training Loss: -3053.9998\n",
            "Epoch [29/30] training Loss: -3054.0000\n",
            "Epoch [29/30] training Loss: -3054.0000\n",
            "Epoch [29/30] training Loss: -3054.0002\n",
            "Epoch [29/30] training Loss: -3054.0002\n",
            "Epoch [29/30] training Loss: -3054.0002\n",
            "Epoch [29/30] training Loss: -3054.0005\n",
            "Epoch [29/30] training Loss: -3054.0005\n",
            "Epoch [29/30] training Loss: -3054.0010\n",
            "Epoch [29/30] training Loss: -3054.0029\n",
            "Epoch [29/30] training Loss: -3053.9993\n",
            "Epoch [29/30] training Loss: -3053.9998\n",
            "Epoch [29/30] training Loss: -3054.0000\n",
            "Epoch [29/30] training Loss: -3054.0000\n",
            "Epoch [29/30] training Loss: -3054.0005\n",
            "Epoch [29/30] training Loss: -3054.0007\n",
            "Epoch [29/30] training Loss: -3054.0044\n",
            "Epoch [29/30] training Loss: -3053.9998\n",
            "0it [00:00, ?it/s]Epoch [28/30] validation Loss: -3054.0000\n",
            "19it [00:01, 10.97it/s]Epoch [28/30] validation Loss: -3054.0000\n",
            "39it [00:03, 16.36it/s]Epoch [28/30] validation Loss: -3053.9998\n",
            "59it [00:04, 16.56it/s]Epoch [28/30] validation Loss: -3054.0000\n",
            "79it [00:05, 16.72it/s]Epoch [28/30] validation Loss: -3053.9998\n",
            "99it [00:06, 16.65it/s]Epoch [28/30] validation Loss: -3053.9998\n",
            "119it [00:07, 16.66it/s]Epoch [28/30] validation Loss: -3054.0000\n",
            "139it [00:09, 16.68it/s]Epoch [28/30] validation Loss: -3054.0000\n",
            "159it [00:10, 16.66it/s]Epoch [28/30] validation Loss: -3054.0000\n",
            "179it [00:11, 16.76it/s]Epoch [28/30] validation Loss: -3054.0000\n",
            "199it [00:12, 16.67it/s]Epoch [28/30] validation Loss: -3053.9998\n",
            "219it [00:13, 16.70it/s]Epoch [28/30] validation Loss: -3054.0000\n",
            "239it [00:15, 16.81it/s]Epoch [28/30] validation Loss: -3054.0000\n",
            "259it [00:16, 16.78it/s]Epoch [28/30] validation Loss: -3054.0000\n",
            "279it [00:17, 16.72it/s]Epoch [28/30] validation Loss: -3054.0000\n",
            "299it [00:18, 16.77it/s]Epoch [28/30] validation Loss: -3054.0000\n",
            "319it [00:19, 16.76it/s]Epoch [28/30] validation Loss: -3054.0000\n",
            "339it [00:21, 16.44it/s]Epoch [28/30] validation Loss: -3053.9998\n",
            "351it [00:21, 17.28it/s]\n",
            "Pixel Acc:  0.49264713931839255\n",
            "Class Accuracy:  [0.03358802 0.         0.89937181 0.         0.         0.06776746]\n",
            "Mean Class Acc:  0.1667878824732625\n",
            "Freq Weighted IoU:  0.280351783569356\n",
            "Mean IoU:  0.09187911111569037\n",
            "confusion_matrix [[  687157.        0. 18439458.        0.        0.  1331779.]\n",
            " [  478363.        0. 11409230.        0.        0.   813091.]\n",
            " [ 1861529.        0. 46283278.        0.        0.  3316977.]\n",
            " [  258031.        0.  5920491.        0.        0.   443878.]\n",
            " [  134842.        0.  2474510.        0.        0.   200640.]\n",
            " [   60777.        0.  1333291.        0.        0.   101340.]]\n",
            "Epoch [30/30] training Loss: -3054.0000\n",
            "Epoch [30/30] training Loss: -3053.9971\n",
            "Epoch [30/30] training Loss: -3053.9998\n",
            "Epoch [30/30] training Loss: -3054.0002\n",
            "Epoch [30/30] training Loss: -3054.0010\n",
            "Epoch [30/30] training Loss: -3054.0046\n",
            "Epoch [30/30] training Loss: -3053.9993\n",
            "Epoch [30/30] training Loss: -3053.9902\n",
            "Epoch [30/30] training Loss: -3053.9978\n",
            "Epoch [30/30] training Loss: -3054.0088\n",
            "Epoch [30/30] training Loss: -3053.9966\n",
            "Epoch [30/30] training Loss: -3053.9976\n",
            "Epoch [30/30] training Loss: -3053.9983\n",
            "Epoch [30/30] training Loss: -3053.9988\n",
            "Epoch [30/30] training Loss: -3053.9993\n",
            "Epoch [30/30] training Loss: -3054.0000\n",
            "Epoch [30/30] training Loss: -3054.0000\n",
            "Epoch [30/30] training Loss: -3053.9998\n",
            "Epoch [30/30] training Loss: -3054.0000\n",
            "Epoch [30/30] training Loss: -3053.9998\n",
            "Epoch [30/30] training Loss: -3054.0000\n",
            "Epoch [30/30] training Loss: -3054.0000\n",
            "Epoch [30/30] training Loss: -3053.9998\n",
            "Epoch [30/30] training Loss: -3053.9998\n",
            "Epoch [30/30] training Loss: -3053.9998\n",
            "Epoch [30/30] training Loss: -3054.0000\n",
            "Epoch [30/30] training Loss: -3054.0000\n",
            "Epoch [30/30] training Loss: -3053.9998\n",
            "Epoch [30/30] training Loss: -3053.9998\n",
            "Epoch [30/30] training Loss: -3054.0000\n",
            "Epoch [30/30] training Loss: -3054.0000\n",
            "Epoch [30/30] training Loss: -3053.9998\n",
            "Epoch [30/30] training Loss: -3054.0002\n",
            "Epoch [30/30] training Loss: -3053.9998\n",
            "Epoch [30/30] training Loss: -3054.0000\n",
            "Epoch [30/30] training Loss: -3054.0002\n",
            "Epoch [30/30] training Loss: -3054.0000\n",
            "Epoch [30/30] training Loss: -3054.0000\n",
            "Epoch [30/30] training Loss: -3054.0000\n",
            "Epoch [30/30] training Loss: -3054.0000\n",
            "Epoch [30/30] training Loss: -3054.0002\n",
            "Epoch [30/30] training Loss: -3054.0000\n",
            "Epoch [30/30] training Loss: -3054.0002\n",
            "Epoch [30/30] training Loss: -3054.0000\n",
            "Epoch [30/30] training Loss: -3054.0002\n",
            "Epoch [30/30] training Loss: -3054.0005\n",
            "Epoch [30/30] training Loss: -3054.0007\n",
            "Epoch [30/30] training Loss: -3053.9978\n",
            "Epoch [30/30] training Loss: -3053.9995\n",
            "Epoch [30/30] training Loss: -3053.9998\n",
            "Epoch [30/30] training Loss: -3054.0000\n",
            "Epoch [30/30] training Loss: -3054.0000\n",
            "Epoch [30/30] training Loss: -3054.0000\n",
            "Epoch [30/30] training Loss: -3054.0000\n",
            "Epoch [30/30] training Loss: -3054.0002\n",
            "Epoch [30/30] training Loss: -3054.0002\n",
            "Epoch [30/30] training Loss: -3054.0005\n",
            "Epoch [30/30] training Loss: -3054.0010\n",
            "Epoch [30/30] training Loss: -3053.9973\n",
            "Epoch [30/30] training Loss: -3054.0002\n",
            "Epoch [30/30] training Loss: -3054.0000\n",
            "Epoch [30/30] training Loss: -3054.0000\n",
            "Epoch [30/30] training Loss: -3054.0000\n",
            "Epoch [30/30] training Loss: -3054.0000\n",
            "Epoch [30/30] training Loss: -3054.0000\n",
            "Epoch [30/30] training Loss: -3054.0002\n",
            "Epoch [30/30] training Loss: -3054.0000\n",
            "Epoch [30/30] training Loss: -3054.0000\n",
            "Epoch [30/30] training Loss: -3054.0000\n",
            "Epoch [30/30] training Loss: -3054.0000\n",
            "Epoch [30/30] training Loss: -3054.0002\n",
            "0it [00:00, ?it/s]Epoch [29/30] validation Loss: -3054.0002\n",
            "19it [00:01, 11.08it/s]Epoch [29/30] validation Loss: -3054.0002\n",
            "39it [00:03, 16.45it/s]Epoch [29/30] validation Loss: -3054.0000\n",
            "59it [00:04, 16.75it/s]Epoch [29/30] validation Loss: -3054.0000\n",
            "79it [00:05, 16.61it/s]Epoch [29/30] validation Loss: -3054.0000\n",
            "99it [00:06, 16.72it/s]Epoch [29/30] validation Loss: -3054.0000\n",
            "119it [00:07, 16.74it/s]Epoch [29/30] validation Loss: -3054.0002\n",
            "139it [00:09, 16.64it/s]Epoch [29/30] validation Loss: -3054.0000\n",
            "159it [00:10, 16.73it/s]Epoch [29/30] validation Loss: -3054.0002\n",
            "179it [00:11, 16.55it/s]Epoch [29/30] validation Loss: -3054.0000\n",
            "199it [00:12, 16.59it/s]Epoch [29/30] validation Loss: -3054.0000\n",
            "219it [00:13, 16.69it/s]Epoch [29/30] validation Loss: -3054.0002\n",
            "239it [00:15, 16.78it/s]Epoch [29/30] validation Loss: -3054.0002\n",
            "259it [00:16, 16.76it/s]Epoch [29/30] validation Loss: -3054.0005\n",
            "279it [00:17, 16.67it/s]Epoch [29/30] validation Loss: -3054.0002\n",
            "299it [00:18, 16.75it/s]Epoch [29/30] validation Loss: -3054.0002\n",
            "319it [00:19, 16.73it/s]Epoch [29/30] validation Loss: -3054.0005\n",
            "339it [00:21, 16.82it/s]Epoch [29/30] validation Loss: -3054.0000\n",
            "351it [00:21, 17.44it/s]\n",
            "Pixel Acc:  0.5058127344577572\n",
            "Class Accuracy:  [9.80389272e-02 0.00000000e+00 9.00153986e-01 0.00000000e+00\n",
            " 0.00000000e+00 3.21651349e-04]\n",
            "Mean Class Acc:  0.16641909411003922\n",
            "Freq Weighted IoU:  0.2892141520718954\n",
            "Mean IoU:  0.09674376456368827\n",
            "confusion_matrix [[2.0057190e+06 0.0000000e+00 1.8439458e+07 0.0000000e+00 0.0000000e+00\n",
            "  1.3217000e+04]\n",
            " [1.2837110e+06 0.0000000e+00 1.1409230e+07 0.0000000e+00 0.0000000e+00\n",
            "  7.7430000e+03]\n",
            " [5.1087370e+06 0.0000000e+00 4.6323530e+07 0.0000000e+00 0.0000000e+00\n",
            "  2.9517000e+04]\n",
            " [6.7238500e+05 0.0000000e+00 5.9486390e+06 0.0000000e+00 0.0000000e+00\n",
            "  1.3760000e+03]\n",
            " [3.0779200e+05 0.0000000e+00 2.5015430e+06 0.0000000e+00 0.0000000e+00\n",
            "  6.5700000e+02]\n",
            " [1.5350500e+05 0.0000000e+00 1.3414220e+06 0.0000000e+00 0.0000000e+00\n",
            "  4.8100000e+02]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jba-4WFzrjYZ",
        "colab_type": "code",
        "outputId": "39b2662e-53fb-4862-dd35-199335028c56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "!python test.py --model_path 'runs/Jan18_233504_SeismicNet/seismic_model.pkl' "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "split: test1, section: 0\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "split: test1, section: 1\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "split: test1, section: 2\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "split: test1, section: 3\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "split: test1, section: 4\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}