{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PETAI-Domain-Adaptation-Training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNLLQujvLOxX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea44c1dd-2895-4206-cbdd-47e66f99f22f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bKN2Kn1M29y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e7301601-df2a-43a1-c355-343232beda37"
      },
      "source": [
        "%cd /content/drive/My Drive/PETAI-master/deep_domain_adaptation/DeepCORAL-master/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/PETAI-master/deep_domain_adaptation/DeepCORAL-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxL5m_vNAFG2",
        "colab_type": "text"
      },
      "source": [
        "!pip install torchviz\n",
        "from torchviz import make_dot\n",
        "import torch\n",
        "from core.models import model\n",
        "print(len(model.DeepCORAL(4, \"SeismicNet\")(torch.randn((32, 1, 40, 40)), torch.randn((32, 1, 40, 40)))))\n",
        "source_outputs_val, _, _, _, _, _, _, _, _ = model.DeepCORAL(4, \"SeismicNet\")(torch.randn((32, 1, 40, 40)), torch.randn((32, 1, 40, 40)))\n",
        "make_dot(models_CORALonEncoder.DeepCORAL(4, \"SeismicNet\")(torch.randn((32, 1, 40, 40)), torch.randn((32, 1, 40, 40))))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fknt2ByNZ-FM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8fdcb739-41a4-465f-8e84-0cee0ec7225e"
      },
      "source": [
        "'''from core import data_loader_netherlands, data_loader_canada\n",
        "from torch.utils import data\n",
        "source_train_set = data_loader_netherlands.PatchLoader(is_transform=True, split='train', augmentations=None)                                          \n",
        "target_train_set = data_loader_canada.PatchLoader(is_transform=True, split='train', augmentations=None)\n",
        "n_classes = source_train_set.n_classes\n",
        "source_trainloader = data.DataLoader(source_train_set,batch_size=128,num_workers=1,shuffle=True)\n",
        "target_trainloader = data.DataLoader(target_train_set,batch_size=98,num_workers=1,shuffle=True)\n",
        "print(len(source_trainloader))\n",
        "print(len(target_trainloader))'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"from core import data_loader_netherlands, data_loader_canada\\nfrom torch.utils import data\\nsource_train_set = data_loader_netherlands.PatchLoader(is_transform=True, split='train', augmentations=None)                                          \\ntarget_train_set = data_loader_canada.PatchLoader(is_transform=True, split='train', augmentations=None)\\nn_classes = source_train_set.n_classes\\nsource_trainloader = data.DataLoader(source_train_set,batch_size=128,num_workers=1,shuffle=True)\\ntarget_trainloader = data.DataLoader(target_train_set,batch_size=98,num_workers=1,shuffle=True)\\nprint(len(source_trainloader))\\nprint(len(target_trainloader))\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-6BvtgjOz5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vJPONgOPI8s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e6b032b8-7b8c-45e3-9d83-b60424380f86"
      },
      "source": [
        "pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (47.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ik7B5qRhhic",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "12eb5a67-a4ba-46ad-ee4b-62be817d9510"
      },
      "source": [
        "%ls Results/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mClassification_0.001_128_adam_SeismicNet_Train_On_Netherlands\u001b[0m/\n",
            "\u001b[01;34mDA_SeismicNet_0.001_128_98_adam_3_Class_factor_1e4_lambda_epoch_based_1_test\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTrMmPVRS1VX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r Results/DA_SeismicNet_0.001_128_98_adam_3_Class_factor_1e4_lambda_epoch_based_1_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icKmge74PEL6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "87d327f6-9a12-4fe0-908c-8792e7a9f901"
      },
      "source": [
        "'''start = time.time()\n",
        "!python train_classifier.py --train --netherlands_batch_size 128 --n_epoch 1 --base_lr 0.001 --optim adam --exp SeismicNet_Train_On_Netherlands\n",
        "done = time.time()\n",
        "elapsed = done - start\n",
        "print(\"\\n\\nTotal Runtime:\", elapsed/60, \"minutes\")'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'start = time.time()\\n!python train_classifier.py --train --netherlands_batch_size 128 --n_epoch 1 --base_lr 0.001 --optim adam --exp SeismicNet_Train_On_Netherlands\\ndone = time.time()\\nelapsed = done - start\\nprint(\"\\n\\nTotal Runtime:\", elapsed/60, \"minutes\")'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRP0lj12vqHH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        },
        "outputId": "0e5494ba-f7a0-4aef-9cc9-486605944958"
      },
      "source": [
        "start = time.time()\n",
        "!python train_DeepCORAL_classification_diff_layers.py --train --netherlands_batch_size 128 --canada_batch_size 98 --n_epoch 1 --base_lr 0.001 --optim adam --resume Results/Classification_0.001_128_adam_SeismicNet_Train_On_Netherlands/best_checkpoint.pth --__lambda epoch_based_1 --backbone SeismicNet --exp 3_Class_factor_1e4_lambda_epoch_based_1_test\n",
        "done = time.time()\n",
        "elapsed = done - start\n",
        "print(\"\\n\\nTotal Runtime:\", elapsed/60, \"minutes\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model and optimizer from checkpoint 'Results/Classification_0.001_128_adam_SeismicNet_Train_On_Netherlands/best_checkpoint.pth'\n",
            "train_DeepCORAL_classification_diff_layers.py:276: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
            "  torch.nn.utils.clip_grad_norm(model.parameters(), args.clip)\n",
            "epoch: 1/1\t\t iter: 1/584\t\t LOSS( Classification Loss:1.1647\t\t CORAL Loss:870.1006\t\t Total Loss:871.2654 )\n",
            "epoch: 1/1\t\t iter: 21/584\t\t LOSS( Classification Loss:0.1480\t\t CORAL Loss:0.0122\t\t Total Loss:0.1601 )\n",
            "epoch: 1/1\t\t iter: 41/584\t\t LOSS( Classification Loss:0.0709\t\t CORAL Loss:0.0096\t\t Total Loss:0.0805 )\n",
            "epoch: 1/1\t\t iter: 61/584\t\t LOSS( Classification Loss:0.1552\t\t CORAL Loss:0.0080\t\t Total Loss:0.1632 )\n",
            "epoch: 1/1\t\t iter: 81/584\t\t LOSS( Classification Loss:0.0663\t\t CORAL Loss:0.0100\t\t Total Loss:0.0764 )\n",
            "epoch: 1/1\t\t iter: 101/584\t\t LOSS( Classification Loss:0.0163\t\t CORAL Loss:0.0037\t\t Total Loss:0.0200 )\n",
            "epoch: 1/1\t\t iter: 121/584\t\t LOSS( Classification Loss:0.2099\t\t CORAL Loss:0.0059\t\t Total Loss:0.2158 )\n",
            "epoch: 1/1\t\t iter: 141/584\t\t LOSS( Classification Loss:0.0612\t\t CORAL Loss:0.0036\t\t Total Loss:0.0648 )\n",
            "epoch: 1/1\t\t iter: 161/584\t\t LOSS( Classification Loss:0.1873\t\t CORAL Loss:0.0015\t\t Total Loss:0.1888 )\n",
            "epoch: 1/1\t\t iter: 181/584\t\t LOSS( Classification Loss:0.0082\t\t CORAL Loss:0.0078\t\t Total Loss:0.0160 )\n",
            "epoch: 1/1\t\t iter: 201/584\t\t LOSS( Classification Loss:0.0254\t\t CORAL Loss:0.0072\t\t Total Loss:0.0325 )\n",
            "epoch: 1/1\t\t iter: 221/584\t\t LOSS( Classification Loss:0.0332\t\t CORAL Loss:0.0050\t\t Total Loss:0.0381 )\n",
            "epoch: 1/1\t\t iter: 241/584\t\t LOSS( Classification Loss:0.0504\t\t CORAL Loss:0.0048\t\t Total Loss:0.0551 )\n",
            "epoch: 1/1\t\t iter: 261/584\t\t LOSS( Classification Loss:0.0556\t\t CORAL Loss:0.0095\t\t Total Loss:0.0651 )\n",
            "epoch: 1/1\t\t iter: 281/584\t\t LOSS( Classification Loss:0.0646\t\t CORAL Loss:0.0012\t\t Total Loss:0.0657 )\n",
            "epoch: 1/1\t\t iter: 301/584\t\t LOSS( Classification Loss:0.0503\t\t CORAL Loss:0.0047\t\t Total Loss:0.0550 )\n",
            "epoch: 1/1\t\t iter: 321/584\t\t LOSS( Classification Loss:0.0770\t\t CORAL Loss:0.0015\t\t Total Loss:0.0785 )\n",
            "epoch: 1/1\t\t iter: 341/584\t\t LOSS( Classification Loss:0.0145\t\t CORAL Loss:0.0088\t\t Total Loss:0.0233 )\n",
            "epoch: 1/1\t\t iter: 361/584\t\t LOSS( Classification Loss:0.0321\t\t CORAL Loss:0.0038\t\t Total Loss:0.0359 )\n",
            "epoch: 1/1\t\t iter: 381/584\t\t LOSS( Classification Loss:0.0482\t\t CORAL Loss:0.0022\t\t Total Loss:0.0504 )\n",
            "epoch: 1/1\t\t iter: 401/584\t\t LOSS( Classification Loss:0.0126\t\t CORAL Loss:0.0013\t\t Total Loss:0.0139 )\n",
            "epoch: 1/1\t\t iter: 421/584\t\t LOSS( Classification Loss:0.0625\t\t CORAL Loss:0.0014\t\t Total Loss:0.0640 )\n",
            "epoch: 1/1\t\t iter: 441/584\t\t LOSS( Classification Loss:0.0030\t\t CORAL Loss:0.0031\t\t Total Loss:0.0061 )\n",
            "epoch: 1/1\t\t iter: 461/584\t\t LOSS( Classification Loss:0.0023\t\t CORAL Loss:0.0025\t\t Total Loss:0.0048 )\n",
            "epoch: 1/1\t\t iter: 481/584\t\t LOSS( Classification Loss:0.0223\t\t CORAL Loss:0.0018\t\t Total Loss:0.0242 )\n",
            "epoch: 1/1\t\t iter: 501/584\t\t LOSS( Classification Loss:0.0048\t\t CORAL Loss:0.0017\t\t Total Loss:0.0065 )\n",
            "epoch: 1/1\t\t iter: 521/584\t\t LOSS( Classification Loss:0.0573\t\t CORAL Loss:0.0007\t\t Total Loss:0.0580 )\n",
            "epoch: 1/1\t\t iter: 541/584\t\t LOSS( Classification Loss:0.0949\t\t CORAL Loss:0.0011\t\t Total Loss:0.0960 )\n",
            "epoch: 1/1\t\t iter: 561/584\t\t LOSS( Classification Loss:0.0105\t\t CORAL Loss:0.0011\t\t Total Loss:0.0117 )\n",
            "epoch: 1/1\t\t iter: 581/584\t\t LOSS( Classification Loss:0.0285\t\t CORAL Loss:0.0006\t\t Total Loss:0.0291 )\n",
            "\n",
            "=====================================================================================================================================================================================\n",
            "\n",
            "epoch: 1/1\t\t iter: 1/19\t\t Validation Classification Loss(SOURCE): 8.4164\n",
            "\n",
            "\n",
            "epoch: 1/1\t\t iter: 1/92\t\t Validation Classification Loss(TARGET): 4.2733\n",
            "epoch: 1/1\t\t iter: 21/92\t\t Validation Classification Loss(TARGET): 5.2696\n",
            "epoch: 1/1\t\t iter: 41/92\t\t Validation Classification Loss(TARGET): 4.5371\n",
            "epoch: 1/1\t\t iter: 61/92\t\t Validation Classification Loss(TARGET): 5.8342\n",
            "epoch: 1/1\t\t iter: 81/92\t\t Validation Classification Loss(TARGET): 4.8809\n",
            "\n",
            "\n",
            "Most Recent Checkpoint Saved at Epoch Number 1.\n",
            "\n",
            "=====================================================================================================================================================================================\n",
            "\n",
            "Best Checkpoint Saved at epoch number 1.\n",
            "\n",
            "\n",
            "Total Runtime: 6.150675805409749 minutes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ5OzpOCRP7u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d7c65d5d-8199-4dc2-8b3f-c2405173b0f1"
      },
      "source": [
        "'''start = time.time()\n",
        "!python train_DeepCORAL_classification.py --train --netherlands_batch_size 128 --canada_batch_size 98 --n_epoch 5 --base_lr 0.001 --optim adam --resume Results/Classification_0.001_128_adam_SeismicNet_Train_On_Netherlands/best_checkpoint.pth --__lambda epoch_based_1 --backbone SeismicNet --exp 3_Class_factor_1e4_lambda_epoch_based_1_test\n",
        "done = time.time()\n",
        "elapsed = done - start\n",
        "print(\"\\n\\nTotal Runtime:\", elapsed/60, \"minutes\")'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'start = time.time()\\n!python train_DeepCORAL_classification.py --train --netherlands_batch_size 128 --canada_batch_size 98 --n_epoch 5 --base_lr 0.001 --optim adam --resume Results/Classification_0.001_128_adam_SeismicNet_Train_On_Netherlands/best_checkpoint.pth --__lambda epoch_based_1 --backbone SeismicNet --exp 3_Class_factor_1e4_lambda_epoch_based_1_test\\ndone = time.time()\\nelapsed = done - start\\nprint(\"\\n\\nTotal Runtime:\", elapsed/60, \"minutes\")'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaXuIPZQJIXD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0f9a8f33-c76f-4501-b8d7-c4bcc974e073"
      },
      "source": [
        "'''start = time.time()\n",
        "!python train_DeepCORAL.py --train --netherlands_batch_size 32 --canada_batch_size 32 --n_epoch 30 --base_lr 0.001 --optim adam --__lambda epoch_based_1 --backbone SeismicNet --exp test1\n",
        "done = time.time()\n",
        "elapsed = done - start\n",
        "print(\"\\n\\nTotal Runtime:\", elapsed/60, \"minutes\")'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'start = time.time()\\n!python train_DeepCORAL.py --train --netherlands_batch_size 32 --canada_batch_size 32 --n_epoch 30 --base_lr 0.001 --optim adam --__lambda epoch_based_1 --backbone SeismicNet --exp test1\\ndone = time.time()\\nelapsed = done - start\\nprint(\"\\n\\nTotal Runtime:\", elapsed/60, \"minutes\")'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3-DFjG4P9bB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}